{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rivaldilambey22/rivaldilambey22/blob/main/Model_ANN_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voPhraMzs1bf"
      },
      "source": [
        "*Social Computing Big Data Laboratory - 2022*\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcE_3aurttXt"
      },
      "source": [
        "## **Predicting Indonesia Stock Exchange Composite**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx8bVK13t8xg"
      },
      "source": [
        "### **Import Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "32ysSwQRhnB3"
      },
      "outputs": [],
      "source": [
        "# Import Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import Modules\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "#Seed\n",
        "import random\n",
        "random.seed(10)\n",
        "\n",
        "#Import Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhNN8Ncuwlfq"
      },
      "source": [
        "### **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m__vfsANjF-1"
      },
      "outputs": [],
      "source": [
        "# Import the files to Google Colab\n",
        "url = 'https://raw.githubusercontent.com/apriandito/dl-python/main/data/idx.csv'\n",
        "df = pd.read_csv(url, sep=',',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BrTtHw0fuuBv",
        "outputId": "e9238ffe-e28b-4b98-8da4-66a867e07129"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date      idx  exchange_rate_m2  interest_rate_m2  inflation_rate_m2  \\\n",
              "0  2006-02-01  1216.14         -0.336762             2.853           3.163729   \n",
              "1  2006-03-01  1322.97         -0.466187             2.853           3.139882   \n",
              "2  2006-04-01  1464.40         -0.727790             2.853           3.405172   \n",
              "3  2006-05-01  1330.00         -0.810401             2.853           2.755361   \n",
              "4  2006-06-01  1310.26         -0.879244             2.853           2.654015   \n",
              "\n",
              "   money_supply_m2  \n",
              "0        -1.379015  \n",
              "1        -1.385178  \n",
              "2        -1.382946  \n",
              "3        -1.382177  \n",
              "4        -1.383458  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a5f3cf7-13a5-4449-abc6-53a8c2996184\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>idx</th>\n",
              "      <th>exchange_rate_m2</th>\n",
              "      <th>interest_rate_m2</th>\n",
              "      <th>inflation_rate_m2</th>\n",
              "      <th>money_supply_m2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006-02-01</td>\n",
              "      <td>1216.14</td>\n",
              "      <td>-0.336762</td>\n",
              "      <td>2.853</td>\n",
              "      <td>3.163729</td>\n",
              "      <td>-1.379015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2006-03-01</td>\n",
              "      <td>1322.97</td>\n",
              "      <td>-0.466187</td>\n",
              "      <td>2.853</td>\n",
              "      <td>3.139882</td>\n",
              "      <td>-1.385178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2006-04-01</td>\n",
              "      <td>1464.40</td>\n",
              "      <td>-0.727790</td>\n",
              "      <td>2.853</td>\n",
              "      <td>3.405172</td>\n",
              "      <td>-1.382946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006-05-01</td>\n",
              "      <td>1330.00</td>\n",
              "      <td>-0.810401</td>\n",
              "      <td>2.853</td>\n",
              "      <td>2.755361</td>\n",
              "      <td>-1.382177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006-06-01</td>\n",
              "      <td>1310.26</td>\n",
              "      <td>-0.879244</td>\n",
              "      <td>2.853</td>\n",
              "      <td>2.654015</td>\n",
              "      <td>-1.383458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a5f3cf7-13a5-4449-abc6-53a8c2996184')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2a5f3cf7-13a5-4449-abc6-53a8c2996184 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2a5f3cf7-13a5-4449-abc6-53a8c2996184');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37d3d18a-d31c-47f4-bffd-80d43d96bbc2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37d3d18a-d31c-47f4-bffd-80d43d96bbc2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37d3d18a-d31c-47f4-bffd-80d43d96bbc2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Show the 5 first row\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1al6aphKjXP-",
        "outputId": "37b56f93-3ae0-429e-bf04-edc253c6499f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 142 entries, 0 to 141\n",
            "Data columns (total 6 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   date               142 non-null    object \n",
            " 1   idx                142 non-null    float64\n",
            " 2   exchange_rate_m2   142 non-null    float64\n",
            " 3   interest_rate_m2   142 non-null    float64\n",
            " 4   inflation_rate_m2  142 non-null    float64\n",
            " 5   money_supply_m2    142 non-null    float64\n",
            "dtypes: float64(5), object(1)\n",
            "memory usage: 6.8+ KB\n"
          ]
        }
      ],
      "source": [
        "# Show data information\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sdzx_P1w2W_"
      },
      "source": [
        "### **Set Feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fVM2eIrTkBjL"
      },
      "outputs": [],
      "source": [
        "# Selecting feature, by remove the unused feature\n",
        "feature = ['idx', 'date']\n",
        "train_feature = df.drop(feature, axis=1)\n",
        "\n",
        "# Set target\n",
        "train_target = df['idx']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EhEdO3Ow657"
      },
      "source": [
        "### **Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QFDRgSSIju3f",
        "outputId": "3e5b4829-009a-4b71-d002-06fc9cbb8dae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     exchange_rate_m2  interest_rate_m2  inflation_rate_m2  money_supply_m2\n",
              "94           0.524049         -0.040183           0.543620         0.491152\n",
              "10          -0.778458          1.800933          -0.061479        -1.279238\n",
              "34          -0.598365          1.143392           1.571991        -0.898711\n",
              "32          -0.859417          0.880375           1.595837        -1.000864\n",
              "114          1.425616          0.091325           0.227657         1.107107\n",
              "..                ...               ...                ...              ...\n",
              "133          1.566055         -1.355266          -0.896098         1.562481\n",
              "137          1.472980         -1.355266          -0.645712         1.711747\n",
              "72          -0.857215         -0.697725          -0.806674        -0.059987\n",
              "140          1.474081         -1.486774          -0.797732         1.784303\n",
              "37           0.169921          0.748867           0.796987        -0.850143\n",
              "\n",
              "[71 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8508218d-5ece-4430-b1cb-8a9729a9295e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exchange_rate_m2</th>\n",
              "      <th>interest_rate_m2</th>\n",
              "      <th>inflation_rate_m2</th>\n",
              "      <th>money_supply_m2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0.524049</td>\n",
              "      <td>-0.040183</td>\n",
              "      <td>0.543620</td>\n",
              "      <td>0.491152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.778458</td>\n",
              "      <td>1.800933</td>\n",
              "      <td>-0.061479</td>\n",
              "      <td>-1.279238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>-0.598365</td>\n",
              "      <td>1.143392</td>\n",
              "      <td>1.571991</td>\n",
              "      <td>-0.898711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>-0.859417</td>\n",
              "      <td>0.880375</td>\n",
              "      <td>1.595837</td>\n",
              "      <td>-1.000864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>1.425616</td>\n",
              "      <td>0.091325</td>\n",
              "      <td>0.227657</td>\n",
              "      <td>1.107107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>1.566055</td>\n",
              "      <td>-1.355266</td>\n",
              "      <td>-0.896098</td>\n",
              "      <td>1.562481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>1.472980</td>\n",
              "      <td>-1.355266</td>\n",
              "      <td>-0.645712</td>\n",
              "      <td>1.711747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>-0.857215</td>\n",
              "      <td>-0.697725</td>\n",
              "      <td>-0.806674</td>\n",
              "      <td>-0.059987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1.474081</td>\n",
              "      <td>-1.486774</td>\n",
              "      <td>-0.797732</td>\n",
              "      <td>1.784303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.169921</td>\n",
              "      <td>0.748867</td>\n",
              "      <td>0.796987</td>\n",
              "      <td>-0.850143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8508218d-5ece-4430-b1cb-8a9729a9295e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8508218d-5ece-4430-b1cb-8a9729a9295e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8508218d-5ece-4430-b1cb-8a9729a9295e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37c5b395-cf06-4535-8bb0-790185be15b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37c5b395-cf06-4535-8bb0-790185be15b1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37c5b395-cf06-4535-8bb0-790185be15b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_feature ,train_target, shuffle = True, test_size=0.5, random_state=1)\n",
        "\n",
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10sK0NKTw-H9"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLMdijESkeA2",
        "outputId": "a90687c5-17d4-4809-a68a-2c721b2ddc28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration 16406, loss = 30427.47771812\n",
            "Iteration 16407, loss = 30426.83532502\n",
            "Iteration 16408, loss = 30425.29053550\n",
            "Iteration 16409, loss = 30423.42146148\n",
            "Iteration 16410, loss = 30422.16793549\n",
            "Iteration 16411, loss = 30421.74805707\n",
            "Iteration 16412, loss = 30420.71958946\n",
            "Iteration 16413, loss = 30418.65495324\n",
            "Iteration 16414, loss = 30416.86784480\n",
            "Iteration 16415, loss = 30416.89877246\n",
            "Iteration 16416, loss = 30415.30939643\n",
            "Iteration 16417, loss = 30413.05641244\n",
            "Iteration 16418, loss = 30411.74278886\n",
            "Iteration 16419, loss = 30411.44230630\n",
            "Iteration 16420, loss = 30410.51979013\n",
            "Iteration 16421, loss = 30407.97016630\n",
            "Iteration 16422, loss = 30408.15307426\n",
            "Iteration 16423, loss = 30407.98866122\n",
            "Iteration 16424, loss = 30406.34486371\n",
            "Iteration 16425, loss = 30404.76596459\n",
            "Iteration 16426, loss = 30403.95607320\n",
            "Iteration 16427, loss = 30402.25670920\n",
            "Iteration 16428, loss = 30399.83324058\n",
            "Iteration 16429, loss = 30399.02749792\n",
            "Iteration 16430, loss = 30397.71415055\n",
            "Iteration 16431, loss = 30396.35915895\n",
            "Iteration 16432, loss = 30395.41806498\n",
            "Iteration 16433, loss = 30394.38066728\n",
            "Iteration 16434, loss = 30393.66692160\n",
            "Iteration 16435, loss = 30391.69447219\n",
            "Iteration 16436, loss = 30390.70001895\n",
            "Iteration 16437, loss = 30390.15524130\n",
            "Iteration 16438, loss = 30388.44087939\n",
            "Iteration 16439, loss = 30386.53463606\n",
            "Iteration 16440, loss = 30385.56602876\n",
            "Iteration 16441, loss = 30384.25778204\n",
            "Iteration 16442, loss = 30383.41827024\n",
            "Iteration 16443, loss = 30382.42837075\n",
            "Iteration 16444, loss = 30380.46525304\n",
            "Iteration 16445, loss = 30379.75034334\n",
            "Iteration 16446, loss = 30378.17774815\n",
            "Iteration 16447, loss = 30377.40704273\n",
            "Iteration 16448, loss = 30376.40708154\n",
            "Iteration 16449, loss = 30374.52538660\n",
            "Iteration 16450, loss = 30373.83054621\n",
            "Iteration 16451, loss = 30373.18257069\n",
            "Iteration 16452, loss = 30371.74413479\n",
            "Iteration 16453, loss = 30369.97667678\n",
            "Iteration 16454, loss = 30368.83574847\n",
            "Iteration 16455, loss = 30367.84003843\n",
            "Iteration 16456, loss = 30366.06212311\n",
            "Iteration 16457, loss = 30366.25881163\n",
            "Iteration 16458, loss = 30365.61204300\n",
            "Iteration 16459, loss = 30363.96139610\n",
            "Iteration 16460, loss = 30362.27002569\n",
            "Iteration 16461, loss = 30360.89492012\n",
            "Iteration 16462, loss = 30359.70986879\n",
            "Iteration 16463, loss = 30358.36175337\n",
            "Iteration 16464, loss = 30357.18146337\n",
            "Iteration 16465, loss = 30356.18978107\n",
            "Iteration 16466, loss = 30355.29625242\n",
            "Iteration 16467, loss = 30353.33370997\n",
            "Iteration 16468, loss = 30353.09017231\n",
            "Iteration 16469, loss = 30352.94703300\n",
            "Iteration 16470, loss = 30351.29868865\n",
            "Iteration 16471, loss = 30348.47856354\n",
            "Iteration 16472, loss = 30347.81835282\n",
            "Iteration 16473, loss = 30346.65778184\n",
            "Iteration 16474, loss = 30344.78299181\n",
            "Iteration 16475, loss = 30343.72940756\n",
            "Iteration 16476, loss = 30342.57873124\n",
            "Iteration 16477, loss = 30341.63690785\n",
            "Iteration 16478, loss = 30340.08271065\n",
            "Iteration 16479, loss = 30339.96547416\n",
            "Iteration 16480, loss = 30338.65930568\n",
            "Iteration 16481, loss = 30336.85615099\n",
            "Iteration 16482, loss = 30336.58264126\n",
            "Iteration 16483, loss = 30335.82869316\n",
            "Iteration 16484, loss = 30334.50885501\n",
            "Iteration 16485, loss = 30333.33707982\n",
            "Iteration 16486, loss = 30331.52619443\n",
            "Iteration 16487, loss = 30330.21714297\n",
            "Iteration 16488, loss = 30328.71285213\n",
            "Iteration 16489, loss = 30327.92355353\n",
            "Iteration 16490, loss = 30326.71426505\n",
            "Iteration 16491, loss = 30325.40488622\n",
            "Iteration 16492, loss = 30324.06012580\n",
            "Iteration 16493, loss = 30323.06227856\n",
            "Iteration 16494, loss = 30321.53433777\n",
            "Iteration 16495, loss = 30320.86170141\n",
            "Iteration 16496, loss = 30320.04698289\n",
            "Iteration 16497, loss = 30319.08944278\n",
            "Iteration 16498, loss = 30317.27290558\n",
            "Iteration 16499, loss = 30316.34844444\n",
            "Iteration 16500, loss = 30315.23931343\n",
            "Iteration 16501, loss = 30313.87241771\n",
            "Iteration 16502, loss = 30312.66601869\n",
            "Iteration 16503, loss = 30312.32333778\n",
            "Iteration 16504, loss = 30311.22752285\n",
            "Iteration 16505, loss = 30309.83009519\n",
            "Iteration 16506, loss = 30308.32274212\n",
            "Iteration 16507, loss = 30306.61325795\n",
            "Iteration 16508, loss = 30306.75253804\n",
            "Iteration 16509, loss = 30306.22474971\n",
            "Iteration 16510, loss = 30304.45179803\n",
            "Iteration 16511, loss = 30302.70275570\n",
            "Iteration 16512, loss = 30301.72014777\n",
            "Iteration 16513, loss = 30300.63926515\n",
            "Iteration 16514, loss = 30299.88265509\n",
            "Iteration 16515, loss = 30298.72456452\n",
            "Iteration 16516, loss = 30297.11774282\n",
            "Iteration 16517, loss = 30295.64062476\n",
            "Iteration 16518, loss = 30293.72230729\n",
            "Iteration 16519, loss = 30293.54860311\n",
            "Iteration 16520, loss = 30294.20402396\n",
            "Iteration 16521, loss = 30292.18638752\n",
            "Iteration 16522, loss = 30290.21898605\n",
            "Iteration 16523, loss = 30288.71667018\n",
            "Iteration 16524, loss = 30287.73203510\n",
            "Iteration 16525, loss = 30287.77271040\n",
            "Iteration 16526, loss = 30286.44455289\n",
            "Iteration 16527, loss = 30284.32705044\n",
            "Iteration 16528, loss = 30283.32350980\n",
            "Iteration 16529, loss = 30283.02448585\n",
            "Iteration 16530, loss = 30282.23219139\n",
            "Iteration 16531, loss = 30280.41422214\n",
            "Iteration 16532, loss = 30278.30962570\n",
            "Iteration 16533, loss = 30279.16116954\n",
            "Iteration 16534, loss = 30278.41287731\n",
            "Iteration 16535, loss = 30277.13930385\n",
            "Iteration 16536, loss = 30274.50496094\n",
            "Iteration 16537, loss = 30273.08272991\n",
            "Iteration 16538, loss = 30272.73211989\n",
            "Iteration 16539, loss = 30271.72794525\n",
            "Iteration 16540, loss = 30270.03671280\n",
            "Iteration 16541, loss = 30267.92846763\n",
            "Iteration 16542, loss = 30267.94441901\n",
            "Iteration 16543, loss = 30267.30281055\n",
            "Iteration 16544, loss = 30266.01415394\n",
            "Iteration 16545, loss = 30263.74064349\n",
            "Iteration 16546, loss = 30262.97849854\n",
            "Iteration 16547, loss = 30262.88335978\n",
            "Iteration 16548, loss = 30261.56679095\n",
            "Iteration 16549, loss = 30261.02353105\n",
            "Iteration 16550, loss = 30259.18381527\n",
            "Iteration 16551, loss = 30257.72659105\n",
            "Iteration 16552, loss = 30256.86216070\n",
            "Iteration 16553, loss = 30255.42564156\n",
            "Iteration 16554, loss = 30253.98720623\n",
            "Iteration 16555, loss = 30252.94175110\n",
            "Iteration 16556, loss = 30251.82637635\n",
            "Iteration 16557, loss = 30250.14629455\n",
            "Iteration 16558, loss = 30249.05333721\n",
            "Iteration 16559, loss = 30248.15686425\n",
            "Iteration 16560, loss = 30247.59928436\n",
            "Iteration 16561, loss = 30245.93216324\n",
            "Iteration 16562, loss = 30244.84188883\n",
            "Iteration 16563, loss = 30244.01964416\n",
            "Iteration 16564, loss = 30242.41490070\n",
            "Iteration 16565, loss = 30241.88235502\n",
            "Iteration 16566, loss = 30241.26391642\n",
            "Iteration 16567, loss = 30240.64114253\n",
            "Iteration 16568, loss = 30239.14197482\n",
            "Iteration 16569, loss = 30237.06309909\n",
            "Iteration 16570, loss = 30236.99867891\n",
            "Iteration 16571, loss = 30236.29627028\n",
            "Iteration 16572, loss = 30235.21660339\n",
            "Iteration 16573, loss = 30232.78989826\n",
            "Iteration 16574, loss = 30231.83703117\n",
            "Iteration 16575, loss = 30231.53817062\n",
            "Iteration 16576, loss = 30230.62504868\n",
            "Iteration 16577, loss = 30229.07872406\n",
            "Iteration 16578, loss = 30227.13669593\n",
            "Iteration 16579, loss = 30226.38151734\n",
            "Iteration 16580, loss = 30225.58049924\n",
            "Iteration 16581, loss = 30224.90845285\n",
            "Iteration 16582, loss = 30222.60782684\n",
            "Iteration 16583, loss = 30221.89120071\n",
            "Iteration 16584, loss = 30220.96988539\n",
            "Iteration 16585, loss = 30220.33439484\n",
            "Iteration 16586, loss = 30218.50798991\n",
            "Iteration 16587, loss = 30217.79926801\n",
            "Iteration 16588, loss = 30217.39765595\n",
            "Iteration 16589, loss = 30215.55821965\n",
            "Iteration 16590, loss = 30215.06643942\n",
            "Iteration 16591, loss = 30215.01422206\n",
            "Iteration 16592, loss = 30213.70327811\n",
            "Iteration 16593, loss = 30212.99820044\n",
            "Iteration 16594, loss = 30211.66147986\n",
            "Iteration 16595, loss = 30209.41408930\n",
            "Iteration 16596, loss = 30209.42343854\n",
            "Iteration 16597, loss = 30208.54655916\n",
            "Iteration 16598, loss = 30207.68930466\n",
            "Iteration 16599, loss = 30206.35705253\n",
            "Iteration 16600, loss = 30205.98561220\n",
            "Iteration 16601, loss = 30204.48924348\n",
            "Iteration 16602, loss = 30202.97326008\n",
            "Iteration 16603, loss = 30202.52474257\n",
            "Iteration 16604, loss = 30201.89673518\n",
            "Iteration 16605, loss = 30199.94646428\n",
            "Iteration 16606, loss = 30197.00679797\n",
            "Iteration 16607, loss = 30197.70073384\n",
            "Iteration 16608, loss = 30197.90204739\n",
            "Iteration 16609, loss = 30196.15320241\n",
            "Iteration 16610, loss = 30193.00227305\n",
            "Iteration 16611, loss = 30192.47416223\n",
            "Iteration 16612, loss = 30193.05049005\n",
            "Iteration 16613, loss = 30191.98338040\n",
            "Iteration 16614, loss = 30190.83120371\n",
            "Iteration 16615, loss = 30189.01800994\n",
            "Iteration 16616, loss = 30186.46273950\n",
            "Iteration 16617, loss = 30187.48645918\n",
            "Iteration 16618, loss = 30187.31333633\n",
            "Iteration 16619, loss = 30185.90549864\n",
            "Iteration 16620, loss = 30183.34380955\n",
            "Iteration 16621, loss = 30181.05548906\n",
            "Iteration 16622, loss = 30180.43223253\n",
            "Iteration 16623, loss = 30179.38415797\n",
            "Iteration 16624, loss = 30178.40103918\n",
            "Iteration 16625, loss = 30177.30218631\n",
            "Iteration 16626, loss = 30175.62827280\n",
            "Iteration 16627, loss = 30174.70760938\n",
            "Iteration 16628, loss = 30174.47004198\n",
            "Iteration 16629, loss = 30173.48187109\n",
            "Iteration 16630, loss = 30172.17107968\n",
            "Iteration 16631, loss = 30171.01519503\n",
            "Iteration 16632, loss = 30169.45025798\n",
            "Iteration 16633, loss = 30168.96041671\n",
            "Iteration 16634, loss = 30168.70369510\n",
            "Iteration 16635, loss = 30167.21771547\n",
            "Iteration 16636, loss = 30165.71341946\n",
            "Iteration 16637, loss = 30164.81645663\n",
            "Iteration 16638, loss = 30164.26662641\n",
            "Iteration 16639, loss = 30162.97658515\n",
            "Iteration 16640, loss = 30162.61855997\n",
            "Iteration 16641, loss = 30161.18518988\n",
            "Iteration 16642, loss = 30159.65183040\n",
            "Iteration 16643, loss = 30157.79051691\n",
            "Iteration 16644, loss = 30158.45178297\n",
            "Iteration 16645, loss = 30157.23050401\n",
            "Iteration 16646, loss = 30155.25647245\n",
            "Iteration 16647, loss = 30154.67573613\n",
            "Iteration 16648, loss = 30154.23101135\n",
            "Iteration 16649, loss = 30153.08817399\n",
            "Iteration 16650, loss = 30151.23543550\n",
            "Iteration 16651, loss = 30150.05360647\n",
            "Iteration 16652, loss = 30149.38442585\n",
            "Iteration 16653, loss = 30147.71906278\n",
            "Iteration 16654, loss = 30146.12439872\n",
            "Iteration 16655, loss = 30145.83655035\n",
            "Iteration 16656, loss = 30144.71643770\n",
            "Iteration 16657, loss = 30143.64712457\n",
            "Iteration 16658, loss = 30142.84491671\n",
            "Iteration 16659, loss = 30141.26937566\n",
            "Iteration 16660, loss = 30140.35645678\n",
            "Iteration 16661, loss = 30139.88303997\n",
            "Iteration 16662, loss = 30138.47331887\n",
            "Iteration 16663, loss = 30137.40994081\n",
            "Iteration 16664, loss = 30136.09579718\n",
            "Iteration 16665, loss = 30135.54624374\n",
            "Iteration 16666, loss = 30134.47215240\n",
            "Iteration 16667, loss = 30132.68314559\n",
            "Iteration 16668, loss = 30131.83828311\n",
            "Iteration 16669, loss = 30131.98860237\n",
            "Iteration 16670, loss = 30129.94242482\n",
            "Iteration 16671, loss = 30129.61348856\n",
            "Iteration 16672, loss = 30129.03006411\n",
            "Iteration 16673, loss = 30127.82964298\n",
            "Iteration 16674, loss = 30126.30746688\n",
            "Iteration 16675, loss = 30125.58860540\n",
            "Iteration 16676, loss = 30124.99580541\n",
            "Iteration 16677, loss = 30123.59103865\n",
            "Iteration 16678, loss = 30122.21586287\n",
            "Iteration 16679, loss = 30121.30441577\n",
            "Iteration 16680, loss = 30120.64673202\n",
            "Iteration 16681, loss = 30119.42298758\n",
            "Iteration 16682, loss = 30118.74269988\n",
            "Iteration 16683, loss = 30118.30179915\n",
            "Iteration 16684, loss = 30117.54275769\n",
            "Iteration 16685, loss = 30116.10033554\n",
            "Iteration 16686, loss = 30114.73735553\n",
            "Iteration 16687, loss = 30113.50661119\n",
            "Iteration 16688, loss = 30112.72013939\n",
            "Iteration 16689, loss = 30112.63109345\n",
            "Iteration 16690, loss = 30111.66237238\n",
            "Iteration 16691, loss = 30109.43310046\n",
            "Iteration 16692, loss = 30108.25925869\n",
            "Iteration 16693, loss = 30108.22254233\n",
            "Iteration 16694, loss = 30106.69445282\n",
            "Iteration 16695, loss = 30105.39147743\n",
            "Iteration 16696, loss = 30104.55574940\n",
            "Iteration 16697, loss = 30103.96265109\n",
            "Iteration 16698, loss = 30101.81862453\n",
            "Iteration 16699, loss = 30101.80433390\n",
            "Iteration 16700, loss = 30101.87052357\n",
            "Iteration 16701, loss = 30100.87166153\n",
            "Iteration 16702, loss = 30098.45837027\n",
            "Iteration 16703, loss = 30096.96407417\n",
            "Iteration 16704, loss = 30096.35420757\n",
            "Iteration 16705, loss = 30094.97020631\n",
            "Iteration 16706, loss = 30094.37292658\n",
            "Iteration 16707, loss = 30093.99935027\n",
            "Iteration 16708, loss = 30092.66574031\n",
            "Iteration 16709, loss = 30092.43115016\n",
            "Iteration 16710, loss = 30090.94527858\n",
            "Iteration 16711, loss = 30089.45495150\n",
            "Iteration 16712, loss = 30088.44798987\n",
            "Iteration 16713, loss = 30088.32775839\n",
            "Iteration 16714, loss = 30087.49933859\n",
            "Iteration 16715, loss = 30086.17276041\n",
            "Iteration 16716, loss = 30084.12713212\n",
            "Iteration 16717, loss = 30083.82876122\n",
            "Iteration 16718, loss = 30082.50128834\n",
            "Iteration 16719, loss = 30081.30534908\n",
            "Iteration 16720, loss = 30080.22572369\n",
            "Iteration 16721, loss = 30079.18033550\n",
            "Iteration 16722, loss = 30077.90911151\n",
            "Iteration 16723, loss = 30076.95582703\n",
            "Iteration 16724, loss = 30076.32158404\n",
            "Iteration 16725, loss = 30074.89074129\n",
            "Iteration 16726, loss = 30074.68665245\n",
            "Iteration 16727, loss = 30073.18113609\n",
            "Iteration 16728, loss = 30072.12727974\n",
            "Iteration 16729, loss = 30071.11427520\n",
            "Iteration 16730, loss = 30069.85737976\n",
            "Iteration 16731, loss = 30069.84712743\n",
            "Iteration 16732, loss = 30068.53417457\n",
            "Iteration 16733, loss = 30067.38249608\n",
            "Iteration 16734, loss = 30067.10331989\n",
            "Iteration 16735, loss = 30065.33811762\n",
            "Iteration 16736, loss = 30064.39495374\n",
            "Iteration 16737, loss = 30064.09683346\n",
            "Iteration 16738, loss = 30063.08352381\n",
            "Iteration 16739, loss = 30061.58704333\n",
            "Iteration 16740, loss = 30060.31765879\n",
            "Iteration 16741, loss = 30060.18678584\n",
            "Iteration 16742, loss = 30058.75223535\n",
            "Iteration 16743, loss = 30058.23725357\n",
            "Iteration 16744, loss = 30057.04617651\n",
            "Iteration 16745, loss = 30055.94041170\n",
            "Iteration 16746, loss = 30055.75915053\n",
            "Iteration 16747, loss = 30054.29579368\n",
            "Iteration 16748, loss = 30053.92478113\n",
            "Iteration 16749, loss = 30052.48735763\n",
            "Iteration 16750, loss = 30051.73124245\n",
            "Iteration 16751, loss = 30050.86022957\n",
            "Iteration 16752, loss = 30048.91148893\n",
            "Iteration 16753, loss = 30048.01602934\n",
            "Iteration 16754, loss = 30047.55904608\n",
            "Iteration 16755, loss = 30047.28635462\n",
            "Iteration 16756, loss = 30045.71650067\n",
            "Iteration 16757, loss = 30043.77480033\n",
            "Iteration 16758, loss = 30042.98421743\n",
            "Iteration 16759, loss = 30042.22243798\n",
            "Iteration 16760, loss = 30041.07502487\n",
            "Iteration 16761, loss = 30040.06291010\n",
            "Iteration 16762, loss = 30039.82334410\n",
            "Iteration 16763, loss = 30038.76633743\n",
            "Iteration 16764, loss = 30037.43505816\n",
            "Iteration 16765, loss = 30036.76308718\n",
            "Iteration 16766, loss = 30035.46476954\n",
            "Iteration 16767, loss = 30034.90935363\n",
            "Iteration 16768, loss = 30033.94422373\n",
            "Iteration 16769, loss = 30032.79352208\n",
            "Iteration 16770, loss = 30031.67237342\n",
            "Iteration 16771, loss = 30030.28452344\n",
            "Iteration 16772, loss = 30030.98472199\n",
            "Iteration 16773, loss = 30030.02700938\n",
            "Iteration 16774, loss = 30028.04960315\n",
            "Iteration 16775, loss = 30027.40476444\n",
            "Iteration 16776, loss = 30027.88245214\n",
            "Iteration 16777, loss = 30027.51422943\n",
            "Iteration 16778, loss = 30025.49889999\n",
            "Iteration 16779, loss = 30023.71984358\n",
            "Iteration 16780, loss = 30023.74095534\n",
            "Iteration 16781, loss = 30023.54199307\n",
            "Iteration 16782, loss = 30022.39464572\n",
            "Iteration 16783, loss = 30020.00786345\n",
            "Iteration 16784, loss = 30020.37419623\n",
            "Iteration 16785, loss = 30020.59939097\n",
            "Iteration 16786, loss = 30019.10537923\n",
            "Iteration 16787, loss = 30017.91740029\n",
            "Iteration 16788, loss = 30016.56687614\n",
            "Iteration 16789, loss = 30014.62453225\n",
            "Iteration 16790, loss = 30014.64605933\n",
            "Iteration 16791, loss = 30014.27246418\n",
            "Iteration 16792, loss = 30014.06041356\n",
            "Iteration 16793, loss = 30012.00591470\n",
            "Iteration 16794, loss = 30010.29837804\n",
            "Iteration 16795, loss = 30009.34316719\n",
            "Iteration 16796, loss = 30008.96985831\n",
            "Iteration 16797, loss = 30007.97617319\n",
            "Iteration 16798, loss = 30005.96619025\n",
            "Iteration 16799, loss = 30005.91296075\n",
            "Iteration 16800, loss = 30006.33239327\n",
            "Iteration 16801, loss = 30004.35970175\n",
            "Iteration 16802, loss = 30002.51937681\n",
            "Iteration 16803, loss = 30002.47346718\n",
            "Iteration 16804, loss = 30001.97356441\n",
            "Iteration 16805, loss = 30000.39496067\n",
            "Iteration 16806, loss = 29999.32601931\n",
            "Iteration 16807, loss = 29998.01045135\n",
            "Iteration 16808, loss = 29996.99568344\n",
            "Iteration 16809, loss = 29995.28334981\n",
            "Iteration 16810, loss = 29995.45641153\n",
            "Iteration 16811, loss = 29995.17265062\n",
            "Iteration 16812, loss = 29993.50975245\n",
            "Iteration 16813, loss = 29992.36101658\n",
            "Iteration 16814, loss = 29991.42465725\n",
            "Iteration 16815, loss = 29990.45757076\n",
            "Iteration 16816, loss = 29989.87061095\n",
            "Iteration 16817, loss = 29989.03514103\n",
            "Iteration 16818, loss = 29987.86823511\n",
            "Iteration 16819, loss = 29987.47562905\n",
            "Iteration 16820, loss = 29986.65734079\n",
            "Iteration 16821, loss = 29985.22263658\n",
            "Iteration 16822, loss = 29983.26926853\n",
            "Iteration 16823, loss = 29983.16579074\n",
            "Iteration 16824, loss = 29982.96120699\n",
            "Iteration 16825, loss = 29981.58236738\n",
            "Iteration 16826, loss = 29980.14408862\n",
            "Iteration 16827, loss = 29979.53729176\n",
            "Iteration 16828, loss = 29978.09279379\n",
            "Iteration 16829, loss = 29977.13643534\n",
            "Iteration 16830, loss = 29977.11915461\n",
            "Iteration 16831, loss = 29976.03624472\n",
            "Iteration 16832, loss = 29975.21556647\n",
            "Iteration 16833, loss = 29974.59814110\n",
            "Iteration 16834, loss = 29973.04674662\n",
            "Iteration 16835, loss = 29972.49352226\n",
            "Iteration 16836, loss = 29971.46846020\n",
            "Iteration 16837, loss = 29970.20901504\n",
            "Iteration 16838, loss = 29968.52352939\n",
            "Iteration 16839, loss = 29969.43615893\n",
            "Iteration 16840, loss = 29967.80081650\n",
            "Iteration 16841, loss = 29966.87677414\n",
            "Iteration 16842, loss = 29966.42255797\n",
            "Iteration 16843, loss = 29965.54495124\n",
            "Iteration 16844, loss = 29964.13596590\n",
            "Iteration 16845, loss = 29962.78535204\n",
            "Iteration 16846, loss = 29963.01763436\n",
            "Iteration 16847, loss = 29962.25273299\n",
            "Iteration 16848, loss = 29960.56448967\n",
            "Iteration 16849, loss = 29959.75503154\n",
            "Iteration 16850, loss = 29959.09952910\n",
            "Iteration 16851, loss = 29957.54251342\n",
            "Iteration 16852, loss = 29956.96228582\n",
            "Iteration 16853, loss = 29957.14121433\n",
            "Iteration 16854, loss = 29956.44545438\n",
            "Iteration 16855, loss = 29954.48860486\n",
            "Iteration 16856, loss = 29953.38865707\n",
            "Iteration 16857, loss = 29953.28772452\n",
            "Iteration 16858, loss = 29952.87072023\n",
            "Iteration 16859, loss = 29951.47849866\n",
            "Iteration 16860, loss = 29949.72342978\n",
            "Iteration 16861, loss = 29948.53693246\n",
            "Iteration 16862, loss = 29948.66344383\n",
            "Iteration 16863, loss = 29947.71526948\n",
            "Iteration 16864, loss = 29947.68023081\n",
            "Iteration 16865, loss = 29946.54350917\n",
            "Iteration 16866, loss = 29944.70909619\n",
            "Iteration 16867, loss = 29944.08854079\n",
            "Iteration 16868, loss = 29943.89173674\n",
            "Iteration 16869, loss = 29942.60875546\n",
            "Iteration 16870, loss = 29941.22884401\n",
            "Iteration 16871, loss = 29940.00031293\n",
            "Iteration 16872, loss = 29940.07113618\n",
            "Iteration 16873, loss = 29939.41074434\n",
            "Iteration 16874, loss = 29939.66338425\n",
            "Iteration 16875, loss = 29938.21582421\n",
            "Iteration 16876, loss = 29937.12193204\n",
            "Iteration 16877, loss = 29936.23197646\n",
            "Iteration 16878, loss = 29934.85707896\n",
            "Iteration 16879, loss = 29934.64306237\n",
            "Iteration 16880, loss = 29934.06714114\n",
            "Iteration 16881, loss = 29932.15332724\n",
            "Iteration 16882, loss = 29929.91293288\n",
            "Iteration 16883, loss = 29930.67469066\n",
            "Iteration 16884, loss = 29930.28972813\n",
            "Iteration 16885, loss = 29929.20083534\n",
            "Iteration 16886, loss = 29928.94979715\n",
            "Iteration 16887, loss = 29927.16251908\n",
            "Iteration 16888, loss = 29925.05976773\n",
            "Iteration 16889, loss = 29925.03434016\n",
            "Iteration 16890, loss = 29925.10078398\n",
            "Iteration 16891, loss = 29923.75069797\n",
            "Iteration 16892, loss = 29921.68538352\n",
            "Iteration 16893, loss = 29921.08964984\n",
            "Iteration 16894, loss = 29920.72182056\n",
            "Iteration 16895, loss = 29919.90724047\n",
            "Iteration 16896, loss = 29919.13606500\n",
            "Iteration 16897, loss = 29917.85267046\n",
            "Iteration 16898, loss = 29916.23164376\n",
            "Iteration 16899, loss = 29915.92959097\n",
            "Iteration 16900, loss = 29914.42387838\n",
            "Iteration 16901, loss = 29913.83822108\n",
            "Iteration 16902, loss = 29913.54856805\n",
            "Iteration 16903, loss = 29912.18478073\n",
            "Iteration 16904, loss = 29911.58093426\n",
            "Iteration 16905, loss = 29910.52477490\n",
            "Iteration 16906, loss = 29909.26222985\n",
            "Iteration 16907, loss = 29908.18940457\n",
            "Iteration 16908, loss = 29906.93125295\n",
            "Iteration 16909, loss = 29907.00036782\n",
            "Iteration 16910, loss = 29905.58788097\n",
            "Iteration 16911, loss = 29905.14612133\n",
            "Iteration 16912, loss = 29904.63335237\n",
            "Iteration 16913, loss = 29903.52391455\n",
            "Iteration 16914, loss = 29902.80429648\n",
            "Iteration 16915, loss = 29902.00358517\n",
            "Iteration 16916, loss = 29901.38970204\n",
            "Iteration 16917, loss = 29900.01942807\n",
            "Iteration 16918, loss = 29899.05757476\n",
            "Iteration 16919, loss = 29898.93463828\n",
            "Iteration 16920, loss = 29897.82095685\n",
            "Iteration 16921, loss = 29896.76587672\n",
            "Iteration 16922, loss = 29895.85058861\n",
            "Iteration 16923, loss = 29894.83341008\n",
            "Iteration 16924, loss = 29893.21663351\n",
            "Iteration 16925, loss = 29893.45905608\n",
            "Iteration 16926, loss = 29892.64831389\n",
            "Iteration 16927, loss = 29891.33597712\n",
            "Iteration 16928, loss = 29890.40615356\n",
            "Iteration 16929, loss = 29889.98519728\n",
            "Iteration 16930, loss = 29889.14634368\n",
            "Iteration 16931, loss = 29887.94281923\n",
            "Iteration 16932, loss = 29886.88006823\n",
            "Iteration 16933, loss = 29887.46693353\n",
            "Iteration 16934, loss = 29887.05806235\n",
            "Iteration 16935, loss = 29885.59761139\n",
            "Iteration 16936, loss = 29883.19381439\n",
            "Iteration 16937, loss = 29883.41146893\n",
            "Iteration 16938, loss = 29883.47962325\n",
            "Iteration 16939, loss = 29881.27208681\n",
            "Iteration 16940, loss = 29880.87149652\n",
            "Iteration 16941, loss = 29880.64613883\n",
            "Iteration 16942, loss = 29879.14150919\n",
            "Iteration 16943, loss = 29878.00912367\n",
            "Iteration 16944, loss = 29878.07131026\n",
            "Iteration 16945, loss = 29877.71524069\n",
            "Iteration 16946, loss = 29875.73976579\n",
            "Iteration 16947, loss = 29875.28199537\n",
            "Iteration 16948, loss = 29875.23009090\n",
            "Iteration 16949, loss = 29874.84408624\n",
            "Iteration 16950, loss = 29872.97557776\n",
            "Iteration 16951, loss = 29871.46593787\n",
            "Iteration 16952, loss = 29871.59476064\n",
            "Iteration 16953, loss = 29871.24739456\n",
            "Iteration 16954, loss = 29869.81866302\n",
            "Iteration 16955, loss = 29867.58284026\n",
            "Iteration 16956, loss = 29868.13248763\n",
            "Iteration 16957, loss = 29867.33861572\n",
            "Iteration 16958, loss = 29866.54175481\n",
            "Iteration 16959, loss = 29864.49462500\n",
            "Iteration 16960, loss = 29864.96039954\n",
            "Iteration 16961, loss = 29865.20868697\n",
            "Iteration 16962, loss = 29864.28822928\n",
            "Iteration 16963, loss = 29862.55618891\n",
            "Iteration 16964, loss = 29862.48136918\n",
            "Iteration 16965, loss = 29861.40154200\n",
            "Iteration 16966, loss = 29859.66282075\n",
            "Iteration 16967, loss = 29858.59658488\n",
            "Iteration 16968, loss = 29857.89530925\n",
            "Iteration 16969, loss = 29856.96884777\n",
            "Iteration 16970, loss = 29856.50460531\n",
            "Iteration 16971, loss = 29856.08159237\n",
            "Iteration 16972, loss = 29854.54369009\n",
            "Iteration 16973, loss = 29853.28113174\n",
            "Iteration 16974, loss = 29853.86658371\n",
            "Iteration 16975, loss = 29852.89297458\n",
            "Iteration 16976, loss = 29852.45760663\n",
            "Iteration 16977, loss = 29851.90094129\n",
            "Iteration 16978, loss = 29850.30149994\n",
            "Iteration 16979, loss = 29850.26337927\n",
            "Iteration 16980, loss = 29849.24730155\n",
            "Iteration 16981, loss = 29847.98329255\n",
            "Iteration 16982, loss = 29846.53419353\n",
            "Iteration 16983, loss = 29845.81830248\n",
            "Iteration 16984, loss = 29845.18624716\n",
            "Iteration 16985, loss = 29844.69286715\n",
            "Iteration 16986, loss = 29843.72516927\n",
            "Iteration 16987, loss = 29843.03190729\n",
            "Iteration 16988, loss = 29841.83840124\n",
            "Iteration 16989, loss = 29841.66349327\n",
            "Iteration 16990, loss = 29840.62560821\n",
            "Iteration 16991, loss = 29839.28436155\n",
            "Iteration 16992, loss = 29838.53206822\n",
            "Iteration 16993, loss = 29838.85883694\n",
            "Iteration 16994, loss = 29838.45702746\n",
            "Iteration 16995, loss = 29837.15111063\n",
            "Iteration 16996, loss = 29837.49651225\n",
            "Iteration 16997, loss = 29836.38661305\n",
            "Iteration 16998, loss = 29835.30113254\n",
            "Iteration 16999, loss = 29833.97173342\n",
            "Iteration 17000, loss = 29833.54136938\n",
            "Iteration 17001, loss = 29832.05915398\n",
            "Iteration 17002, loss = 29830.82570908\n",
            "Iteration 17003, loss = 29831.08570279\n",
            "Iteration 17004, loss = 29830.06416935\n",
            "Iteration 17005, loss = 29827.31124204\n",
            "Iteration 17006, loss = 29828.71144107\n",
            "Iteration 17007, loss = 29828.59414065\n",
            "Iteration 17008, loss = 29826.83736338\n",
            "Iteration 17009, loss = 29825.52015737\n",
            "Iteration 17010, loss = 29824.41029347\n",
            "Iteration 17011, loss = 29824.11921467\n",
            "Iteration 17012, loss = 29823.69055151\n",
            "Iteration 17013, loss = 29821.96881034\n",
            "Iteration 17014, loss = 29821.06430388\n",
            "Iteration 17015, loss = 29821.20950017\n",
            "Iteration 17016, loss = 29819.60344319\n",
            "Iteration 17017, loss = 29817.85334665\n",
            "Iteration 17018, loss = 29817.60892042\n",
            "Iteration 17019, loss = 29816.60467084\n",
            "Iteration 17020, loss = 29815.27556597\n",
            "Iteration 17021, loss = 29815.23057099\n",
            "Iteration 17022, loss = 29814.91912757\n",
            "Iteration 17023, loss = 29813.66848903\n",
            "Iteration 17024, loss = 29812.86936051\n",
            "Iteration 17025, loss = 29812.99534642\n",
            "Iteration 17026, loss = 29812.14154123\n",
            "Iteration 17027, loss = 29810.51181045\n",
            "Iteration 17028, loss = 29810.27903837\n",
            "Iteration 17029, loss = 29809.89939689\n",
            "Iteration 17030, loss = 29808.67325945\n",
            "Iteration 17031, loss = 29806.90857159\n",
            "Iteration 17032, loss = 29806.74796114\n",
            "Iteration 17033, loss = 29806.26109749\n",
            "Iteration 17034, loss = 29804.99849917\n",
            "Iteration 17035, loss = 29803.90034190\n",
            "Iteration 17036, loss = 29803.95600177\n",
            "Iteration 17037, loss = 29802.61686291\n",
            "Iteration 17038, loss = 29801.88235312\n",
            "Iteration 17039, loss = 29801.56130809\n",
            "Iteration 17040, loss = 29800.71548028\n",
            "Iteration 17041, loss = 29800.97986063\n",
            "Iteration 17042, loss = 29800.12126099\n",
            "Iteration 17043, loss = 29798.70032774\n",
            "Iteration 17044, loss = 29797.89799150\n",
            "Iteration 17045, loss = 29797.35738802\n",
            "Iteration 17046, loss = 29795.94754589\n",
            "Iteration 17047, loss = 29794.83319883\n",
            "Iteration 17048, loss = 29795.95716984\n",
            "Iteration 17049, loss = 29795.79392091\n",
            "Iteration 17050, loss = 29794.97344147\n",
            "Iteration 17051, loss = 29792.31488491\n",
            "Iteration 17052, loss = 29790.98075182\n",
            "Iteration 17053, loss = 29791.24631097\n",
            "Iteration 17054, loss = 29791.05000562\n",
            "Iteration 17055, loss = 29789.75112004\n",
            "Iteration 17056, loss = 29788.49570686\n",
            "Iteration 17057, loss = 29788.13656431\n",
            "Iteration 17058, loss = 29786.61556284\n",
            "Iteration 17059, loss = 29785.73272439\n",
            "Iteration 17060, loss = 29784.70531491\n",
            "Iteration 17061, loss = 29784.49876645\n",
            "Iteration 17062, loss = 29783.01431759\n",
            "Iteration 17063, loss = 29782.55839472\n",
            "Iteration 17064, loss = 29782.60548137\n",
            "Iteration 17065, loss = 29781.71214344\n",
            "Iteration 17066, loss = 29780.89920406\n",
            "Iteration 17067, loss = 29780.06540194\n",
            "Iteration 17068, loss = 29780.23309053\n",
            "Iteration 17069, loss = 29778.96691571\n",
            "Iteration 17070, loss = 29778.63079989\n",
            "Iteration 17071, loss = 29777.30506538\n",
            "Iteration 17072, loss = 29776.13884088\n",
            "Iteration 17073, loss = 29776.18701277\n",
            "Iteration 17074, loss = 29775.71442687\n",
            "Iteration 17075, loss = 29774.64905317\n",
            "Iteration 17076, loss = 29773.41839053\n",
            "Iteration 17077, loss = 29772.30502130\n",
            "Iteration 17078, loss = 29771.45302130\n",
            "Iteration 17079, loss = 29771.10769754\n",
            "Iteration 17080, loss = 29770.57746382\n",
            "Iteration 17081, loss = 29769.05727328\n",
            "Iteration 17082, loss = 29769.27766152\n",
            "Iteration 17083, loss = 29768.91239892\n",
            "Iteration 17084, loss = 29767.16375888\n",
            "Iteration 17085, loss = 29767.24240755\n",
            "Iteration 17086, loss = 29766.58592398\n",
            "Iteration 17087, loss = 29766.27532217\n",
            "Iteration 17088, loss = 29765.11165779\n",
            "Iteration 17089, loss = 29763.95652305\n",
            "Iteration 17090, loss = 29762.40374117\n",
            "Iteration 17091, loss = 29762.37654574\n",
            "Iteration 17092, loss = 29760.96114020\n",
            "Iteration 17093, loss = 29760.25828104\n",
            "Iteration 17094, loss = 29760.17149154\n",
            "Iteration 17095, loss = 29759.31817232\n",
            "Iteration 17096, loss = 29758.28240458\n",
            "Iteration 17097, loss = 29757.11208210\n",
            "Iteration 17098, loss = 29756.71248462\n",
            "Iteration 17099, loss = 29755.28217356\n",
            "Iteration 17100, loss = 29754.77108831\n",
            "Iteration 17101, loss = 29754.76655969\n",
            "Iteration 17102, loss = 29753.40379012\n",
            "Iteration 17103, loss = 29752.57123755\n",
            "Iteration 17104, loss = 29752.74320061\n",
            "Iteration 17105, loss = 29751.87452402\n",
            "Iteration 17106, loss = 29750.19133956\n",
            "Iteration 17107, loss = 29751.06168336\n",
            "Iteration 17108, loss = 29750.65197393\n",
            "Iteration 17109, loss = 29748.73830573\n",
            "Iteration 17110, loss = 29748.60499246\n",
            "Iteration 17111, loss = 29748.28801074\n",
            "Iteration 17112, loss = 29747.32940837\n",
            "Iteration 17113, loss = 29746.59433715\n",
            "Iteration 17114, loss = 29744.79190853\n",
            "Iteration 17115, loss = 29744.13151672\n",
            "Iteration 17116, loss = 29744.76051416\n",
            "Iteration 17117, loss = 29743.51939963\n",
            "Iteration 17118, loss = 29741.69459156\n",
            "Iteration 17119, loss = 29742.14740482\n",
            "Iteration 17120, loss = 29741.60894852\n",
            "Iteration 17121, loss = 29740.56324628\n",
            "Iteration 17122, loss = 29739.97981469\n",
            "Iteration 17123, loss = 29738.84660129\n",
            "Iteration 17124, loss = 29736.77038496\n",
            "Iteration 17125, loss = 29736.51914707\n",
            "Iteration 17126, loss = 29735.70627113\n",
            "Iteration 17127, loss = 29735.26423186\n",
            "Iteration 17128, loss = 29735.15550151\n",
            "Iteration 17129, loss = 29734.42263970\n",
            "Iteration 17130, loss = 29733.36404069\n",
            "Iteration 17131, loss = 29731.71440867\n",
            "Iteration 17132, loss = 29732.72818913\n",
            "Iteration 17133, loss = 29731.86853100\n",
            "Iteration 17134, loss = 29730.19490738\n",
            "Iteration 17135, loss = 29730.11414650\n",
            "Iteration 17136, loss = 29730.09508333\n",
            "Iteration 17137, loss = 29729.07958743\n",
            "Iteration 17138, loss = 29728.61444101\n",
            "Iteration 17139, loss = 29726.61494319\n",
            "Iteration 17140, loss = 29726.35713926\n",
            "Iteration 17141, loss = 29726.41758793\n",
            "Iteration 17142, loss = 29725.09193852\n",
            "Iteration 17143, loss = 29723.94333290\n",
            "Iteration 17144, loss = 29723.73180708\n",
            "Iteration 17145, loss = 29722.90863545\n",
            "Iteration 17146, loss = 29722.16205805\n",
            "Iteration 17147, loss = 29721.19112901\n",
            "Iteration 17148, loss = 29720.35335436\n",
            "Iteration 17149, loss = 29719.38009084\n",
            "Iteration 17150, loss = 29719.06430565\n",
            "Iteration 17151, loss = 29718.43556537\n",
            "Iteration 17152, loss = 29717.06677280\n",
            "Iteration 17153, loss = 29716.18839686\n",
            "Iteration 17154, loss = 29716.13868988\n",
            "Iteration 17155, loss = 29715.54905480\n",
            "Iteration 17156, loss = 29714.63381266\n",
            "Iteration 17157, loss = 29714.52029679\n",
            "Iteration 17158, loss = 29713.23573848\n",
            "Iteration 17159, loss = 29712.07303304\n",
            "Iteration 17160, loss = 29711.35783725\n",
            "Iteration 17161, loss = 29711.23882090\n",
            "Iteration 17162, loss = 29709.84392159\n",
            "Iteration 17163, loss = 29709.70322836\n",
            "Iteration 17164, loss = 29709.03611120\n",
            "Iteration 17165, loss = 29708.33392162\n",
            "Iteration 17166, loss = 29707.36854532\n",
            "Iteration 17167, loss = 29707.30178228\n",
            "Iteration 17168, loss = 29706.60101045\n",
            "Iteration 17169, loss = 29705.15413487\n",
            "Iteration 17170, loss = 29704.53381290\n",
            "Iteration 17171, loss = 29703.54519436\n",
            "Iteration 17172, loss = 29703.09035467\n",
            "Iteration 17173, loss = 29702.19694929\n",
            "Iteration 17174, loss = 29702.02596294\n",
            "Iteration 17175, loss = 29701.10573008\n",
            "Iteration 17176, loss = 29700.60073323\n",
            "Iteration 17177, loss = 29700.41039203\n",
            "Iteration 17178, loss = 29700.42529853\n",
            "Iteration 17179, loss = 29699.10925852\n",
            "Iteration 17180, loss = 29698.21627384\n",
            "Iteration 17181, loss = 29699.11578669\n",
            "Iteration 17182, loss = 29698.34033941\n",
            "Iteration 17183, loss = 29697.27001176\n",
            "Iteration 17184, loss = 29696.34528229\n",
            "Iteration 17185, loss = 29695.53691654\n",
            "Iteration 17186, loss = 29694.76937716\n",
            "Iteration 17187, loss = 29692.58469848\n",
            "Iteration 17188, loss = 29693.89650755\n",
            "Iteration 17189, loss = 29693.98363856\n",
            "Iteration 17190, loss = 29692.38507883\n",
            "Iteration 17191, loss = 29689.81934828\n",
            "Iteration 17192, loss = 29691.10401419\n",
            "Iteration 17193, loss = 29691.26991721\n",
            "Iteration 17194, loss = 29690.44737891\n",
            "Iteration 17195, loss = 29690.24412002\n",
            "Iteration 17196, loss = 29689.10633486\n",
            "Iteration 17197, loss = 29687.43520663\n",
            "Iteration 17198, loss = 29685.75967096\n",
            "Iteration 17199, loss = 29687.27191217\n",
            "Iteration 17200, loss = 29688.06787643\n",
            "Iteration 17201, loss = 29687.95707973\n",
            "Iteration 17202, loss = 29685.87711086\n",
            "Iteration 17203, loss = 29683.44185267\n",
            "Iteration 17204, loss = 29684.22893445\n",
            "Iteration 17205, loss = 29684.44276294\n",
            "Iteration 17206, loss = 29684.42727147\n",
            "Iteration 17207, loss = 29683.58857581\n",
            "Iteration 17208, loss = 29682.04264883\n",
            "Iteration 17209, loss = 29680.46210756\n",
            "Iteration 17210, loss = 29679.34182016\n",
            "Iteration 17211, loss = 29677.01171182\n",
            "Iteration 17212, loss = 29676.93247277\n",
            "Iteration 17213, loss = 29676.89543621\n",
            "Iteration 17214, loss = 29676.20104123\n",
            "Iteration 17215, loss = 29675.30486075\n",
            "Iteration 17216, loss = 29674.16542005\n",
            "Iteration 17217, loss = 29673.58228314\n",
            "Iteration 17218, loss = 29672.42798417\n",
            "Iteration 17219, loss = 29672.48700042\n",
            "Iteration 17220, loss = 29671.80060281\n",
            "Iteration 17221, loss = 29670.18471571\n",
            "Iteration 17222, loss = 29669.33698761\n",
            "Iteration 17223, loss = 29669.89607499\n",
            "Iteration 17224, loss = 29669.55759278\n",
            "Iteration 17225, loss = 29667.85068466\n",
            "Iteration 17226, loss = 29667.46618558\n",
            "Iteration 17227, loss = 29667.38454469\n",
            "Iteration 17228, loss = 29666.52776789\n",
            "Iteration 17229, loss = 29665.64245942\n",
            "Iteration 17230, loss = 29664.23600375\n",
            "Iteration 17231, loss = 29663.88922651\n",
            "Iteration 17232, loss = 29664.25290658\n",
            "Iteration 17233, loss = 29663.16860822\n",
            "Iteration 17234, loss = 29661.12557806\n",
            "Iteration 17235, loss = 29660.93823431\n",
            "Iteration 17236, loss = 29660.00642342\n",
            "Iteration 17237, loss = 29659.61218551\n",
            "Iteration 17238, loss = 29659.34097402\n",
            "Iteration 17239, loss = 29658.87158968\n",
            "Iteration 17240, loss = 29657.24465363\n",
            "Iteration 17241, loss = 29657.08992786\n",
            "Iteration 17242, loss = 29657.26880133\n",
            "Iteration 17243, loss = 29656.77066164\n",
            "Iteration 17244, loss = 29655.87491751\n",
            "Iteration 17245, loss = 29654.14790278\n",
            "Iteration 17246, loss = 29653.86675162\n",
            "Iteration 17247, loss = 29653.74333076\n",
            "Iteration 17248, loss = 29652.23398125\n",
            "Iteration 17249, loss = 29651.51000967\n",
            "Iteration 17250, loss = 29651.93637134\n",
            "Iteration 17251, loss = 29651.73441329\n",
            "Iteration 17252, loss = 29650.17797917\n",
            "Iteration 17253, loss = 29648.36596321\n",
            "Iteration 17254, loss = 29647.99432458\n",
            "Iteration 17255, loss = 29647.92395167\n",
            "Iteration 17256, loss = 29646.84030085\n",
            "Iteration 17257, loss = 29646.24884707\n",
            "Iteration 17258, loss = 29645.96011712\n",
            "Iteration 17259, loss = 29645.05803138\n",
            "Iteration 17260, loss = 29644.66798326\n",
            "Iteration 17261, loss = 29644.31580216\n",
            "Iteration 17262, loss = 29644.30464519\n",
            "Iteration 17263, loss = 29643.49700941\n",
            "Iteration 17264, loss = 29641.49406237\n",
            "Iteration 17265, loss = 29641.91809870\n",
            "Iteration 17266, loss = 29642.35338012\n",
            "Iteration 17267, loss = 29641.19213217\n",
            "Iteration 17268, loss = 29639.24142898\n",
            "Iteration 17269, loss = 29638.87053692\n",
            "Iteration 17270, loss = 29639.94436925\n",
            "Iteration 17271, loss = 29640.17383767\n",
            "Iteration 17272, loss = 29638.91787417\n",
            "Iteration 17273, loss = 29636.38339124\n",
            "Iteration 17274, loss = 29635.38731601\n",
            "Iteration 17275, loss = 29635.68671640\n",
            "Iteration 17276, loss = 29635.73565240\n",
            "Iteration 17277, loss = 29634.60496353\n",
            "Iteration 17278, loss = 29633.38980762\n",
            "Iteration 17279, loss = 29631.89429984\n",
            "Iteration 17280, loss = 29632.19225226\n",
            "Iteration 17281, loss = 29632.25407815\n",
            "Iteration 17282, loss = 29631.02243463\n",
            "Iteration 17283, loss = 29629.12767214\n",
            "Iteration 17284, loss = 29629.53788415\n",
            "Iteration 17285, loss = 29629.34356023\n",
            "Iteration 17286, loss = 29628.12121091\n",
            "Iteration 17287, loss = 29627.72229194\n",
            "Iteration 17288, loss = 29627.35568801\n",
            "Iteration 17289, loss = 29626.77643022\n",
            "Iteration 17290, loss = 29625.72752940\n",
            "Iteration 17291, loss = 29624.37752052\n",
            "Iteration 17292, loss = 29624.94937112\n",
            "Iteration 17293, loss = 29624.34268771\n",
            "Iteration 17294, loss = 29623.32357360\n",
            "Iteration 17295, loss = 29621.92368743\n",
            "Iteration 17296, loss = 29621.54322748\n",
            "Iteration 17297, loss = 29620.72159883\n",
            "Iteration 17298, loss = 29620.23609441\n",
            "Iteration 17299, loss = 29619.26396791\n",
            "Iteration 17300, loss = 29618.68332465\n",
            "Iteration 17301, loss = 29617.92060239\n",
            "Iteration 17302, loss = 29617.36219985\n",
            "Iteration 17303, loss = 29616.50996540\n",
            "Iteration 17304, loss = 29617.07369756\n",
            "Iteration 17305, loss = 29616.04336928\n",
            "Iteration 17306, loss = 29614.76265206\n",
            "Iteration 17307, loss = 29614.08373710\n",
            "Iteration 17308, loss = 29613.34234926\n",
            "Iteration 17309, loss = 29613.21035345\n",
            "Iteration 17310, loss = 29612.45540833\n",
            "Iteration 17311, loss = 29611.27024240\n",
            "Iteration 17312, loss = 29610.91333165\n",
            "Iteration 17313, loss = 29610.45268624\n",
            "Iteration 17314, loss = 29610.14141834\n",
            "Iteration 17315, loss = 29608.84164613\n",
            "Iteration 17316, loss = 29608.50031642\n",
            "Iteration 17317, loss = 29607.86133548\n",
            "Iteration 17318, loss = 29607.29570186\n",
            "Iteration 17319, loss = 29605.97175045\n",
            "Iteration 17320, loss = 29605.62324493\n",
            "Iteration 17321, loss = 29605.30629891\n",
            "Iteration 17322, loss = 29604.21694736\n",
            "Iteration 17323, loss = 29603.82996666\n",
            "Iteration 17324, loss = 29603.60173449\n",
            "Iteration 17325, loss = 29603.32707271\n",
            "Iteration 17326, loss = 29602.09962711\n",
            "Iteration 17327, loss = 29601.99212522\n",
            "Iteration 17328, loss = 29601.17958058\n",
            "Iteration 17329, loss = 29600.86270322\n",
            "Iteration 17330, loss = 29600.34090501\n",
            "Iteration 17331, loss = 29599.25468788\n",
            "Iteration 17332, loss = 29599.34572048\n",
            "Iteration 17333, loss = 29598.91492620\n",
            "Iteration 17334, loss = 29597.55638876\n",
            "Iteration 17335, loss = 29598.20434314\n",
            "Iteration 17336, loss = 29597.67879622\n",
            "Iteration 17337, loss = 29596.34975617\n",
            "Iteration 17338, loss = 29594.97330322\n",
            "Iteration 17339, loss = 29594.99221683\n",
            "Iteration 17340, loss = 29594.87820045\n",
            "Iteration 17341, loss = 29594.13573745\n",
            "Iteration 17342, loss = 29592.20899279\n",
            "Iteration 17343, loss = 29593.55110837\n",
            "Iteration 17344, loss = 29593.59858286\n",
            "Iteration 17345, loss = 29592.97897935\n",
            "Iteration 17346, loss = 29592.04620196\n",
            "Iteration 17347, loss = 29590.93988925\n",
            "Iteration 17348, loss = 29590.72395405\n",
            "Iteration 17349, loss = 29590.24264394\n",
            "Iteration 17350, loss = 29588.30959296\n",
            "Iteration 17351, loss = 29588.58888613\n",
            "Iteration 17352, loss = 29588.34612459\n",
            "Iteration 17353, loss = 29588.06961529\n",
            "Iteration 17354, loss = 29586.19635853\n",
            "Iteration 17355, loss = 29585.85611136\n",
            "Iteration 17356, loss = 29584.51705634\n",
            "Iteration 17357, loss = 29584.69099757\n",
            "Iteration 17358, loss = 29585.06773844\n",
            "Iteration 17359, loss = 29584.08596406\n",
            "Iteration 17360, loss = 29582.86698638\n",
            "Iteration 17361, loss = 29582.47002785\n",
            "Iteration 17362, loss = 29581.12303713\n",
            "Iteration 17363, loss = 29581.33104952\n",
            "Iteration 17364, loss = 29580.69023369\n",
            "Iteration 17365, loss = 29579.33160213\n",
            "Iteration 17366, loss = 29579.30437676\n",
            "Iteration 17367, loss = 29578.50769092\n",
            "Iteration 17368, loss = 29578.04695793\n",
            "Iteration 17369, loss = 29577.01705289\n",
            "Iteration 17370, loss = 29576.80276576\n",
            "Iteration 17371, loss = 29576.29313140\n",
            "Iteration 17372, loss = 29575.76868475\n",
            "Iteration 17373, loss = 29574.46031351\n",
            "Iteration 17374, loss = 29574.49554519\n",
            "Iteration 17375, loss = 29574.30800309\n",
            "Iteration 17376, loss = 29573.84530237\n",
            "Iteration 17377, loss = 29572.94138931\n",
            "Iteration 17378, loss = 29572.00917492\n",
            "Iteration 17379, loss = 29571.03180939\n",
            "Iteration 17380, loss = 29570.66965912\n",
            "Iteration 17381, loss = 29569.21951422\n",
            "Iteration 17382, loss = 29568.76153026\n",
            "Iteration 17383, loss = 29568.81996268\n",
            "Iteration 17384, loss = 29568.24759302\n",
            "Iteration 17385, loss = 29566.96547616\n",
            "Iteration 17386, loss = 29566.62743929\n",
            "Iteration 17387, loss = 29566.16218116\n",
            "Iteration 17388, loss = 29565.13844591\n",
            "Iteration 17389, loss = 29564.30602832\n",
            "Iteration 17390, loss = 29563.80190210\n",
            "Iteration 17391, loss = 29564.66022871\n",
            "Iteration 17392, loss = 29564.11622731\n",
            "Iteration 17393, loss = 29562.62733124\n",
            "Iteration 17394, loss = 29562.32077208\n",
            "Iteration 17395, loss = 29561.95319858\n",
            "Iteration 17396, loss = 29561.40994481\n",
            "Iteration 17397, loss = 29560.97448830\n",
            "Iteration 17398, loss = 29559.28535061\n",
            "Iteration 17399, loss = 29559.61707027\n",
            "Iteration 17400, loss = 29559.27023584\n",
            "Iteration 17401, loss = 29558.14933875\n",
            "Iteration 17402, loss = 29557.20620002\n",
            "Iteration 17403, loss = 29556.40216906\n",
            "Iteration 17404, loss = 29555.58307996\n",
            "Iteration 17405, loss = 29555.30297593\n",
            "Iteration 17406, loss = 29554.89041867\n",
            "Iteration 17407, loss = 29554.66473904\n",
            "Iteration 17408, loss = 29554.13505263\n",
            "Iteration 17409, loss = 29553.20502706\n",
            "Iteration 17410, loss = 29552.69232045\n",
            "Iteration 17411, loss = 29552.53907373\n",
            "Iteration 17412, loss = 29551.38909532\n",
            "Iteration 17413, loss = 29550.87007367\n",
            "Iteration 17414, loss = 29551.16328794\n",
            "Iteration 17415, loss = 29550.22611520\n",
            "Iteration 17416, loss = 29549.14847934\n",
            "Iteration 17417, loss = 29548.53692748\n",
            "Iteration 17418, loss = 29548.45812919\n",
            "Iteration 17419, loss = 29548.17986293\n",
            "Iteration 17420, loss = 29547.16678895\n",
            "Iteration 17421, loss = 29546.30254315\n",
            "Iteration 17422, loss = 29545.91044955\n",
            "Iteration 17423, loss = 29545.96806738\n",
            "Iteration 17424, loss = 29545.13228456\n",
            "Iteration 17425, loss = 29543.83599750\n",
            "Iteration 17426, loss = 29542.70479896\n",
            "Iteration 17427, loss = 29543.18435526\n",
            "Iteration 17428, loss = 29543.08565533\n",
            "Iteration 17429, loss = 29541.45114504\n",
            "Iteration 17430, loss = 29540.50304116\n",
            "Iteration 17431, loss = 29540.85411506\n",
            "Iteration 17432, loss = 29540.79321316\n",
            "Iteration 17433, loss = 29539.82507842\n",
            "Iteration 17434, loss = 29538.96387912\n",
            "Iteration 17435, loss = 29538.45258033\n",
            "Iteration 17436, loss = 29538.96808098\n",
            "Iteration 17437, loss = 29537.75653624\n",
            "Iteration 17438, loss = 29536.33405672\n",
            "Iteration 17439, loss = 29535.64885179\n",
            "Iteration 17440, loss = 29535.38169506\n",
            "Iteration 17441, loss = 29535.04910840\n",
            "Iteration 17442, loss = 29534.04013184\n",
            "Iteration 17443, loss = 29532.60378928\n",
            "Iteration 17444, loss = 29533.69212803\n",
            "Iteration 17445, loss = 29533.44442205\n",
            "Iteration 17446, loss = 29531.93210734\n",
            "Iteration 17447, loss = 29530.40374684\n",
            "Iteration 17448, loss = 29530.44586471\n",
            "Iteration 17449, loss = 29529.76423341\n",
            "Iteration 17450, loss = 29528.88119547\n",
            "Iteration 17451, loss = 29528.89501436\n",
            "Iteration 17452, loss = 29528.32781059\n",
            "Iteration 17453, loss = 29527.39870013\n",
            "Iteration 17454, loss = 29527.01513668\n",
            "Iteration 17455, loss = 29526.02235895\n",
            "Iteration 17456, loss = 29525.70301006\n",
            "Iteration 17457, loss = 29525.63902417\n",
            "Iteration 17458, loss = 29525.29555263\n",
            "Iteration 17459, loss = 29524.25583782\n",
            "Iteration 17460, loss = 29522.88301261\n",
            "Iteration 17461, loss = 29523.19619976\n",
            "Iteration 17462, loss = 29522.35020471\n",
            "Iteration 17463, loss = 29521.12783498\n",
            "Iteration 17464, loss = 29521.62246393\n",
            "Iteration 17465, loss = 29521.58804230\n",
            "Iteration 17466, loss = 29519.80719156\n",
            "Iteration 17467, loss = 29520.45989822\n",
            "Iteration 17468, loss = 29520.49087254\n",
            "Iteration 17469, loss = 29520.60998915\n",
            "Iteration 17470, loss = 29519.88989898\n",
            "Iteration 17471, loss = 29518.41146137\n",
            "Iteration 17472, loss = 29517.18507616\n",
            "Iteration 17473, loss = 29517.95008299\n",
            "Iteration 17474, loss = 29517.83323193\n",
            "Iteration 17475, loss = 29517.36956405\n",
            "Iteration 17476, loss = 29516.20486750\n",
            "Iteration 17477, loss = 29515.60542126\n",
            "Iteration 17478, loss = 29515.33346223\n",
            "Iteration 17479, loss = 29514.95686372\n",
            "Iteration 17480, loss = 29514.95296464\n",
            "Iteration 17481, loss = 29514.38407789\n",
            "Iteration 17482, loss = 29512.38814055\n",
            "Iteration 17483, loss = 29511.53618298\n",
            "Iteration 17484, loss = 29511.71326344\n",
            "Iteration 17485, loss = 29510.80470022\n",
            "Iteration 17486, loss = 29509.24198465\n",
            "Iteration 17487, loss = 29508.87692626\n",
            "Iteration 17488, loss = 29508.45742175\n",
            "Iteration 17489, loss = 29507.56757155\n",
            "Iteration 17490, loss = 29507.82755526\n",
            "Iteration 17491, loss = 29507.10092145\n",
            "Iteration 17492, loss = 29505.64014540\n",
            "Iteration 17493, loss = 29506.03966487\n",
            "Iteration 17494, loss = 29506.47934014\n",
            "Iteration 17495, loss = 29506.38655460\n",
            "Iteration 17496, loss = 29505.43889178\n",
            "Iteration 17497, loss = 29503.90937108\n",
            "Iteration 17498, loss = 29502.90256766\n",
            "Iteration 17499, loss = 29504.07690821\n",
            "Iteration 17500, loss = 29503.84035507\n",
            "Iteration 17501, loss = 29503.18333751\n",
            "Iteration 17502, loss = 29501.29286894\n",
            "Iteration 17503, loss = 29500.67214943\n",
            "Iteration 17504, loss = 29500.72682810\n",
            "Iteration 17505, loss = 29500.75051433\n",
            "Iteration 17506, loss = 29500.27026103\n",
            "Iteration 17507, loss = 29498.91207097\n",
            "Iteration 17508, loss = 29497.66377070\n",
            "Iteration 17509, loss = 29498.14951731\n",
            "Iteration 17510, loss = 29498.34749030\n",
            "Iteration 17511, loss = 29497.32752416\n",
            "Iteration 17512, loss = 29495.20685808\n",
            "Iteration 17513, loss = 29495.89294498\n",
            "Iteration 17514, loss = 29495.51714604\n",
            "Iteration 17515, loss = 29494.73201936\n",
            "Iteration 17516, loss = 29494.19361539\n",
            "Iteration 17517, loss = 29494.32118424\n",
            "Iteration 17518, loss = 29493.28531011\n",
            "Iteration 17519, loss = 29493.10887465\n",
            "Iteration 17520, loss = 29493.10961246\n",
            "Iteration 17521, loss = 29492.57075404\n",
            "Iteration 17522, loss = 29491.41846966\n",
            "Iteration 17523, loss = 29490.71033891\n",
            "Iteration 17524, loss = 29488.74055938\n",
            "Iteration 17525, loss = 29490.00229000\n",
            "Iteration 17526, loss = 29490.35783889\n",
            "Iteration 17527, loss = 29489.18512802\n",
            "Iteration 17528, loss = 29487.40680272\n",
            "Iteration 17529, loss = 29486.75128278\n",
            "Iteration 17530, loss = 29487.32696904\n",
            "Iteration 17531, loss = 29486.98161231\n",
            "Iteration 17532, loss = 29486.29672191\n",
            "Iteration 17533, loss = 29485.70307110\n",
            "Iteration 17534, loss = 29484.46451522\n",
            "Iteration 17535, loss = 29483.65797857\n",
            "Iteration 17536, loss = 29484.32945305\n",
            "Iteration 17537, loss = 29483.33823875\n",
            "Iteration 17538, loss = 29481.41182285\n",
            "Iteration 17539, loss = 29481.71318571\n",
            "Iteration 17540, loss = 29481.37173552\n",
            "Iteration 17541, loss = 29480.77753479\n",
            "Iteration 17542, loss = 29479.65777547\n",
            "Iteration 17543, loss = 29479.27414820\n",
            "Iteration 17544, loss = 29479.16770273\n",
            "Iteration 17545, loss = 29478.91401017\n",
            "Iteration 17546, loss = 29477.65187331\n",
            "Iteration 17547, loss = 29477.62181349\n",
            "Iteration 17548, loss = 29477.80014154\n",
            "Iteration 17549, loss = 29476.73644562\n",
            "Iteration 17550, loss = 29475.48727159\n",
            "Iteration 17551, loss = 29474.49924061\n",
            "Iteration 17552, loss = 29474.20578115\n",
            "Iteration 17553, loss = 29474.12941898\n",
            "Iteration 17554, loss = 29473.79352288\n",
            "Iteration 17555, loss = 29473.34355426\n",
            "Iteration 17556, loss = 29472.76793699\n",
            "Iteration 17557, loss = 29471.70267589\n",
            "Iteration 17558, loss = 29472.51843694\n",
            "Iteration 17559, loss = 29471.98594901\n",
            "Iteration 17560, loss = 29470.63653130\n",
            "Iteration 17561, loss = 29469.92025268\n",
            "Iteration 17562, loss = 29469.75180329\n",
            "Iteration 17563, loss = 29469.53981221\n",
            "Iteration 17564, loss = 29468.36045984\n",
            "Iteration 17565, loss = 29467.76524458\n",
            "Iteration 17566, loss = 29467.94104135\n",
            "Iteration 17567, loss = 29467.28039527\n",
            "Iteration 17568, loss = 29466.82130455\n",
            "Iteration 17569, loss = 29466.69167709\n",
            "Iteration 17570, loss = 29466.54906336\n",
            "Iteration 17571, loss = 29466.14287298\n",
            "Iteration 17572, loss = 29464.43166837\n",
            "Iteration 17573, loss = 29463.18911209\n",
            "Iteration 17574, loss = 29464.57333152\n",
            "Iteration 17575, loss = 29464.09005182\n",
            "Iteration 17576, loss = 29462.45383304\n",
            "Iteration 17577, loss = 29461.42649476\n",
            "Iteration 17578, loss = 29461.42565337\n",
            "Iteration 17579, loss = 29461.11117252\n",
            "Iteration 17580, loss = 29460.19536564\n",
            "Iteration 17581, loss = 29459.19224981\n",
            "Iteration 17582, loss = 29458.73416245\n",
            "Iteration 17583, loss = 29458.25814618\n",
            "Iteration 17584, loss = 29457.88751073\n",
            "Iteration 17585, loss = 29456.84664620\n",
            "Iteration 17586, loss = 29457.02445623\n",
            "Iteration 17587, loss = 29456.58857596\n",
            "Iteration 17588, loss = 29456.22573873\n",
            "Iteration 17589, loss = 29455.86169117\n",
            "Iteration 17590, loss = 29455.48937604\n",
            "Iteration 17591, loss = 29453.64070167\n",
            "Iteration 17592, loss = 29454.17432398\n",
            "Iteration 17593, loss = 29454.05891700\n",
            "Iteration 17594, loss = 29452.40644518\n",
            "Iteration 17595, loss = 29452.17469229\n",
            "Iteration 17596, loss = 29452.48742692\n",
            "Iteration 17597, loss = 29452.06805093\n",
            "Iteration 17598, loss = 29451.34100301\n",
            "Iteration 17599, loss = 29449.82426631\n",
            "Iteration 17600, loss = 29450.30229157\n",
            "Iteration 17601, loss = 29449.82026438\n",
            "Iteration 17602, loss = 29448.60791104\n",
            "Iteration 17603, loss = 29448.80975582\n",
            "Iteration 17604, loss = 29448.66289719\n",
            "Iteration 17605, loss = 29448.58731930\n",
            "Iteration 17606, loss = 29447.67462525\n",
            "Iteration 17607, loss = 29446.70366602\n",
            "Iteration 17608, loss = 29446.99237987\n",
            "Iteration 17609, loss = 29447.75580139\n",
            "Iteration 17610, loss = 29446.87414144\n",
            "Iteration 17611, loss = 29444.28201321\n",
            "Iteration 17612, loss = 29444.25808082\n",
            "Iteration 17613, loss = 29443.80938319\n",
            "Iteration 17614, loss = 29442.78445359\n",
            "Iteration 17615, loss = 29442.46857702\n",
            "Iteration 17616, loss = 29441.68916947\n",
            "Iteration 17617, loss = 29442.12887050\n",
            "Iteration 17618, loss = 29441.89874870\n",
            "Iteration 17619, loss = 29440.55136273\n",
            "Iteration 17620, loss = 29439.89673038\n",
            "Iteration 17621, loss = 29439.84067881\n",
            "Iteration 17622, loss = 29439.58024972\n",
            "Iteration 17623, loss = 29439.63526565\n",
            "Iteration 17624, loss = 29438.39012841\n",
            "Iteration 17625, loss = 29437.42639589\n",
            "Iteration 17626, loss = 29437.90935271\n",
            "Iteration 17627, loss = 29437.34321968\n",
            "Iteration 17628, loss = 29436.81360443\n",
            "Iteration 17629, loss = 29436.85235312\n",
            "Iteration 17630, loss = 29436.41054905\n",
            "Iteration 17631, loss = 29435.77608764\n",
            "Iteration 17632, loss = 29435.20097302\n",
            "Iteration 17633, loss = 29435.37228144\n",
            "Iteration 17634, loss = 29434.88687260\n",
            "Iteration 17635, loss = 29433.90734471\n",
            "Iteration 17636, loss = 29432.33655296\n",
            "Iteration 17637, loss = 29432.69899878\n",
            "Iteration 17638, loss = 29432.38094712\n",
            "Iteration 17639, loss = 29431.82948463\n",
            "Iteration 17640, loss = 29430.92142175\n",
            "Iteration 17641, loss = 29429.78415379\n",
            "Iteration 17642, loss = 29430.19926446\n",
            "Iteration 17643, loss = 29429.89357778\n",
            "Iteration 17644, loss = 29429.95968505\n",
            "Iteration 17645, loss = 29428.32441895\n",
            "Iteration 17646, loss = 29427.51664206\n",
            "Iteration 17647, loss = 29427.46818506\n",
            "Iteration 17648, loss = 29426.73807840\n",
            "Iteration 17649, loss = 29426.19179599\n",
            "Iteration 17650, loss = 29425.54370966\n",
            "Iteration 17651, loss = 29425.11449501\n",
            "Iteration 17652, loss = 29424.74684011\n",
            "Iteration 17653, loss = 29424.21381110\n",
            "Iteration 17654, loss = 29423.64229142\n",
            "Iteration 17655, loss = 29422.72202728\n",
            "Iteration 17656, loss = 29422.61396279\n",
            "Iteration 17657, loss = 29423.02172057\n",
            "Iteration 17658, loss = 29422.66323146\n",
            "Iteration 17659, loss = 29421.65452832\n",
            "Iteration 17660, loss = 29421.40112765\n",
            "Iteration 17661, loss = 29421.01949205\n",
            "Iteration 17662, loss = 29419.90154304\n",
            "Iteration 17663, loss = 29420.35710365\n",
            "Iteration 17664, loss = 29420.31180763\n",
            "Iteration 17665, loss = 29419.90405190\n",
            "Iteration 17666, loss = 29419.12807765\n",
            "Iteration 17667, loss = 29417.43059890\n",
            "Iteration 17668, loss = 29416.96587044\n",
            "Iteration 17669, loss = 29416.83821854\n",
            "Iteration 17670, loss = 29415.81059253\n",
            "Iteration 17671, loss = 29416.13359925\n",
            "Iteration 17672, loss = 29416.12086291\n",
            "Iteration 17673, loss = 29415.76492517\n",
            "Iteration 17674, loss = 29414.49345018\n",
            "Iteration 17675, loss = 29413.31770876\n",
            "Iteration 17676, loss = 29413.57956346\n",
            "Iteration 17677, loss = 29413.34145534\n",
            "Iteration 17678, loss = 29412.36623656\n",
            "Iteration 17679, loss = 29412.18516030\n",
            "Iteration 17680, loss = 29411.86669106\n",
            "Iteration 17681, loss = 29411.81012034\n",
            "Iteration 17682, loss = 29411.41178573\n",
            "Iteration 17683, loss = 29410.17616280\n",
            "Iteration 17684, loss = 29410.36188362\n",
            "Iteration 17685, loss = 29409.62050995\n",
            "Iteration 17686, loss = 29409.39097994\n",
            "Iteration 17687, loss = 29408.70005210\n",
            "Iteration 17688, loss = 29408.34878743\n",
            "Iteration 17689, loss = 29407.15693096\n",
            "Iteration 17690, loss = 29407.71700095\n",
            "Iteration 17691, loss = 29407.16648315\n",
            "Iteration 17692, loss = 29406.46659950\n",
            "Iteration 17693, loss = 29406.52259924\n",
            "Iteration 17694, loss = 29405.72478958\n",
            "Iteration 17695, loss = 29404.01130212\n",
            "Iteration 17696, loss = 29404.00656866\n",
            "Iteration 17697, loss = 29404.61996728\n",
            "Iteration 17698, loss = 29403.76693966\n",
            "Iteration 17699, loss = 29402.28663414\n",
            "Iteration 17700, loss = 29402.40159093\n",
            "Iteration 17701, loss = 29402.74015518\n",
            "Iteration 17702, loss = 29401.29613762\n",
            "Iteration 17703, loss = 29401.29241131\n",
            "Iteration 17704, loss = 29400.99367774\n",
            "Iteration 17705, loss = 29400.41959393\n",
            "Iteration 17706, loss = 29399.64018521\n",
            "Iteration 17707, loss = 29399.11428609\n",
            "Iteration 17708, loss = 29398.39241019\n",
            "Iteration 17709, loss = 29397.54872859\n",
            "Iteration 17710, loss = 29397.26976630\n",
            "Iteration 17711, loss = 29396.34256341\n",
            "Iteration 17712, loss = 29397.20270615\n",
            "Iteration 17713, loss = 29396.77566560\n",
            "Iteration 17714, loss = 29395.39454727\n",
            "Iteration 17715, loss = 29394.55225805\n",
            "Iteration 17716, loss = 29394.40054921\n",
            "Iteration 17717, loss = 29394.29936582\n",
            "Iteration 17718, loss = 29393.19906545\n",
            "Iteration 17719, loss = 29394.01309004\n",
            "Iteration 17720, loss = 29394.13539279\n",
            "Iteration 17721, loss = 29392.80514664\n",
            "Iteration 17722, loss = 29391.97069299\n",
            "Iteration 17723, loss = 29392.28560564\n",
            "Iteration 17724, loss = 29391.77274079\n",
            "Iteration 17725, loss = 29390.26585856\n",
            "Iteration 17726, loss = 29390.19306955\n",
            "Iteration 17727, loss = 29390.19680569\n",
            "Iteration 17728, loss = 29390.83286893\n",
            "Iteration 17729, loss = 29389.82742453\n",
            "Iteration 17730, loss = 29388.27814632\n",
            "Iteration 17731, loss = 29387.46979608\n",
            "Iteration 17732, loss = 29387.70451034\n",
            "Iteration 17733, loss = 29386.78665820\n",
            "Iteration 17734, loss = 29386.51937138\n",
            "Iteration 17735, loss = 29385.51915852\n",
            "Iteration 17736, loss = 29385.23173574\n",
            "Iteration 17737, loss = 29385.01383532\n",
            "Iteration 17738, loss = 29384.74159417\n",
            "Iteration 17739, loss = 29383.45681776\n",
            "Iteration 17740, loss = 29383.61086552\n",
            "Iteration 17741, loss = 29383.43663077\n",
            "Iteration 17742, loss = 29382.47484784\n",
            "Iteration 17743, loss = 29382.44201761\n",
            "Iteration 17744, loss = 29382.26481570\n",
            "Iteration 17745, loss = 29381.67200327\n",
            "Iteration 17746, loss = 29380.31582258\n",
            "Iteration 17747, loss = 29380.64259591\n",
            "Iteration 17748, loss = 29379.70626643\n",
            "Iteration 17749, loss = 29379.47542067\n",
            "Iteration 17750, loss = 29379.11157329\n",
            "Iteration 17751, loss = 29379.37554896\n",
            "Iteration 17752, loss = 29378.42168298\n",
            "Iteration 17753, loss = 29378.38586600\n",
            "Iteration 17754, loss = 29377.87022848\n",
            "Iteration 17755, loss = 29377.52105771\n",
            "Iteration 17756, loss = 29376.31951676\n",
            "Iteration 17757, loss = 29375.57830437\n",
            "Iteration 17758, loss = 29375.47271864\n",
            "Iteration 17759, loss = 29375.48443948\n",
            "Iteration 17760, loss = 29374.55106653\n",
            "Iteration 17761, loss = 29374.39633264\n",
            "Iteration 17762, loss = 29374.65752695\n",
            "Iteration 17763, loss = 29374.63457169\n",
            "Iteration 17764, loss = 29373.85346438\n",
            "Iteration 17765, loss = 29372.65289567\n",
            "Iteration 17766, loss = 29372.19211659\n",
            "Iteration 17767, loss = 29370.86070243\n",
            "Iteration 17768, loss = 29371.62542571\n",
            "Iteration 17769, loss = 29370.70416499\n",
            "Iteration 17770, loss = 29370.54686306\n",
            "Iteration 17771, loss = 29370.27793174\n",
            "Iteration 17772, loss = 29370.18599062\n",
            "Iteration 17773, loss = 29369.39142415\n",
            "Iteration 17774, loss = 29368.80042854\n",
            "Iteration 17775, loss = 29367.83985487\n",
            "Iteration 17776, loss = 29366.84862909\n",
            "Iteration 17777, loss = 29367.33406710\n",
            "Iteration 17778, loss = 29366.95696490\n",
            "Iteration 17779, loss = 29366.65955456\n",
            "Iteration 17780, loss = 29366.32227197\n",
            "Iteration 17781, loss = 29365.02029039\n",
            "Iteration 17782, loss = 29364.46589766\n",
            "Iteration 17783, loss = 29364.68362842\n",
            "Iteration 17784, loss = 29364.30424178\n",
            "Iteration 17785, loss = 29363.55871275\n",
            "Iteration 17786, loss = 29363.39969785\n",
            "Iteration 17787, loss = 29363.16926776\n",
            "Iteration 17788, loss = 29362.31377040\n",
            "Iteration 17789, loss = 29361.82462021\n",
            "Iteration 17790, loss = 29360.87489357\n",
            "Iteration 17791, loss = 29361.46011970\n",
            "Iteration 17792, loss = 29361.06509951\n",
            "Iteration 17793, loss = 29360.95443624\n",
            "Iteration 17794, loss = 29360.04312894\n",
            "Iteration 17795, loss = 29359.61295996\n",
            "Iteration 17796, loss = 29358.60313855\n",
            "Iteration 17797, loss = 29358.60598709\n",
            "Iteration 17798, loss = 29359.87910737\n",
            "Iteration 17799, loss = 29358.39407368\n",
            "Iteration 17800, loss = 29357.66536805\n",
            "Iteration 17801, loss = 29357.95352703\n",
            "Iteration 17802, loss = 29358.27686249\n",
            "Iteration 17803, loss = 29357.30063240\n",
            "Iteration 17804, loss = 29355.77668312\n",
            "Iteration 17805, loss = 29354.69478865\n",
            "Iteration 17806, loss = 29354.75060142\n",
            "Iteration 17807, loss = 29353.65164201\n",
            "Iteration 17808, loss = 29353.88378666\n",
            "Iteration 17809, loss = 29353.49567402\n",
            "Iteration 17810, loss = 29353.30859879\n",
            "Iteration 17811, loss = 29352.68529822\n",
            "Iteration 17812, loss = 29351.94250000\n",
            "Iteration 17813, loss = 29351.44938853\n",
            "Iteration 17814, loss = 29351.40554316\n",
            "Iteration 17815, loss = 29351.18943908\n",
            "Iteration 17816, loss = 29350.44838039\n",
            "Iteration 17817, loss = 29349.30439291\n",
            "Iteration 17818, loss = 29349.85943787\n",
            "Iteration 17819, loss = 29349.69039055\n",
            "Iteration 17820, loss = 29348.25420540\n",
            "Iteration 17821, loss = 29347.67094635\n",
            "Iteration 17822, loss = 29347.68269956\n",
            "Iteration 17823, loss = 29348.25644238\n",
            "Iteration 17824, loss = 29347.49828524\n",
            "Iteration 17825, loss = 29345.87428896\n",
            "Iteration 17826, loss = 29345.85084878\n",
            "Iteration 17827, loss = 29345.10915474\n",
            "Iteration 17828, loss = 29345.21656180\n",
            "Iteration 17829, loss = 29345.10886243\n",
            "Iteration 17830, loss = 29344.78025501\n",
            "Iteration 17831, loss = 29344.56394443\n",
            "Iteration 17832, loss = 29343.84812117\n",
            "Iteration 17833, loss = 29343.40170440\n",
            "Iteration 17834, loss = 29343.13074342\n",
            "Iteration 17835, loss = 29342.51538247\n",
            "Iteration 17836, loss = 29341.18845385\n",
            "Iteration 17837, loss = 29342.10344225\n",
            "Iteration 17838, loss = 29341.87141595\n",
            "Iteration 17839, loss = 29342.03457866\n",
            "Iteration 17840, loss = 29341.74955652\n",
            "Iteration 17841, loss = 29340.81102116\n",
            "Iteration 17842, loss = 29339.28861496\n",
            "Iteration 17843, loss = 29340.21832743\n",
            "Iteration 17844, loss = 29341.23814796\n",
            "Iteration 17845, loss = 29340.69930979\n",
            "Iteration 17846, loss = 29338.46680682\n",
            "Iteration 17847, loss = 29337.47346829\n",
            "Iteration 17848, loss = 29338.01737497\n",
            "Iteration 17849, loss = 29338.35512734\n",
            "Iteration 17850, loss = 29338.48335918\n",
            "Iteration 17851, loss = 29336.99742631\n",
            "Iteration 17852, loss = 29335.62831688\n",
            "Iteration 17853, loss = 29334.12332150\n",
            "Iteration 17854, loss = 29334.40989483\n",
            "Iteration 17855, loss = 29333.37999518\n",
            "Iteration 17856, loss = 29332.96309179\n",
            "Iteration 17857, loss = 29333.69358699\n",
            "Iteration 17858, loss = 29333.66694595\n",
            "Iteration 17859, loss = 29332.25916895\n",
            "Iteration 17860, loss = 29331.92454933\n",
            "Iteration 17861, loss = 29331.70443387\n",
            "Iteration 17862, loss = 29330.92648441\n",
            "Iteration 17863, loss = 29331.43691135\n",
            "Iteration 17864, loss = 29331.39681723\n",
            "Iteration 17865, loss = 29330.10204890\n",
            "Iteration 17866, loss = 29330.29572110\n",
            "Iteration 17867, loss = 29330.31510958\n",
            "Iteration 17868, loss = 29329.43072475\n",
            "Iteration 17869, loss = 29328.75891645\n",
            "Iteration 17870, loss = 29329.26610138\n",
            "Iteration 17871, loss = 29329.79810847\n",
            "Iteration 17872, loss = 29329.05510579\n",
            "Iteration 17873, loss = 29327.14897470\n",
            "Iteration 17874, loss = 29326.37839704\n",
            "Iteration 17875, loss = 29327.27257391\n",
            "Iteration 17876, loss = 29325.82985687\n",
            "Iteration 17877, loss = 29326.47794204\n",
            "Iteration 17878, loss = 29326.46879432\n",
            "Iteration 17879, loss = 29325.69121077\n",
            "Iteration 17880, loss = 29325.19310708\n",
            "Iteration 17881, loss = 29324.10694918\n",
            "Iteration 17882, loss = 29323.98731533\n",
            "Iteration 17883, loss = 29323.56103790\n",
            "Iteration 17884, loss = 29321.43948946\n",
            "Iteration 17885, loss = 29322.43745427\n",
            "Iteration 17886, loss = 29323.37480492\n",
            "Iteration 17887, loss = 29323.24710704\n",
            "Iteration 17888, loss = 29322.06248680\n",
            "Iteration 17889, loss = 29320.92729159\n",
            "Iteration 17890, loss = 29319.63808837\n",
            "Iteration 17891, loss = 29319.91918171\n",
            "Iteration 17892, loss = 29319.12368704\n",
            "Iteration 17893, loss = 29318.75286022\n",
            "Iteration 17894, loss = 29318.91659090\n",
            "Iteration 17895, loss = 29319.04311244\n",
            "Iteration 17896, loss = 29318.14847046\n",
            "Iteration 17897, loss = 29316.95290172\n",
            "Iteration 17898, loss = 29316.48322984\n",
            "Iteration 17899, loss = 29316.82638481\n",
            "Iteration 17900, loss = 29315.46345339\n",
            "Iteration 17901, loss = 29315.40035101\n",
            "Iteration 17902, loss = 29315.80126091\n",
            "Iteration 17903, loss = 29315.19393073\n",
            "Iteration 17904, loss = 29314.50734101\n",
            "Iteration 17905, loss = 29313.55526657\n",
            "Iteration 17906, loss = 29313.41528217\n",
            "Iteration 17907, loss = 29313.26278731\n",
            "Iteration 17908, loss = 29312.27257497\n",
            "Iteration 17909, loss = 29312.39206309\n",
            "Iteration 17910, loss = 29312.61985220\n",
            "Iteration 17911, loss = 29312.07794691\n",
            "Iteration 17912, loss = 29311.19696434\n",
            "Iteration 17913, loss = 29310.39448898\n",
            "Iteration 17914, loss = 29309.92417999\n",
            "Iteration 17915, loss = 29310.86931621\n",
            "Iteration 17916, loss = 29309.90889295\n",
            "Iteration 17917, loss = 29309.02740714\n",
            "Iteration 17918, loss = 29308.89382645\n",
            "Iteration 17919, loss = 29308.78981740\n",
            "Iteration 17920, loss = 29308.15773665\n",
            "Iteration 17921, loss = 29306.82757856\n",
            "Iteration 17922, loss = 29306.75876409\n",
            "Iteration 17923, loss = 29307.17800778\n",
            "Iteration 17924, loss = 29306.58293438\n",
            "Iteration 17925, loss = 29305.79730723\n",
            "Iteration 17926, loss = 29305.33911943\n",
            "Iteration 17927, loss = 29306.45965761\n",
            "Iteration 17928, loss = 29305.71637525\n",
            "Iteration 17929, loss = 29304.45952114\n",
            "Iteration 17930, loss = 29304.43677463\n",
            "Iteration 17931, loss = 29304.39040082\n",
            "Iteration 17932, loss = 29303.02555373\n",
            "Iteration 17933, loss = 29301.81496117\n",
            "Iteration 17934, loss = 29302.04663130\n",
            "Iteration 17935, loss = 29302.51366468\n",
            "Iteration 17936, loss = 29301.72918195\n",
            "Iteration 17937, loss = 29300.34368477\n",
            "Iteration 17938, loss = 29300.75101393\n",
            "Iteration 17939, loss = 29301.54383480\n",
            "Iteration 17940, loss = 29300.85293464\n",
            "Iteration 17941, loss = 29299.69612894\n",
            "Iteration 17942, loss = 29298.93743118\n",
            "Iteration 17943, loss = 29299.43476121\n",
            "Iteration 17944, loss = 29299.08314340\n",
            "Iteration 17945, loss = 29298.26916853\n",
            "Iteration 17946, loss = 29299.37904774\n",
            "Iteration 17947, loss = 29298.53564362\n",
            "Iteration 17948, loss = 29296.54588520\n",
            "Iteration 17949, loss = 29297.14156316\n",
            "Iteration 17950, loss = 29297.84213437\n",
            "Iteration 17951, loss = 29296.71310375\n",
            "Iteration 17952, loss = 29295.51856594\n",
            "Iteration 17953, loss = 29295.23753999\n",
            "Iteration 17954, loss = 29296.58048169\n",
            "Iteration 17955, loss = 29296.04638896\n",
            "Iteration 17956, loss = 29294.44440354\n",
            "Iteration 17957, loss = 29293.42126184\n",
            "Iteration 17958, loss = 29294.81598025\n",
            "Iteration 17959, loss = 29294.69142514\n",
            "Iteration 17960, loss = 29292.95494746\n",
            "Iteration 17961, loss = 29291.50735946\n",
            "Iteration 17962, loss = 29293.00818135\n",
            "Iteration 17963, loss = 29293.11700326\n",
            "Iteration 17964, loss = 29291.42951167\n",
            "Iteration 17965, loss = 29290.13195597\n",
            "Iteration 17966, loss = 29290.49161160\n",
            "Iteration 17967, loss = 29290.49449502\n",
            "Iteration 17968, loss = 29289.20416831\n",
            "Iteration 17969, loss = 29287.87313012\n",
            "Iteration 17970, loss = 29287.65642308\n",
            "Iteration 17971, loss = 29287.42856062\n",
            "Iteration 17972, loss = 29286.70975532\n",
            "Iteration 17973, loss = 29286.27352044\n",
            "Iteration 17974, loss = 29286.14951698\n",
            "Iteration 17975, loss = 29285.92307019\n",
            "Iteration 17976, loss = 29286.27336219\n",
            "Iteration 17977, loss = 29285.85741478\n",
            "Iteration 17978, loss = 29285.38177557\n",
            "Iteration 17979, loss = 29284.74384091\n",
            "Iteration 17980, loss = 29283.86601178\n",
            "Iteration 17981, loss = 29283.77191823\n",
            "Iteration 17982, loss = 29283.32917931\n",
            "Iteration 17983, loss = 29282.58149286\n",
            "Iteration 17984, loss = 29282.40393215\n",
            "Iteration 17985, loss = 29282.07027013\n",
            "Iteration 17986, loss = 29281.45142104\n",
            "Iteration 17987, loss = 29281.03749834\n",
            "Iteration 17988, loss = 29281.06424844\n",
            "Iteration 17989, loss = 29281.35265773\n",
            "Iteration 17990, loss = 29280.41775847\n",
            "Iteration 17991, loss = 29280.34769160\n",
            "Iteration 17992, loss = 29280.66538448\n",
            "Iteration 17993, loss = 29279.50760909\n",
            "Iteration 17994, loss = 29279.75575079\n",
            "Iteration 17995, loss = 29279.36157567\n",
            "Iteration 17996, loss = 29279.47082622\n",
            "Iteration 17997, loss = 29279.42652853\n",
            "Iteration 17998, loss = 29277.91610901\n",
            "Iteration 17999, loss = 29277.10754704\n",
            "Iteration 18000, loss = 29277.50616396\n",
            "Iteration 18001, loss = 29275.89762061\n",
            "Iteration 18002, loss = 29275.01777945\n",
            "Iteration 18003, loss = 29275.93973454\n",
            "Iteration 18004, loss = 29274.93840617\n",
            "Iteration 18005, loss = 29274.44403023\n",
            "Iteration 18006, loss = 29274.71555825\n",
            "Iteration 18007, loss = 29274.17181239\n",
            "Iteration 18008, loss = 29274.32139411\n",
            "Iteration 18009, loss = 29273.75880730\n",
            "Iteration 18010, loss = 29273.79944953\n",
            "Iteration 18011, loss = 29273.40596796\n",
            "Iteration 18012, loss = 29272.32503251\n",
            "Iteration 18013, loss = 29272.30221275\n",
            "Iteration 18014, loss = 29272.06080539\n",
            "Iteration 18015, loss = 29271.37428583\n",
            "Iteration 18016, loss = 29270.22035499\n",
            "Iteration 18017, loss = 29270.21999405\n",
            "Iteration 18018, loss = 29269.86236317\n",
            "Iteration 18019, loss = 29269.05950255\n",
            "Iteration 18020, loss = 29269.04356641\n",
            "Iteration 18021, loss = 29268.69493903\n",
            "Iteration 18022, loss = 29267.67587371\n",
            "Iteration 18023, loss = 29268.91385229\n",
            "Iteration 18024, loss = 29268.83499881\n",
            "Iteration 18025, loss = 29267.23354845\n",
            "Iteration 18026, loss = 29267.63566585\n",
            "Iteration 18027, loss = 29268.07503206\n",
            "Iteration 18028, loss = 29267.55382234\n",
            "Iteration 18029, loss = 29266.78049422\n",
            "Iteration 18030, loss = 29266.06509807\n",
            "Iteration 18031, loss = 29265.18804419\n",
            "Iteration 18032, loss = 29264.56899373\n",
            "Iteration 18033, loss = 29263.56694746\n",
            "Iteration 18034, loss = 29263.60873095\n",
            "Iteration 18035, loss = 29262.90383099\n",
            "Iteration 18036, loss = 29263.05564385\n",
            "Iteration 18037, loss = 29262.58733249\n",
            "Iteration 18038, loss = 29262.12680563\n",
            "Iteration 18039, loss = 29261.91486741\n",
            "Iteration 18040, loss = 29262.19379919\n",
            "Iteration 18041, loss = 29262.23333238\n",
            "Iteration 18042, loss = 29261.59876900\n",
            "Iteration 18043, loss = 29260.32500578\n",
            "Iteration 18044, loss = 29260.58059197\n",
            "Iteration 18045, loss = 29260.38748025\n",
            "Iteration 18046, loss = 29260.14779585\n",
            "Iteration 18047, loss = 29259.33575920\n",
            "Iteration 18048, loss = 29259.52059081\n",
            "Iteration 18049, loss = 29259.33325614\n",
            "Iteration 18050, loss = 29258.76583930\n",
            "Iteration 18051, loss = 29259.11656831\n",
            "Iteration 18052, loss = 29259.10298470\n",
            "Iteration 18053, loss = 29257.60194862\n",
            "Iteration 18054, loss = 29257.43440022\n",
            "Iteration 18055, loss = 29258.61189177\n",
            "Iteration 18056, loss = 29258.75563223\n",
            "Iteration 18057, loss = 29256.60826731\n",
            "Iteration 18058, loss = 29255.19898260\n",
            "Iteration 18059, loss = 29255.72228885\n",
            "Iteration 18060, loss = 29255.75992925\n",
            "Iteration 18061, loss = 29254.84315721\n",
            "Iteration 18062, loss = 29253.89741574\n",
            "Iteration 18063, loss = 29253.04408896\n",
            "Iteration 18064, loss = 29252.97150619\n",
            "Iteration 18065, loss = 29252.01921503\n",
            "Iteration 18066, loss = 29251.53592245\n",
            "Iteration 18067, loss = 29252.20701046\n",
            "Iteration 18068, loss = 29251.82816121\n",
            "Iteration 18069, loss = 29250.52560377\n",
            "Iteration 18070, loss = 29250.89681936\n",
            "Iteration 18071, loss = 29250.59385031\n",
            "Iteration 18072, loss = 29251.07369291\n",
            "Iteration 18073, loss = 29250.67903981\n",
            "Iteration 18074, loss = 29249.58055043\n",
            "Iteration 18075, loss = 29249.07077278\n",
            "Iteration 18076, loss = 29247.75857934\n",
            "Iteration 18077, loss = 29247.49410417\n",
            "Iteration 18078, loss = 29247.44802786\n",
            "Iteration 18079, loss = 29247.44118981\n",
            "Iteration 18080, loss = 29246.67847531\n",
            "Iteration 18081, loss = 29246.45236448\n",
            "Iteration 18082, loss = 29245.78827623\n",
            "Iteration 18083, loss = 29245.77342879\n",
            "Iteration 18084, loss = 29246.23273852\n",
            "Iteration 18085, loss = 29245.43702934\n",
            "Iteration 18086, loss = 29245.26533871\n",
            "Iteration 18087, loss = 29245.79783765\n",
            "Iteration 18088, loss = 29245.02081629\n",
            "Iteration 18089, loss = 29243.76740132\n",
            "Iteration 18090, loss = 29244.75513604\n",
            "Iteration 18091, loss = 29244.52168268\n",
            "Iteration 18092, loss = 29244.26756675\n",
            "Iteration 18093, loss = 29243.72066466\n",
            "Iteration 18094, loss = 29243.03441226\n",
            "Iteration 18095, loss = 29241.81824979\n",
            "Iteration 18096, loss = 29241.27175769\n",
            "Iteration 18097, loss = 29240.62209342\n",
            "Iteration 18098, loss = 29240.73352476\n",
            "Iteration 18099, loss = 29240.23020803\n",
            "Iteration 18100, loss = 29240.46941139\n",
            "Iteration 18101, loss = 29240.18186103\n",
            "Iteration 18102, loss = 29239.88592520\n",
            "Iteration 18103, loss = 29239.14593622\n",
            "Iteration 18104, loss = 29239.19189318\n",
            "Iteration 18105, loss = 29238.97627207\n",
            "Iteration 18106, loss = 29238.17261403\n",
            "Iteration 18107, loss = 29238.01456289\n",
            "Iteration 18108, loss = 29237.85529901\n",
            "Iteration 18109, loss = 29237.50197857\n",
            "Iteration 18110, loss = 29236.86772536\n",
            "Iteration 18111, loss = 29236.40276057\n",
            "Iteration 18112, loss = 29236.40105602\n",
            "Iteration 18113, loss = 29235.64604138\n",
            "Iteration 18114, loss = 29234.89934304\n",
            "Iteration 18115, loss = 29235.36579506\n",
            "Iteration 18116, loss = 29235.25736807\n",
            "Iteration 18117, loss = 29234.70447309\n",
            "Iteration 18118, loss = 29234.52414918\n",
            "Iteration 18119, loss = 29233.09037345\n",
            "Iteration 18120, loss = 29233.18221032\n",
            "Iteration 18121, loss = 29233.56658677\n",
            "Iteration 18122, loss = 29233.01905343\n",
            "Iteration 18123, loss = 29232.19245070\n",
            "Iteration 18124, loss = 29231.33546951\n",
            "Iteration 18125, loss = 29232.38694112\n",
            "Iteration 18126, loss = 29232.42527415\n",
            "Iteration 18127, loss = 29231.02607306\n",
            "Iteration 18128, loss = 29229.70269824\n",
            "Iteration 18129, loss = 29229.72674512\n",
            "Iteration 18130, loss = 29229.61481843\n",
            "Iteration 18131, loss = 29229.40182813\n",
            "Iteration 18132, loss = 29229.08098319\n",
            "Iteration 18133, loss = 29228.15853896\n",
            "Iteration 18134, loss = 29228.02184653\n",
            "Iteration 18135, loss = 29227.74237126\n",
            "Iteration 18136, loss = 29227.28107718\n",
            "Iteration 18137, loss = 29227.97362431\n",
            "Iteration 18138, loss = 29227.08397126\n",
            "Iteration 18139, loss = 29226.73953538\n",
            "Iteration 18140, loss = 29227.40798876\n",
            "Iteration 18141, loss = 29227.40409211\n",
            "Iteration 18142, loss = 29226.00035124\n",
            "Iteration 18143, loss = 29224.82426146\n",
            "Iteration 18144, loss = 29225.70861893\n",
            "Iteration 18145, loss = 29224.83119107\n",
            "Iteration 18146, loss = 29224.03209258\n",
            "Iteration 18147, loss = 29223.44834257\n",
            "Iteration 18148, loss = 29223.74078187\n",
            "Iteration 18149, loss = 29223.18299065\n",
            "Iteration 18150, loss = 29223.39881014\n",
            "Iteration 18151, loss = 29223.56064249\n",
            "Iteration 18152, loss = 29222.42165926\n",
            "Iteration 18153, loss = 29221.32036050\n",
            "Iteration 18154, loss = 29221.33764975\n",
            "Iteration 18155, loss = 29221.25084161\n",
            "Iteration 18156, loss = 29221.12883287\n",
            "Iteration 18157, loss = 29221.12742472\n",
            "Iteration 18158, loss = 29220.32225454\n",
            "Iteration 18159, loss = 29219.74499395\n",
            "Iteration 18160, loss = 29219.30812847\n",
            "Iteration 18161, loss = 29218.53837799\n",
            "Iteration 18162, loss = 29217.84440012\n",
            "Iteration 18163, loss = 29217.72458994\n",
            "Iteration 18164, loss = 29217.89489804\n",
            "Iteration 18165, loss = 29217.25067114\n",
            "Iteration 18166, loss = 29216.44219299\n",
            "Iteration 18167, loss = 29217.84015159\n",
            "Iteration 18168, loss = 29217.56192999\n",
            "Iteration 18169, loss = 29215.66417096\n",
            "Iteration 18170, loss = 29216.44420780\n",
            "Iteration 18171, loss = 29217.09145844\n",
            "Iteration 18172, loss = 29216.81680192\n",
            "Iteration 18173, loss = 29215.95720309\n",
            "Iteration 18174, loss = 29215.35491731\n",
            "Iteration 18175, loss = 29214.80820756\n",
            "Iteration 18176, loss = 29215.54229700\n",
            "Iteration 18177, loss = 29216.09453167\n",
            "Iteration 18178, loss = 29214.51084816\n",
            "Iteration 18179, loss = 29212.39498003\n",
            "Iteration 18180, loss = 29214.74158053\n",
            "Iteration 18181, loss = 29215.35964323\n",
            "Iteration 18182, loss = 29214.46999576\n",
            "Iteration 18183, loss = 29213.99645013\n",
            "Iteration 18184, loss = 29212.95630626\n",
            "Iteration 18185, loss = 29211.93841073\n",
            "Iteration 18186, loss = 29210.09583488\n",
            "Iteration 18187, loss = 29210.34759036\n",
            "Iteration 18188, loss = 29211.39902908\n",
            "Iteration 18189, loss = 29210.59049699\n",
            "Iteration 18190, loss = 29208.52371338\n",
            "Iteration 18191, loss = 29208.91262610\n",
            "Iteration 18192, loss = 29209.27074681\n",
            "Iteration 18193, loss = 29209.95515676\n",
            "Iteration 18194, loss = 29209.45831653\n",
            "Iteration 18195, loss = 29208.10486961\n",
            "Iteration 18196, loss = 29207.56573263\n",
            "Iteration 18197, loss = 29207.16439716\n",
            "Iteration 18198, loss = 29207.12297625\n",
            "Iteration 18199, loss = 29205.96790337\n",
            "Iteration 18200, loss = 29205.86662257\n",
            "Iteration 18201, loss = 29206.21551353\n",
            "Iteration 18202, loss = 29206.37870557\n",
            "Iteration 18203, loss = 29205.11538426\n",
            "Iteration 18204, loss = 29203.80720703\n",
            "Iteration 18205, loss = 29204.85376221\n",
            "Iteration 18206, loss = 29204.71775434\n",
            "Iteration 18207, loss = 29203.68352144\n",
            "Iteration 18208, loss = 29202.96370224\n",
            "Iteration 18209, loss = 29203.76144180\n",
            "Iteration 18210, loss = 29203.68932695\n",
            "Iteration 18211, loss = 29202.39615054\n",
            "Iteration 18212, loss = 29201.89568425\n",
            "Iteration 18213, loss = 29202.75202115\n",
            "Iteration 18214, loss = 29202.13622622\n",
            "Iteration 18215, loss = 29202.13884946\n",
            "Iteration 18216, loss = 29200.38170117\n",
            "Iteration 18217, loss = 29200.58579220\n",
            "Iteration 18218, loss = 29200.55954339\n",
            "Iteration 18219, loss = 29200.17565425\n",
            "Iteration 18220, loss = 29199.80463250\n",
            "Iteration 18221, loss = 29200.95717938\n",
            "Iteration 18222, loss = 29200.99486952\n",
            "Iteration 18223, loss = 29199.60420996\n",
            "Iteration 18224, loss = 29197.96597064\n",
            "Iteration 18225, loss = 29198.71923780\n",
            "Iteration 18226, loss = 29198.37902018\n",
            "Iteration 18227, loss = 29197.12950538\n",
            "Iteration 18228, loss = 29196.53013472\n",
            "Iteration 18229, loss = 29196.94815042\n",
            "Iteration 18230, loss = 29196.85116099\n",
            "Iteration 18231, loss = 29196.57627317\n",
            "Iteration 18232, loss = 29196.07866711\n",
            "Iteration 18233, loss = 29195.38630757\n",
            "Iteration 18234, loss = 29195.11899456\n",
            "Iteration 18235, loss = 29195.17533920\n",
            "Iteration 18236, loss = 29194.31670648\n",
            "Iteration 18237, loss = 29193.71037045\n",
            "Iteration 18238, loss = 29193.47488658\n",
            "Iteration 18239, loss = 29193.85515616\n",
            "Iteration 18240, loss = 29193.04261578\n",
            "Iteration 18241, loss = 29192.39533251\n",
            "Iteration 18242, loss = 29192.67004244\n",
            "Iteration 18243, loss = 29192.02036506\n",
            "Iteration 18244, loss = 29191.28852355\n",
            "Iteration 18245, loss = 29190.99710449\n",
            "Iteration 18246, loss = 29191.51504248\n",
            "Iteration 18247, loss = 29191.74361816\n",
            "Iteration 18248, loss = 29190.75360238\n",
            "Iteration 18249, loss = 29189.91907456\n",
            "Iteration 18250, loss = 29189.19873627\n",
            "Iteration 18251, loss = 29190.65199000\n",
            "Iteration 18252, loss = 29190.24682583\n",
            "Iteration 18253, loss = 29189.33668396\n",
            "Iteration 18254, loss = 29188.03073644\n",
            "Iteration 18255, loss = 29187.60975097\n",
            "Iteration 18256, loss = 29188.35935053\n",
            "Iteration 18257, loss = 29188.06342786\n",
            "Iteration 18258, loss = 29187.10888317\n",
            "Iteration 18259, loss = 29186.00252430\n",
            "Iteration 18260, loss = 29186.61920090\n",
            "Iteration 18261, loss = 29186.34249705\n",
            "Iteration 18262, loss = 29186.22632544\n",
            "Iteration 18263, loss = 29186.01949039\n",
            "Iteration 18264, loss = 29185.59342144\n",
            "Iteration 18265, loss = 29184.30740365\n",
            "Iteration 18266, loss = 29184.31795426\n",
            "Iteration 18267, loss = 29183.99865049\n",
            "Iteration 18268, loss = 29183.66332597\n",
            "Iteration 18269, loss = 29184.24844094\n",
            "Iteration 18270, loss = 29183.31722827\n",
            "Iteration 18271, loss = 29183.22391313\n",
            "Iteration 18272, loss = 29182.65242676\n",
            "Iteration 18273, loss = 29182.05698514\n",
            "Iteration 18274, loss = 29181.68970774\n",
            "Iteration 18275, loss = 29180.80863301\n",
            "Iteration 18276, loss = 29180.98705600\n",
            "Iteration 18277, loss = 29180.33933513\n",
            "Iteration 18278, loss = 29180.25976149\n",
            "Iteration 18279, loss = 29180.79425631\n",
            "Iteration 18280, loss = 29180.19253430\n",
            "Iteration 18281, loss = 29179.81197754\n",
            "Iteration 18282, loss = 29179.60824301\n",
            "Iteration 18283, loss = 29179.39691925\n",
            "Iteration 18284, loss = 29178.71190551\n",
            "Iteration 18285, loss = 29178.46616484\n",
            "Iteration 18286, loss = 29177.17455132\n",
            "Iteration 18287, loss = 29178.56834310\n",
            "Iteration 18288, loss = 29178.32903993\n",
            "Iteration 18289, loss = 29177.54024240\n",
            "Iteration 18290, loss = 29176.39170457\n",
            "Iteration 18291, loss = 29176.29657219\n",
            "Iteration 18292, loss = 29176.63191591\n",
            "Iteration 18293, loss = 29176.37282130\n",
            "Iteration 18294, loss = 29176.40857289\n",
            "Iteration 18295, loss = 29176.09243524\n",
            "Iteration 18296, loss = 29174.81300837\n",
            "Iteration 18297, loss = 29174.89305818\n",
            "Iteration 18298, loss = 29175.30379877\n",
            "Iteration 18299, loss = 29174.83722917\n",
            "Iteration 18300, loss = 29173.30299826\n",
            "Iteration 18301, loss = 29172.83315425\n",
            "Iteration 18302, loss = 29172.86962529\n",
            "Iteration 18303, loss = 29172.43814816\n",
            "Iteration 18304, loss = 29171.74212690\n",
            "Iteration 18305, loss = 29171.30693048\n",
            "Iteration 18306, loss = 29170.89658585\n",
            "Iteration 18307, loss = 29170.49449625\n",
            "Iteration 18308, loss = 29171.06990495\n",
            "Iteration 18309, loss = 29170.80337108\n",
            "Iteration 18310, loss = 29170.74839015\n",
            "Iteration 18311, loss = 29170.77803992\n",
            "Iteration 18312, loss = 29170.04039829\n",
            "Iteration 18313, loss = 29169.61128347\n",
            "Iteration 18314, loss = 29170.66665394\n",
            "Iteration 18315, loss = 29170.14149519\n",
            "Iteration 18316, loss = 29168.76797482\n",
            "Iteration 18317, loss = 29169.28681615\n",
            "Iteration 18318, loss = 29169.87523663\n",
            "Iteration 18319, loss = 29170.13107885\n",
            "Iteration 18320, loss = 29169.08888819\n",
            "Iteration 18321, loss = 29167.16634808\n",
            "Iteration 18322, loss = 29166.74672430\n",
            "Iteration 18323, loss = 29168.09566900\n",
            "Iteration 18324, loss = 29168.45391459\n",
            "Iteration 18325, loss = 29167.55894007\n",
            "Iteration 18326, loss = 29165.66069183\n",
            "Iteration 18327, loss = 29166.23894420\n",
            "Iteration 18328, loss = 29166.59358962\n",
            "Iteration 18329, loss = 29166.89791137\n",
            "Iteration 18330, loss = 29166.93903861\n",
            "Iteration 18331, loss = 29165.64459702\n",
            "Iteration 18332, loss = 29164.74981072\n",
            "Iteration 18333, loss = 29164.13134987\n",
            "Iteration 18334, loss = 29166.77372215\n",
            "Iteration 18335, loss = 29167.16363088\n",
            "Iteration 18336, loss = 29165.24198385\n",
            "Iteration 18337, loss = 29162.90545715\n",
            "Iteration 18338, loss = 29162.60745568\n",
            "Iteration 18339, loss = 29163.41436673\n",
            "Iteration 18340, loss = 29162.78092286\n",
            "Iteration 18341, loss = 29162.24494499\n",
            "Iteration 18342, loss = 29161.86447609\n",
            "Iteration 18343, loss = 29160.67541526\n",
            "Iteration 18344, loss = 29161.03300671\n",
            "Iteration 18345, loss = 29161.63104632\n",
            "Iteration 18346, loss = 29160.78326177\n",
            "Iteration 18347, loss = 29159.19059839\n",
            "Iteration 18348, loss = 29159.16368744\n",
            "Iteration 18349, loss = 29158.65669937\n",
            "Iteration 18350, loss = 29158.13109746\n",
            "Iteration 18351, loss = 29158.57656717\n",
            "Iteration 18352, loss = 29157.95405110\n",
            "Iteration 18353, loss = 29156.94769006\n",
            "Iteration 18354, loss = 29156.96236002\n",
            "Iteration 18355, loss = 29156.07355171\n",
            "Iteration 18356, loss = 29156.94644673\n",
            "Iteration 18357, loss = 29156.53098602\n",
            "Iteration 18358, loss = 29156.53515573\n",
            "Iteration 18359, loss = 29156.15328197\n",
            "Iteration 18360, loss = 29155.42797580\n",
            "Iteration 18361, loss = 29154.93282275\n",
            "Iteration 18362, loss = 29156.27451243\n",
            "Iteration 18363, loss = 29155.78875503\n",
            "Iteration 18364, loss = 29153.68937871\n",
            "Iteration 18365, loss = 29154.85042523\n",
            "Iteration 18366, loss = 29155.27561979\n",
            "Iteration 18367, loss = 29155.02673459\n",
            "Iteration 18368, loss = 29155.16780611\n",
            "Iteration 18369, loss = 29154.20001603\n",
            "Iteration 18370, loss = 29151.96849926\n",
            "Iteration 18371, loss = 29154.03643386\n",
            "Iteration 18372, loss = 29155.42556903\n",
            "Iteration 18373, loss = 29154.50061315\n",
            "Iteration 18374, loss = 29151.82870441\n",
            "Iteration 18375, loss = 29150.94730028\n",
            "Iteration 18376, loss = 29152.89335268\n",
            "Iteration 18377, loss = 29153.39339855\n",
            "Iteration 18378, loss = 29152.20670414\n",
            "Iteration 18379, loss = 29150.79581048\n",
            "Iteration 18380, loss = 29151.05588632\n",
            "Iteration 18381, loss = 29150.23336247\n",
            "Iteration 18382, loss = 29149.82643890\n",
            "Iteration 18383, loss = 29147.91935186\n",
            "Iteration 18384, loss = 29148.62487574\n",
            "Iteration 18385, loss = 29148.60622520\n",
            "Iteration 18386, loss = 29148.39316065\n",
            "Iteration 18387, loss = 29148.04284623\n",
            "Iteration 18388, loss = 29146.98093058\n",
            "Iteration 18389, loss = 29147.67654603\n",
            "Iteration 18390, loss = 29147.43357156\n",
            "Iteration 18391, loss = 29147.10507537\n",
            "Iteration 18392, loss = 29145.86150107\n",
            "Iteration 18393, loss = 29145.72838883\n",
            "Iteration 18394, loss = 29145.97355857\n",
            "Iteration 18395, loss = 29145.95402420\n",
            "Iteration 18396, loss = 29145.32280100\n",
            "Iteration 18397, loss = 29146.38893259\n",
            "Iteration 18398, loss = 29146.09467427\n",
            "Iteration 18399, loss = 29145.60494869\n",
            "Iteration 18400, loss = 29144.48340525\n",
            "Iteration 18401, loss = 29143.97516606\n",
            "Iteration 18402, loss = 29142.97473882\n",
            "Iteration 18403, loss = 29143.12462486\n",
            "Iteration 18404, loss = 29142.91324818\n",
            "Iteration 18405, loss = 29141.49042713\n",
            "Iteration 18406, loss = 29142.26523873\n",
            "Iteration 18407, loss = 29142.72685149\n",
            "Iteration 18408, loss = 29142.40317452\n",
            "Iteration 18409, loss = 29140.79916072\n",
            "Iteration 18410, loss = 29142.20433796\n",
            "Iteration 18411, loss = 29142.28292369\n",
            "Iteration 18412, loss = 29140.61302877\n",
            "Iteration 18413, loss = 29139.96139643\n",
            "Iteration 18414, loss = 29140.69158054\n",
            "Iteration 18415, loss = 29140.73879258\n",
            "Iteration 18416, loss = 29140.26365735\n",
            "Iteration 18417, loss = 29139.18869523\n",
            "Iteration 18418, loss = 29139.71658783\n",
            "Iteration 18419, loss = 29139.57598040\n",
            "Iteration 18420, loss = 29137.56395827\n",
            "Iteration 18421, loss = 29138.19192631\n",
            "Iteration 18422, loss = 29138.58012250\n",
            "Iteration 18423, loss = 29138.13454498\n",
            "Iteration 18424, loss = 29137.34411796\n",
            "Iteration 18425, loss = 29136.14402833\n",
            "Iteration 18426, loss = 29135.89725146\n",
            "Iteration 18427, loss = 29136.03207302\n",
            "Iteration 18428, loss = 29134.44722231\n",
            "Iteration 18429, loss = 29135.87132065\n",
            "Iteration 18430, loss = 29135.97317768\n",
            "Iteration 18431, loss = 29135.41284520\n",
            "Iteration 18432, loss = 29134.98811080\n",
            "Iteration 18433, loss = 29134.34170065\n",
            "Iteration 18434, loss = 29133.63737098\n",
            "Iteration 18435, loss = 29133.27849193\n",
            "Iteration 18436, loss = 29133.03395156\n",
            "Iteration 18437, loss = 29133.98793651\n",
            "Iteration 18438, loss = 29133.46487621\n",
            "Iteration 18439, loss = 29133.38834556\n",
            "Iteration 18440, loss = 29132.51618671\n",
            "Iteration 18441, loss = 29131.35646229\n",
            "Iteration 18442, loss = 29131.62069269\n",
            "Iteration 18443, loss = 29131.64998900\n",
            "Iteration 18444, loss = 29131.07265935\n",
            "Iteration 18445, loss = 29130.99312787\n",
            "Iteration 18446, loss = 29130.80421246\n",
            "Iteration 18447, loss = 29130.81142880\n",
            "Iteration 18448, loss = 29130.45043558\n",
            "Iteration 18449, loss = 29129.78699359\n",
            "Iteration 18450, loss = 29129.70174641\n",
            "Iteration 18451, loss = 29129.03309930\n",
            "Iteration 18452, loss = 29129.37106096\n",
            "Iteration 18453, loss = 29129.75590699\n",
            "Iteration 18454, loss = 29129.56936887\n",
            "Iteration 18455, loss = 29129.27028003\n",
            "Iteration 18456, loss = 29128.47379815\n",
            "Iteration 18457, loss = 29128.02997117\n",
            "Iteration 18458, loss = 29129.06854108\n",
            "Iteration 18459, loss = 29128.71260545\n",
            "Iteration 18460, loss = 29127.06850914\n",
            "Iteration 18461, loss = 29126.39958475\n",
            "Iteration 18462, loss = 29128.35647756\n",
            "Iteration 18463, loss = 29128.13266738\n",
            "Iteration 18464, loss = 29126.84844002\n",
            "Iteration 18465, loss = 29125.16573341\n",
            "Iteration 18466, loss = 29126.59386712\n",
            "Iteration 18467, loss = 29126.64343392\n",
            "Iteration 18468, loss = 29125.47417553\n",
            "Iteration 18469, loss = 29123.69627049\n",
            "Iteration 18470, loss = 29123.72351416\n",
            "Iteration 18471, loss = 29123.62289042\n",
            "Iteration 18472, loss = 29123.54819776\n",
            "Iteration 18473, loss = 29122.78920141\n",
            "Iteration 18474, loss = 29123.75081589\n",
            "Iteration 18475, loss = 29123.01896835\n",
            "Iteration 18476, loss = 29122.34643421\n",
            "Iteration 18477, loss = 29121.89435243\n",
            "Iteration 18478, loss = 29122.04114416\n",
            "Iteration 18479, loss = 29121.61377459\n",
            "Iteration 18480, loss = 29121.20173571\n",
            "Iteration 18481, loss = 29119.93829305\n",
            "Iteration 18482, loss = 29120.61221735\n",
            "Iteration 18483, loss = 29121.24138422\n",
            "Iteration 18484, loss = 29119.99883478\n",
            "Iteration 18485, loss = 29119.03029681\n",
            "Iteration 18486, loss = 29119.40758585\n",
            "Iteration 18487, loss = 29119.80960649\n",
            "Iteration 18488, loss = 29118.98505386\n",
            "Iteration 18489, loss = 29117.93131066\n",
            "Iteration 18490, loss = 29117.52365751\n",
            "Iteration 18491, loss = 29117.64603601\n",
            "Iteration 18492, loss = 29116.48769496\n",
            "Iteration 18493, loss = 29117.02600024\n",
            "Iteration 18494, loss = 29117.55452485\n",
            "Iteration 18495, loss = 29117.35888750\n",
            "Iteration 18496, loss = 29116.58209507\n",
            "Iteration 18497, loss = 29115.85445637\n",
            "Iteration 18498, loss = 29117.42166342\n",
            "Iteration 18499, loss = 29117.99096947\n",
            "Iteration 18500, loss = 29116.53153460\n",
            "Iteration 18501, loss = 29114.70124702\n",
            "Iteration 18502, loss = 29115.27134722\n",
            "Iteration 18503, loss = 29115.74447995\n",
            "Iteration 18504, loss = 29114.56414192\n",
            "Iteration 18505, loss = 29112.71338390\n",
            "Iteration 18506, loss = 29115.46631556\n",
            "Iteration 18507, loss = 29115.41867856\n",
            "Iteration 18508, loss = 29114.49226354\n",
            "Iteration 18509, loss = 29113.49746338\n",
            "Iteration 18510, loss = 29113.53667343\n",
            "Iteration 18511, loss = 29112.84732091\n",
            "Iteration 18512, loss = 29112.57851375\n",
            "Iteration 18513, loss = 29112.10019979\n",
            "Iteration 18514, loss = 29111.51531235\n",
            "Iteration 18515, loss = 29110.93117254\n",
            "Iteration 18516, loss = 29111.01882163\n",
            "Iteration 18517, loss = 29111.22530704\n",
            "Iteration 18518, loss = 29110.49415744\n",
            "Iteration 18519, loss = 29109.96492742\n",
            "Iteration 18520, loss = 29109.28676638\n",
            "Iteration 18521, loss = 29108.86683679\n",
            "Iteration 18522, loss = 29109.59812036\n",
            "Iteration 18523, loss = 29109.03380530\n",
            "Iteration 18524, loss = 29107.73208421\n",
            "Iteration 18525, loss = 29107.56281864\n",
            "Iteration 18526, loss = 29108.00425033\n",
            "Iteration 18527, loss = 29107.24249387\n",
            "Iteration 18528, loss = 29107.16801438\n",
            "Iteration 18529, loss = 29108.13002704\n",
            "Iteration 18530, loss = 29108.03444353\n",
            "Iteration 18531, loss = 29106.48078682\n",
            "Iteration 18532, loss = 29106.47665844\n",
            "Iteration 18533, loss = 29106.55610001\n",
            "Iteration 18534, loss = 29105.34557588\n",
            "Iteration 18535, loss = 29105.10262615\n",
            "Iteration 18536, loss = 29104.94344605\n",
            "Iteration 18537, loss = 29104.56016720\n",
            "Iteration 18538, loss = 29104.29970738\n",
            "Iteration 18539, loss = 29103.74246631\n",
            "Iteration 18540, loss = 29103.58808834\n",
            "Iteration 18541, loss = 29103.44144021\n",
            "Iteration 18542, loss = 29103.27298211\n",
            "Iteration 18543, loss = 29103.40599083\n",
            "Iteration 18544, loss = 29102.79354481\n",
            "Iteration 18545, loss = 29102.90431183\n",
            "Iteration 18546, loss = 29103.17724451\n",
            "Iteration 18547, loss = 29101.80129212\n",
            "Iteration 18548, loss = 29102.23818167\n",
            "Iteration 18549, loss = 29101.83554189\n",
            "Iteration 18550, loss = 29101.88172793\n",
            "Iteration 18551, loss = 29100.92157855\n",
            "Iteration 18552, loss = 29101.57265341\n",
            "Iteration 18553, loss = 29102.48265943\n",
            "Iteration 18554, loss = 29101.62397725\n",
            "Iteration 18555, loss = 29099.30345317\n",
            "Iteration 18556, loss = 29100.83864206\n",
            "Iteration 18557, loss = 29101.30003349\n",
            "Iteration 18558, loss = 29099.54053033\n",
            "Iteration 18559, loss = 29099.34310162\n",
            "Iteration 18560, loss = 29100.29175139\n",
            "Iteration 18561, loss = 29100.11076008\n",
            "Iteration 18562, loss = 29099.12200708\n",
            "Iteration 18563, loss = 29098.34227495\n",
            "Iteration 18564, loss = 29097.44567041\n",
            "Iteration 18565, loss = 29097.61370631\n",
            "Iteration 18566, loss = 29096.85420688\n",
            "Iteration 18567, loss = 29096.64150641\n",
            "Iteration 18568, loss = 29095.80543328\n",
            "Iteration 18569, loss = 29097.38209520\n",
            "Iteration 18570, loss = 29097.31612805\n",
            "Iteration 18571, loss = 29095.39763046\n",
            "Iteration 18572, loss = 29095.60285196\n",
            "Iteration 18573, loss = 29095.95174252\n",
            "Iteration 18574, loss = 29096.99683519\n",
            "Iteration 18575, loss = 29095.69523800\n",
            "Iteration 18576, loss = 29094.42583732\n",
            "Iteration 18577, loss = 29095.00699726\n",
            "Iteration 18578, loss = 29095.22849112\n",
            "Iteration 18579, loss = 29093.95755630\n",
            "Iteration 18580, loss = 29094.27903325\n",
            "Iteration 18581, loss = 29094.64295418\n",
            "Iteration 18582, loss = 29092.96065464\n",
            "Iteration 18583, loss = 29092.74141643\n",
            "Iteration 18584, loss = 29093.41690734\n",
            "Iteration 18585, loss = 29093.13860781\n",
            "Iteration 18586, loss = 29093.22405035\n",
            "Iteration 18587, loss = 29092.06368707\n",
            "Iteration 18588, loss = 29091.51369650\n",
            "Iteration 18589, loss = 29091.62382730\n",
            "Iteration 18590, loss = 29090.52290719\n",
            "Iteration 18591, loss = 29090.63642891\n",
            "Iteration 18592, loss = 29090.94389555\n",
            "Iteration 18593, loss = 29090.18269911\n",
            "Iteration 18594, loss = 29089.23975537\n",
            "Iteration 18595, loss = 29090.31547253\n",
            "Iteration 18596, loss = 29089.81397428\n",
            "Iteration 18597, loss = 29089.45528912\n",
            "Iteration 18598, loss = 29089.14141660\n",
            "Iteration 18599, loss = 29089.18434429\n",
            "Iteration 18600, loss = 29088.42673307\n",
            "Iteration 18601, loss = 29087.86068916\n",
            "Iteration 18602, loss = 29087.25637139\n",
            "Iteration 18603, loss = 29086.77706233\n",
            "Iteration 18604, loss = 29086.21603827\n",
            "Iteration 18605, loss = 29085.24914290\n",
            "Iteration 18606, loss = 29085.88947117\n",
            "Iteration 18607, loss = 29084.99251746\n",
            "Iteration 18608, loss = 29083.99705491\n",
            "Iteration 18609, loss = 29084.00311028\n",
            "Iteration 18610, loss = 29082.67625725\n",
            "Iteration 18611, loss = 29082.21844621\n",
            "Iteration 18612, loss = 29082.08672411\n",
            "Iteration 18613, loss = 29081.18964568\n",
            "Iteration 18614, loss = 29080.07319301\n",
            "Iteration 18615, loss = 29079.68496372\n",
            "Iteration 18616, loss = 29079.14818620\n",
            "Iteration 18617, loss = 29078.09503947\n",
            "Iteration 18618, loss = 29077.66323825\n",
            "Iteration 18619, loss = 29077.59436723\n",
            "Iteration 18620, loss = 29076.95925833\n",
            "Iteration 18621, loss = 29076.08175749\n",
            "Iteration 18622, loss = 29075.28702957\n",
            "Iteration 18623, loss = 29074.09670236\n",
            "Iteration 18624, loss = 29073.35962864\n",
            "Iteration 18625, loss = 29073.25941473\n",
            "Iteration 18626, loss = 29072.03961606\n",
            "Iteration 18627, loss = 29070.44480341\n",
            "Iteration 18628, loss = 29070.05943420\n",
            "Iteration 18629, loss = 29069.62396752\n",
            "Iteration 18630, loss = 29069.46245539\n",
            "Iteration 18631, loss = 29068.10835492\n",
            "Iteration 18632, loss = 29066.40544655\n",
            "Iteration 18633, loss = 29066.72071765\n",
            "Iteration 18634, loss = 29066.45900948\n",
            "Iteration 18635, loss = 29065.86894428\n",
            "Iteration 18636, loss = 29064.31288555\n",
            "Iteration 18637, loss = 29063.07852122\n",
            "Iteration 18638, loss = 29063.86482430\n",
            "Iteration 18639, loss = 29063.39514025\n",
            "Iteration 18640, loss = 29062.53778014\n",
            "Iteration 18641, loss = 29060.99143723\n",
            "Iteration 18642, loss = 29059.94270621\n",
            "Iteration 18643, loss = 29058.77834220\n",
            "Iteration 18644, loss = 29058.23475487\n",
            "Iteration 18645, loss = 29057.46328227\n",
            "Iteration 18646, loss = 29056.98999900\n",
            "Iteration 18647, loss = 29055.63942485\n",
            "Iteration 18648, loss = 29054.55424856\n",
            "Iteration 18649, loss = 29054.99968165\n",
            "Iteration 18650, loss = 29054.68853926\n",
            "Iteration 18651, loss = 29052.97489033\n",
            "Iteration 18652, loss = 29051.64007224\n",
            "Iteration 18653, loss = 29051.98381488\n",
            "Iteration 18654, loss = 29051.86019160\n",
            "Iteration 18655, loss = 29050.25128940\n",
            "Iteration 18656, loss = 29049.06327575\n",
            "Iteration 18657, loss = 29048.86331046\n",
            "Iteration 18658, loss = 29047.98060817\n",
            "Iteration 18659, loss = 29046.50710877\n",
            "Iteration 18660, loss = 29045.58991568\n",
            "Iteration 18661, loss = 29045.41666540\n",
            "Iteration 18662, loss = 29044.71203793\n",
            "Iteration 18663, loss = 29043.33218629\n",
            "Iteration 18664, loss = 29042.96548319\n",
            "Iteration 18665, loss = 29042.11353500\n",
            "Iteration 18666, loss = 29041.02972386\n",
            "Iteration 18667, loss = 29040.10070278\n",
            "Iteration 18668, loss = 29039.72767084\n",
            "Iteration 18669, loss = 29038.56179555\n",
            "Iteration 18670, loss = 29037.63456047\n",
            "Iteration 18671, loss = 29038.19186279\n",
            "Iteration 18672, loss = 29037.36257330\n",
            "Iteration 18673, loss = 29035.85403298\n",
            "Iteration 18674, loss = 29035.38088081\n",
            "Iteration 18675, loss = 29033.98801718\n",
            "Iteration 18676, loss = 29035.05683724\n",
            "Iteration 18677, loss = 29033.76781815\n",
            "Iteration 18678, loss = 29032.96251013\n",
            "Iteration 18679, loss = 29033.19262558\n",
            "Iteration 18680, loss = 29032.14137003\n",
            "Iteration 18681, loss = 29031.00669796\n",
            "Iteration 18682, loss = 29030.50456468\n",
            "Iteration 18683, loss = 29030.17817426\n",
            "Iteration 18684, loss = 29028.45101154\n",
            "Iteration 18685, loss = 29027.91501656\n",
            "Iteration 18686, loss = 29026.51175034\n",
            "Iteration 18687, loss = 29026.27048640\n",
            "Iteration 18688, loss = 29025.51637793\n",
            "Iteration 18689, loss = 29024.89672335\n",
            "Iteration 18690, loss = 29024.01842988\n",
            "Iteration 18691, loss = 29024.42331246\n",
            "Iteration 18692, loss = 29022.63232901\n",
            "Iteration 18693, loss = 29021.56724064\n",
            "Iteration 18694, loss = 29021.02879043\n",
            "Iteration 18695, loss = 29019.88942343\n",
            "Iteration 18696, loss = 29019.47417111\n",
            "Iteration 18697, loss = 29018.53927153\n",
            "Iteration 18698, loss = 29018.15342477\n",
            "Iteration 18699, loss = 29017.33100963\n",
            "Iteration 18700, loss = 29016.51685662\n",
            "Iteration 18701, loss = 29016.68739065\n",
            "Iteration 18702, loss = 29016.06641108\n",
            "Iteration 18703, loss = 29014.87537473\n",
            "Iteration 18704, loss = 29014.01575078\n",
            "Iteration 18705, loss = 29013.62651918\n",
            "Iteration 18706, loss = 29012.06345254\n",
            "Iteration 18707, loss = 29011.23437666\n",
            "Iteration 18708, loss = 29010.33825337\n",
            "Iteration 18709, loss = 29010.53724661\n",
            "Iteration 18710, loss = 29009.30292788\n",
            "Iteration 18711, loss = 29008.37058890\n",
            "Iteration 18712, loss = 29008.70593650\n",
            "Iteration 18713, loss = 29008.14288599\n",
            "Iteration 18714, loss = 29006.85197438\n",
            "Iteration 18715, loss = 29006.01427148\n",
            "Iteration 18716, loss = 29005.71331461\n",
            "Iteration 18717, loss = 29005.07021061\n",
            "Iteration 18718, loss = 29004.05193736\n",
            "Iteration 18719, loss = 29003.39312709\n",
            "Iteration 18720, loss = 29003.16302254\n",
            "Iteration 18721, loss = 29002.11218558\n",
            "Iteration 18722, loss = 29002.44391383\n",
            "Iteration 18723, loss = 29002.23914576\n",
            "Iteration 18724, loss = 29000.29545602\n",
            "Iteration 18725, loss = 28998.57269395\n",
            "Iteration 18726, loss = 28999.05491258\n",
            "Iteration 18727, loss = 28997.96344522\n",
            "Iteration 18728, loss = 28996.82992460\n",
            "Iteration 18729, loss = 28996.08981480\n",
            "Iteration 18730, loss = 28995.51486137\n",
            "Iteration 18731, loss = 28995.65488328\n",
            "Iteration 18732, loss = 28994.53308256\n",
            "Iteration 18733, loss = 28993.23783959\n",
            "Iteration 18734, loss = 28993.09668225\n",
            "Iteration 18735, loss = 28992.78896374\n",
            "Iteration 18736, loss = 28991.14459445\n",
            "Iteration 18737, loss = 28990.78203215\n",
            "Iteration 18738, loss = 28990.27348103\n",
            "Iteration 18739, loss = 28989.68036871\n",
            "Iteration 18740, loss = 28988.70658242\n",
            "Iteration 18741, loss = 28987.74166148\n",
            "Iteration 18742, loss = 28988.07882210\n",
            "Iteration 18743, loss = 28986.88444281\n",
            "Iteration 18744, loss = 28985.37573292\n",
            "Iteration 18745, loss = 28985.70778372\n",
            "Iteration 18746, loss = 28985.10001760\n",
            "Iteration 18747, loss = 28983.93549361\n",
            "Iteration 18748, loss = 28982.89773431\n",
            "Iteration 18749, loss = 28982.24097316\n",
            "Iteration 18750, loss = 28981.62972043\n",
            "Iteration 18751, loss = 28981.50848766\n",
            "Iteration 18752, loss = 28980.30416450\n",
            "Iteration 18753, loss = 28979.30232720\n",
            "Iteration 18754, loss = 28978.54825687\n",
            "Iteration 18755, loss = 28978.24742485\n",
            "Iteration 18756, loss = 28979.09831125\n",
            "Iteration 18757, loss = 28977.96417713\n",
            "Iteration 18758, loss = 28975.98604421\n",
            "Iteration 18759, loss = 28975.35822522\n",
            "Iteration 18760, loss = 28974.57668351\n",
            "Iteration 18761, loss = 28973.60672471\n",
            "Iteration 18762, loss = 28973.47458879\n",
            "Iteration 18763, loss = 28972.44051087\n",
            "Iteration 18764, loss = 28970.98043211\n",
            "Iteration 18765, loss = 28970.00260295\n",
            "Iteration 18766, loss = 28970.22432700\n",
            "Iteration 18767, loss = 28968.98168839\n",
            "Iteration 18768, loss = 28968.53556769\n",
            "Iteration 18769, loss = 28967.53830045\n",
            "Iteration 18770, loss = 28967.86083587\n",
            "Iteration 18771, loss = 28967.56257026\n",
            "Iteration 18772, loss = 28965.67524323\n",
            "Iteration 18773, loss = 28965.40899612\n",
            "Iteration 18774, loss = 28965.16514736\n",
            "Iteration 18775, loss = 28964.76180964\n",
            "Iteration 18776, loss = 28963.87506373\n",
            "Iteration 18777, loss = 28963.44901056\n",
            "Iteration 18778, loss = 28962.41406565\n",
            "Iteration 18779, loss = 28961.85823209\n",
            "Iteration 18780, loss = 28960.67267522\n",
            "Iteration 18781, loss = 28959.38031815\n",
            "Iteration 18782, loss = 28959.54701734\n",
            "Iteration 18783, loss = 28959.18559004\n",
            "Iteration 18784, loss = 28958.01442115\n",
            "Iteration 18785, loss = 28957.63406231\n",
            "Iteration 18786, loss = 28957.17291914\n",
            "Iteration 18787, loss = 28957.04823641\n",
            "Iteration 18788, loss = 28955.10424800\n",
            "Iteration 18789, loss = 28954.63696773\n",
            "Iteration 18790, loss = 28955.30833333\n",
            "Iteration 18791, loss = 28954.64383189\n",
            "Iteration 18792, loss = 28954.11643867\n",
            "Iteration 18793, loss = 28952.60550064\n",
            "Iteration 18794, loss = 28951.96626610\n",
            "Iteration 18795, loss = 28951.86251658\n",
            "Iteration 18796, loss = 28950.20283227\n",
            "Iteration 18797, loss = 28949.02720214\n",
            "Iteration 18798, loss = 28949.28151082\n",
            "Iteration 18799, loss = 28949.45525612\n",
            "Iteration 18800, loss = 28948.09496575\n",
            "Iteration 18801, loss = 28947.08401784\n",
            "Iteration 18802, loss = 28946.19020035\n",
            "Iteration 18803, loss = 28946.84762572\n",
            "Iteration 18804, loss = 28946.06885163\n",
            "Iteration 18805, loss = 28945.06391429\n",
            "Iteration 18806, loss = 28944.15549654\n",
            "Iteration 18807, loss = 28942.79096353\n",
            "Iteration 18808, loss = 28942.15929425\n",
            "Iteration 18809, loss = 28942.77026035\n",
            "Iteration 18810, loss = 28941.24229966\n",
            "Iteration 18811, loss = 28939.81460357\n",
            "Iteration 18812, loss = 28940.32628142\n",
            "Iteration 18813, loss = 28939.60461810\n",
            "Iteration 18814, loss = 28939.99467049\n",
            "Iteration 18815, loss = 28939.69118442\n",
            "Iteration 18816, loss = 28938.63090567\n",
            "Iteration 18817, loss = 28935.90597578\n",
            "Iteration 18818, loss = 28935.83806202\n",
            "Iteration 18819, loss = 28936.62507577\n",
            "Iteration 18820, loss = 28935.43033523\n",
            "Iteration 18821, loss = 28932.70146585\n",
            "Iteration 18822, loss = 28932.80232890\n",
            "Iteration 18823, loss = 28932.61305393\n",
            "Iteration 18824, loss = 28932.16629275\n",
            "Iteration 18825, loss = 28931.06240021\n",
            "Iteration 18826, loss = 28930.93140014\n",
            "Iteration 18827, loss = 28930.77805896\n",
            "Iteration 18828, loss = 28929.24341981\n",
            "Iteration 18829, loss = 28928.71711474\n",
            "Iteration 18830, loss = 28928.27365208\n",
            "Iteration 18831, loss = 28926.90717124\n",
            "Iteration 18832, loss = 28926.48521482\n",
            "Iteration 18833, loss = 28925.25673497\n",
            "Iteration 18834, loss = 28925.13629632\n",
            "Iteration 18835, loss = 28924.93717811\n",
            "Iteration 18836, loss = 28923.19875471\n",
            "Iteration 18837, loss = 28922.33312052\n",
            "Iteration 18838, loss = 28922.13494494\n",
            "Iteration 18839, loss = 28921.41482996\n",
            "Iteration 18840, loss = 28921.36221674\n",
            "Iteration 18841, loss = 28920.05420332\n",
            "Iteration 18842, loss = 28919.46607596\n",
            "Iteration 18843, loss = 28919.06306000\n",
            "Iteration 18844, loss = 28918.70162807\n",
            "Iteration 18845, loss = 28917.55999229\n",
            "Iteration 18846, loss = 28916.41865178\n",
            "Iteration 18847, loss = 28916.12002420\n",
            "Iteration 18848, loss = 28915.23002840\n",
            "Iteration 18849, loss = 28913.86101676\n",
            "Iteration 18850, loss = 28913.63264317\n",
            "Iteration 18851, loss = 28913.03548124\n",
            "Iteration 18852, loss = 28911.87320079\n",
            "Iteration 18853, loss = 28911.95789300\n",
            "Iteration 18854, loss = 28912.09127803\n",
            "Iteration 18855, loss = 28911.06757363\n",
            "Iteration 18856, loss = 28910.04039728\n",
            "Iteration 18857, loss = 28909.38003866\n",
            "Iteration 18858, loss = 28908.16707915\n",
            "Iteration 18859, loss = 28907.77817240\n",
            "Iteration 18860, loss = 28906.60579351\n",
            "Iteration 18861, loss = 28906.26659546\n",
            "Iteration 18862, loss = 28905.44359601\n",
            "Iteration 18863, loss = 28905.14639532\n",
            "Iteration 18864, loss = 28904.33919323\n",
            "Iteration 18865, loss = 28904.01466643\n",
            "Iteration 18866, loss = 28903.06560376\n",
            "Iteration 18867, loss = 28902.15283763\n",
            "Iteration 18868, loss = 28901.85687655\n",
            "Iteration 18869, loss = 28900.72623400\n",
            "Iteration 18870, loss = 28899.83649127\n",
            "Iteration 18871, loss = 28899.31802063\n",
            "Iteration 18872, loss = 28899.31957180\n",
            "Iteration 18873, loss = 28898.52159132\n",
            "Iteration 18874, loss = 28898.00746425\n",
            "Iteration 18875, loss = 28897.75038031\n",
            "Iteration 18876, loss = 28897.34059826\n",
            "Iteration 18877, loss = 28895.60327742\n",
            "Iteration 18878, loss = 28895.10528892\n",
            "Iteration 18879, loss = 28894.91761318\n",
            "Iteration 18880, loss = 28894.11271534\n",
            "Iteration 18881, loss = 28893.52800305\n",
            "Iteration 18882, loss = 28892.88612922\n",
            "Iteration 18883, loss = 28891.89102907\n",
            "Iteration 18884, loss = 28890.88846872\n",
            "Iteration 18885, loss = 28890.19439336\n",
            "Iteration 18886, loss = 28889.62131765\n",
            "Iteration 18887, loss = 28889.06211323\n",
            "Iteration 18888, loss = 28888.25924999\n",
            "Iteration 18889, loss = 28888.38594032\n",
            "Iteration 18890, loss = 28887.35166153\n",
            "Iteration 18891, loss = 28885.98217126\n",
            "Iteration 18892, loss = 28885.70905142\n",
            "Iteration 18893, loss = 28884.98935493\n",
            "Iteration 18894, loss = 28884.38212878\n",
            "Iteration 18895, loss = 28884.79018291\n",
            "Iteration 18896, loss = 28884.20098193\n",
            "Iteration 18897, loss = 28882.36313272\n",
            "Iteration 18898, loss = 28882.52518466\n",
            "Iteration 18899, loss = 28882.08490289\n",
            "Iteration 18900, loss = 28881.88948276\n",
            "Iteration 18901, loss = 28881.01196735\n",
            "Iteration 18902, loss = 28880.21056246\n",
            "Iteration 18903, loss = 28878.48732245\n",
            "Iteration 18904, loss = 28879.94511490\n",
            "Iteration 18905, loss = 28880.14792330\n",
            "Iteration 18906, loss = 28878.25547274\n",
            "Iteration 18907, loss = 28876.54406356\n",
            "Iteration 18908, loss = 28876.93848127\n",
            "Iteration 18909, loss = 28876.18622167\n",
            "Iteration 18910, loss = 28873.85461241\n",
            "Iteration 18911, loss = 28873.87069903\n",
            "Iteration 18912, loss = 28873.13737021\n",
            "Iteration 18913, loss = 28872.75941728\n",
            "Iteration 18914, loss = 28872.38349982\n",
            "Iteration 18915, loss = 28871.37786660\n",
            "Iteration 18916, loss = 28870.36800779\n",
            "Iteration 18917, loss = 28870.17574266\n",
            "Iteration 18918, loss = 28869.50442230\n",
            "Iteration 18919, loss = 28868.79476842\n",
            "Iteration 18920, loss = 28867.64956022\n",
            "Iteration 18921, loss = 28866.53245013\n",
            "Iteration 18922, loss = 28867.26089738\n",
            "Iteration 18923, loss = 28866.32237568\n",
            "Iteration 18924, loss = 28865.47665966\n",
            "Iteration 18925, loss = 28865.05013266\n",
            "Iteration 18926, loss = 28864.53917541\n",
            "Iteration 18927, loss = 28863.84036633\n",
            "Iteration 18928, loss = 28863.12441932\n",
            "Iteration 18929, loss = 28862.71017894\n",
            "Iteration 18930, loss = 28861.76270618\n",
            "Iteration 18931, loss = 28861.10562662\n",
            "Iteration 18932, loss = 28860.06347066\n",
            "Iteration 18933, loss = 28859.40608264\n",
            "Iteration 18934, loss = 28858.41292276\n",
            "Iteration 18935, loss = 28858.75791660\n",
            "Iteration 18936, loss = 28858.65216742\n",
            "Iteration 18937, loss = 28857.51318584\n",
            "Iteration 18938, loss = 28857.35888684\n",
            "Iteration 18939, loss = 28856.36767017\n",
            "Iteration 18940, loss = 28855.14316580\n",
            "Iteration 18941, loss = 28854.99428411\n",
            "Iteration 18942, loss = 28854.69489709\n",
            "Iteration 18943, loss = 28853.32937316\n",
            "Iteration 18944, loss = 28853.05533865\n",
            "Iteration 18945, loss = 28852.70782523\n",
            "Iteration 18946, loss = 28851.82032670\n",
            "Iteration 18947, loss = 28851.14339791\n",
            "Iteration 18948, loss = 28850.43525903\n",
            "Iteration 18949, loss = 28849.62161153\n",
            "Iteration 18950, loss = 28849.59442326\n",
            "Iteration 18951, loss = 28848.47765326\n",
            "Iteration 18952, loss = 28848.04140757\n",
            "Iteration 18953, loss = 28848.47462854\n",
            "Iteration 18954, loss = 28847.12205058\n",
            "Iteration 18955, loss = 28845.58325978\n",
            "Iteration 18956, loss = 28845.52088677\n",
            "Iteration 18957, loss = 28845.45442843\n",
            "Iteration 18958, loss = 28843.67509757\n",
            "Iteration 18959, loss = 28843.55126759\n",
            "Iteration 18960, loss = 28844.23509780\n",
            "Iteration 18961, loss = 28844.24923009\n",
            "Iteration 18962, loss = 28842.56025617\n",
            "Iteration 18963, loss = 28841.71178276\n",
            "Iteration 18964, loss = 28840.99189058\n",
            "Iteration 18965, loss = 28840.39084319\n",
            "Iteration 18966, loss = 28840.36729891\n",
            "Iteration 18967, loss = 28839.33070304\n",
            "Iteration 18968, loss = 28837.99160706\n",
            "Iteration 18969, loss = 28837.37453362\n",
            "Iteration 18970, loss = 28837.03095364\n",
            "Iteration 18971, loss = 28836.25475651\n",
            "Iteration 18972, loss = 28834.85019022\n",
            "Iteration 18973, loss = 28835.18313377\n",
            "Iteration 18974, loss = 28835.37392826\n",
            "Iteration 18975, loss = 28833.59829459\n",
            "Iteration 18976, loss = 28832.62563702\n",
            "Iteration 18977, loss = 28832.77229281\n",
            "Iteration 18978, loss = 28832.48946403\n",
            "Iteration 18979, loss = 28831.44876664\n",
            "Iteration 18980, loss = 28830.34584584\n",
            "Iteration 18981, loss = 28828.87479544\n",
            "Iteration 18982, loss = 28829.00337087\n",
            "Iteration 18983, loss = 28828.48003999\n",
            "Iteration 18984, loss = 28827.25884723\n",
            "Iteration 18985, loss = 28826.48385511\n",
            "Iteration 18986, loss = 28826.64630138\n",
            "Iteration 18987, loss = 28825.22000042\n",
            "Iteration 18988, loss = 28825.02866857\n",
            "Iteration 18989, loss = 28824.86939678\n",
            "Iteration 18990, loss = 28824.21357563\n",
            "Iteration 18991, loss = 28823.01575630\n",
            "Iteration 18992, loss = 28823.17410023\n",
            "Iteration 18993, loss = 28822.43066925\n",
            "Iteration 18994, loss = 28820.99228092\n",
            "Iteration 18995, loss = 28820.62176138\n",
            "Iteration 18996, loss = 28819.65604979\n",
            "Iteration 18997, loss = 28819.12714503\n",
            "Iteration 18998, loss = 28818.44924258\n",
            "Iteration 18999, loss = 28818.03393427\n",
            "Iteration 19000, loss = 28818.06613745\n",
            "Iteration 19001, loss = 28817.20317554\n",
            "Iteration 19002, loss = 28816.88099419\n",
            "Iteration 19003, loss = 28816.00886760\n",
            "Iteration 19004, loss = 28814.79661917\n",
            "Iteration 19005, loss = 28814.26006610\n",
            "Iteration 19006, loss = 28813.74411220\n",
            "Iteration 19007, loss = 28813.31091729\n",
            "Iteration 19008, loss = 28812.70450411\n",
            "Iteration 19009, loss = 28812.87726168\n",
            "Iteration 19010, loss = 28812.39942595\n",
            "Iteration 19011, loss = 28810.85870831\n",
            "Iteration 19012, loss = 28810.61002022\n",
            "Iteration 19013, loss = 28810.16018075\n",
            "Iteration 19014, loss = 28809.91748701\n",
            "Iteration 19015, loss = 28809.46488620\n",
            "Iteration 19016, loss = 28808.02500820\n",
            "Iteration 19017, loss = 28806.33920899\n",
            "Iteration 19018, loss = 28806.96971085\n",
            "Iteration 19019, loss = 28807.21417944\n",
            "Iteration 19020, loss = 28806.56178742\n",
            "Iteration 19021, loss = 28804.42554361\n",
            "Iteration 19022, loss = 28804.02044911\n",
            "Iteration 19023, loss = 28804.14632563\n",
            "Iteration 19024, loss = 28803.30330845\n",
            "Iteration 19025, loss = 28801.93054846\n",
            "Iteration 19026, loss = 28801.73194317\n",
            "Iteration 19027, loss = 28800.99377888\n",
            "Iteration 19028, loss = 28799.73558100\n",
            "Iteration 19029, loss = 28799.24306055\n",
            "Iteration 19030, loss = 28799.26881133\n",
            "Iteration 19031, loss = 28798.71360569\n",
            "Iteration 19032, loss = 28797.90809352\n",
            "Iteration 19033, loss = 28796.88099207\n",
            "Iteration 19034, loss = 28796.03765215\n",
            "Iteration 19035, loss = 28796.38695343\n",
            "Iteration 19036, loss = 28796.62796671\n",
            "Iteration 19037, loss = 28795.46609858\n",
            "Iteration 19038, loss = 28794.88429506\n",
            "Iteration 19039, loss = 28793.59603033\n",
            "Iteration 19040, loss = 28793.97933585\n",
            "Iteration 19041, loss = 28793.62710449\n",
            "Iteration 19042, loss = 28791.62042588\n",
            "Iteration 19043, loss = 28791.13468801\n",
            "Iteration 19044, loss = 28791.63866083\n",
            "Iteration 19045, loss = 28790.74649771\n",
            "Iteration 19046, loss = 28789.26274856\n",
            "Iteration 19047, loss = 28788.11763017\n",
            "Iteration 19048, loss = 28788.07218644\n",
            "Iteration 19049, loss = 28787.76444726\n",
            "Iteration 19050, loss = 28785.99621046\n",
            "Iteration 19051, loss = 28785.27871961\n",
            "Iteration 19052, loss = 28784.45501700\n",
            "Iteration 19053, loss = 28784.05841703\n",
            "Iteration 19054, loss = 28784.24295908\n",
            "Iteration 19055, loss = 28783.37511472\n",
            "Iteration 19056, loss = 28783.60440532\n",
            "Iteration 19057, loss = 28782.59748082\n",
            "Iteration 19058, loss = 28781.28391892\n",
            "Iteration 19059, loss = 28781.47592114\n",
            "Iteration 19060, loss = 28780.42918043\n",
            "Iteration 19061, loss = 28779.14079484\n",
            "Iteration 19062, loss = 28779.31517285\n",
            "Iteration 19063, loss = 28779.33353522\n",
            "Iteration 19064, loss = 28778.62810629\n",
            "Iteration 19065, loss = 28778.12244440\n",
            "Iteration 19066, loss = 28776.55211534\n",
            "Iteration 19067, loss = 28776.32378534\n",
            "Iteration 19068, loss = 28776.22641136\n",
            "Iteration 19069, loss = 28775.06603921\n",
            "Iteration 19070, loss = 28773.97992756\n",
            "Iteration 19071, loss = 28773.60983297\n",
            "Iteration 19072, loss = 28772.77016816\n",
            "Iteration 19073, loss = 28773.45301826\n",
            "Iteration 19074, loss = 28772.70079954\n",
            "Iteration 19075, loss = 28770.69775052\n",
            "Iteration 19076, loss = 28770.90573697\n",
            "Iteration 19077, loss = 28771.86563846\n",
            "Iteration 19078, loss = 28771.25872286\n",
            "Iteration 19079, loss = 28770.18409180\n",
            "Iteration 19080, loss = 28768.76031033\n",
            "Iteration 19081, loss = 28767.72432519\n",
            "Iteration 19082, loss = 28766.90799505\n",
            "Iteration 19083, loss = 28766.68384630\n",
            "Iteration 19084, loss = 28765.73180334\n",
            "Iteration 19085, loss = 28765.82464581\n",
            "Iteration 19086, loss = 28765.42965193\n",
            "Iteration 19087, loss = 28764.06168338\n",
            "Iteration 19088, loss = 28764.21196463\n",
            "Iteration 19089, loss = 28762.76404617\n",
            "Iteration 19090, loss = 28761.60162787\n",
            "Iteration 19091, loss = 28762.06673579\n",
            "Iteration 19092, loss = 28760.95287676\n",
            "Iteration 19093, loss = 28760.90084852\n",
            "Iteration 19094, loss = 28760.23102394\n",
            "Iteration 19095, loss = 28760.11519461\n",
            "Iteration 19096, loss = 28758.87853798\n",
            "Iteration 19097, loss = 28758.36049109\n",
            "Iteration 19098, loss = 28757.41527426\n",
            "Iteration 19099, loss = 28757.54377862\n",
            "Iteration 19100, loss = 28757.90488446\n",
            "Iteration 19101, loss = 28756.88444652\n",
            "Iteration 19102, loss = 28754.54997489\n",
            "Iteration 19103, loss = 28754.67421223\n",
            "Iteration 19104, loss = 28753.98985101\n",
            "Iteration 19105, loss = 28752.74770103\n",
            "Iteration 19106, loss = 28752.01856307\n",
            "Iteration 19107, loss = 28751.27075050\n",
            "Iteration 19108, loss = 28751.21541442\n",
            "Iteration 19109, loss = 28750.85460387\n",
            "Iteration 19110, loss = 28750.35582800\n",
            "Iteration 19111, loss = 28748.51149908\n",
            "Iteration 19112, loss = 28748.34574675\n",
            "Iteration 19113, loss = 28748.42126375\n",
            "Iteration 19114, loss = 28747.50173114\n",
            "Iteration 19115, loss = 28746.91249673\n",
            "Iteration 19116, loss = 28745.43784553\n",
            "Iteration 19117, loss = 28745.77781558\n",
            "Iteration 19118, loss = 28745.69009170\n",
            "Iteration 19119, loss = 28744.47506314\n",
            "Iteration 19120, loss = 28743.86140026\n",
            "Iteration 19121, loss = 28743.71457673\n",
            "Iteration 19122, loss = 28742.39814715\n",
            "Iteration 19123, loss = 28742.20799033\n",
            "Iteration 19124, loss = 28741.76098912\n",
            "Iteration 19125, loss = 28740.23865858\n",
            "Iteration 19126, loss = 28740.49499817\n",
            "Iteration 19127, loss = 28740.88458607\n",
            "Iteration 19128, loss = 28739.40320004\n",
            "Iteration 19129, loss = 28739.50130668\n",
            "Iteration 19130, loss = 28738.85152238\n",
            "Iteration 19131, loss = 28737.27346661\n",
            "Iteration 19132, loss = 28736.84502191\n",
            "Iteration 19133, loss = 28737.50640696\n",
            "Iteration 19134, loss = 28736.96500034\n",
            "Iteration 19135, loss = 28735.70317705\n",
            "Iteration 19136, loss = 28734.41388886\n",
            "Iteration 19137, loss = 28733.66326784\n",
            "Iteration 19138, loss = 28733.50228406\n",
            "Iteration 19139, loss = 28733.12619954\n",
            "Iteration 19140, loss = 28732.56866343\n",
            "Iteration 19141, loss = 28731.07487159\n",
            "Iteration 19142, loss = 28730.93185336\n",
            "Iteration 19143, loss = 28730.22143125\n",
            "Iteration 19144, loss = 28729.49202281\n",
            "Iteration 19145, loss = 28728.23042778\n",
            "Iteration 19146, loss = 28729.16260947\n",
            "Iteration 19147, loss = 28728.76610601\n",
            "Iteration 19148, loss = 28727.16685565\n",
            "Iteration 19149, loss = 28726.83436245\n",
            "Iteration 19150, loss = 28726.98125151\n",
            "Iteration 19151, loss = 28726.09809329\n",
            "Iteration 19152, loss = 28726.07617336\n",
            "Iteration 19153, loss = 28724.93272911\n",
            "Iteration 19154, loss = 28722.93842422\n",
            "Iteration 19155, loss = 28721.86875802\n",
            "Iteration 19156, loss = 28722.20546379\n",
            "Iteration 19157, loss = 28721.90877717\n",
            "Iteration 19158, loss = 28721.79315611\n",
            "Iteration 19159, loss = 28720.97571303\n",
            "Iteration 19160, loss = 28718.93311397\n",
            "Iteration 19161, loss = 28718.61908718\n",
            "Iteration 19162, loss = 28718.69737395\n",
            "Iteration 19163, loss = 28717.76766843\n",
            "Iteration 19164, loss = 28716.38284220\n",
            "Iteration 19165, loss = 28716.25044694\n",
            "Iteration 19166, loss = 28716.45960228\n",
            "Iteration 19167, loss = 28716.34702945\n",
            "Iteration 19168, loss = 28714.95445791\n",
            "Iteration 19169, loss = 28713.80331822\n",
            "Iteration 19170, loss = 28713.51263233\n",
            "Iteration 19171, loss = 28713.11342382\n",
            "Iteration 19172, loss = 28712.57122902\n",
            "Iteration 19173, loss = 28711.41517403\n",
            "Iteration 19174, loss = 28710.63529770\n",
            "Iteration 19175, loss = 28710.53538761\n",
            "Iteration 19176, loss = 28709.66911122\n",
            "Iteration 19177, loss = 28709.38826718\n",
            "Iteration 19178, loss = 28708.99821643\n",
            "Iteration 19179, loss = 28708.07688805\n",
            "Iteration 19180, loss = 28707.63309604\n",
            "Iteration 19181, loss = 28706.70142270\n",
            "Iteration 19182, loss = 28706.58085812\n",
            "Iteration 19183, loss = 28706.08313803\n",
            "Iteration 19184, loss = 28704.09344304\n",
            "Iteration 19185, loss = 28704.28205752\n",
            "Iteration 19186, loss = 28704.98522376\n",
            "Iteration 19187, loss = 28704.19220771\n",
            "Iteration 19188, loss = 28704.10317380\n",
            "Iteration 19189, loss = 28703.22463100\n",
            "Iteration 19190, loss = 28701.33771862\n",
            "Iteration 19191, loss = 28700.87175282\n",
            "Iteration 19192, loss = 28700.49039706\n",
            "Iteration 19193, loss = 28699.52537245\n",
            "Iteration 19194, loss = 28698.91881401\n",
            "Iteration 19195, loss = 28698.69058675\n",
            "Iteration 19196, loss = 28698.10677921\n",
            "Iteration 19197, loss = 28698.02175055\n",
            "Iteration 19198, loss = 28696.71203427\n",
            "Iteration 19199, loss = 28696.63705737\n",
            "Iteration 19200, loss = 28696.77756009\n",
            "Iteration 19201, loss = 28694.75266666\n",
            "Iteration 19202, loss = 28694.74496894\n",
            "Iteration 19203, loss = 28694.72061348\n",
            "Iteration 19204, loss = 28694.42567289\n",
            "Iteration 19205, loss = 28693.36716153\n",
            "Iteration 19206, loss = 28692.05548973\n",
            "Iteration 19207, loss = 28690.85260301\n",
            "Iteration 19208, loss = 28691.32005737\n",
            "Iteration 19209, loss = 28691.95970118\n",
            "Iteration 19210, loss = 28690.26595096\n",
            "Iteration 19211, loss = 28688.52426013\n",
            "Iteration 19212, loss = 28689.62212731\n",
            "Iteration 19213, loss = 28689.65999617\n",
            "Iteration 19214, loss = 28687.69726704\n",
            "Iteration 19215, loss = 28685.54956119\n",
            "Iteration 19216, loss = 28685.98434377\n",
            "Iteration 19217, loss = 28685.86206721\n",
            "Iteration 19218, loss = 28685.17614663\n",
            "Iteration 19219, loss = 28684.03932333\n",
            "Iteration 19220, loss = 28683.55387798\n",
            "Iteration 19221, loss = 28682.22687711\n",
            "Iteration 19222, loss = 28682.58851495\n",
            "Iteration 19223, loss = 28682.81689793\n",
            "Iteration 19224, loss = 28682.00012132\n",
            "Iteration 19225, loss = 28681.27542425\n",
            "Iteration 19226, loss = 28681.01859210\n",
            "Iteration 19227, loss = 28680.75804901\n",
            "Iteration 19228, loss = 28680.81280115\n",
            "Iteration 19229, loss = 28678.98813420\n",
            "Iteration 19230, loss = 28677.50500028\n",
            "Iteration 19231, loss = 28677.55342842\n",
            "Iteration 19232, loss = 28677.61975112\n",
            "Iteration 19233, loss = 28677.63640841\n",
            "Iteration 19234, loss = 28676.65737979\n",
            "Iteration 19235, loss = 28674.97408787\n",
            "Iteration 19236, loss = 28674.59320518\n",
            "Iteration 19237, loss = 28673.83453677\n",
            "Iteration 19238, loss = 28672.00165635\n",
            "Iteration 19239, loss = 28671.76156997\n",
            "Iteration 19240, loss = 28671.76041360\n",
            "Iteration 19241, loss = 28670.94927587\n",
            "Iteration 19242, loss = 28669.68550773\n",
            "Iteration 19243, loss = 28669.48116068\n",
            "Iteration 19244, loss = 28668.50895110\n",
            "Iteration 19245, loss = 28668.24181320\n",
            "Iteration 19246, loss = 28667.80797943\n",
            "Iteration 19247, loss = 28667.62420748\n",
            "Iteration 19248, loss = 28666.36059941\n",
            "Iteration 19249, loss = 28665.47631840\n",
            "Iteration 19250, loss = 28664.72101171\n",
            "Iteration 19251, loss = 28664.87338499\n",
            "Iteration 19252, loss = 28664.33786908\n",
            "Iteration 19253, loss = 28663.16208171\n",
            "Iteration 19254, loss = 28662.13543218\n",
            "Iteration 19255, loss = 28662.80754453\n",
            "Iteration 19256, loss = 28661.90671095\n",
            "Iteration 19257, loss = 28661.08726508\n",
            "Iteration 19258, loss = 28661.13650274\n",
            "Iteration 19259, loss = 28661.17512303\n",
            "Iteration 19260, loss = 28660.28226426\n",
            "Iteration 19261, loss = 28659.70616910\n",
            "Iteration 19262, loss = 28658.91739495\n",
            "Iteration 19263, loss = 28657.26676623\n",
            "Iteration 19264, loss = 28657.12141632\n",
            "Iteration 19265, loss = 28657.50682019\n",
            "Iteration 19266, loss = 28655.70473629\n",
            "Iteration 19267, loss = 28655.50168314\n",
            "Iteration 19268, loss = 28655.20464323\n",
            "Iteration 19269, loss = 28654.48074326\n",
            "Iteration 19270, loss = 28654.68718590\n",
            "Iteration 19271, loss = 28653.70475198\n",
            "Iteration 19272, loss = 28654.30910626\n",
            "Iteration 19273, loss = 28653.19426070\n",
            "Iteration 19274, loss = 28652.47177092\n",
            "Iteration 19275, loss = 28652.32153196\n",
            "Iteration 19276, loss = 28651.06756121\n",
            "Iteration 19277, loss = 28650.41754928\n",
            "Iteration 19278, loss = 28650.04343193\n",
            "Iteration 19279, loss = 28649.71415635\n",
            "Iteration 19280, loss = 28648.06845855\n",
            "Iteration 19281, loss = 28646.89893825\n",
            "Iteration 19282, loss = 28646.28341607\n",
            "Iteration 19283, loss = 28645.61220081\n",
            "Iteration 19284, loss = 28645.40316806\n",
            "Iteration 19285, loss = 28645.27787018\n",
            "Iteration 19286, loss = 28643.79833405\n",
            "Iteration 19287, loss = 28643.81312939\n",
            "Iteration 19288, loss = 28644.07789817\n",
            "Iteration 19289, loss = 28643.30281194\n",
            "Iteration 19290, loss = 28641.86826283\n",
            "Iteration 19291, loss = 28641.06329561\n",
            "Iteration 19292, loss = 28641.73765657\n",
            "Iteration 19293, loss = 28641.19658864\n",
            "Iteration 19294, loss = 28640.79594592\n",
            "Iteration 19295, loss = 28639.37339207\n",
            "Iteration 19296, loss = 28638.83902721\n",
            "Iteration 19297, loss = 28637.89835684\n",
            "Iteration 19298, loss = 28637.80260385\n",
            "Iteration 19299, loss = 28636.26277482\n",
            "Iteration 19300, loss = 28636.18574212\n",
            "Iteration 19301, loss = 28636.86118423\n",
            "Iteration 19302, loss = 28635.67198349\n",
            "Iteration 19303, loss = 28635.23855065\n",
            "Iteration 19304, loss = 28634.49854450\n",
            "Iteration 19305, loss = 28634.41613826\n",
            "Iteration 19306, loss = 28633.56344699\n",
            "Iteration 19307, loss = 28632.42307319\n",
            "Iteration 19308, loss = 28631.54625732\n",
            "Iteration 19309, loss = 28631.50069329\n",
            "Iteration 19310, loss = 28631.64081654\n",
            "Iteration 19311, loss = 28630.27768280\n",
            "Iteration 19312, loss = 28629.44146199\n",
            "Iteration 19313, loss = 28629.66681462\n",
            "Iteration 19314, loss = 28628.35216590\n",
            "Iteration 19315, loss = 28628.65487805\n",
            "Iteration 19316, loss = 28627.88398516\n",
            "Iteration 19317, loss = 28628.24761858\n",
            "Iteration 19318, loss = 28627.85024792\n",
            "Iteration 19319, loss = 28625.43041518\n",
            "Iteration 19320, loss = 28625.61687502\n",
            "Iteration 19321, loss = 28625.60573419\n",
            "Iteration 19322, loss = 28624.49325184\n",
            "Iteration 19323, loss = 28624.80290689\n",
            "Iteration 19324, loss = 28623.58444755\n",
            "Iteration 19325, loss = 28622.78002032\n",
            "Iteration 19326, loss = 28622.64077261\n",
            "Iteration 19327, loss = 28621.33379499\n",
            "Iteration 19328, loss = 28621.51314324\n",
            "Iteration 19329, loss = 28621.04914121\n",
            "Iteration 19330, loss = 28620.07654096\n",
            "Iteration 19331, loss = 28619.43715072\n",
            "Iteration 19332, loss = 28620.42613676\n",
            "Iteration 19333, loss = 28620.48343868\n",
            "Iteration 19334, loss = 28618.91583815\n",
            "Iteration 19335, loss = 28617.43531732\n",
            "Iteration 19336, loss = 28618.26131606\n",
            "Iteration 19337, loss = 28617.54952064\n",
            "Iteration 19338, loss = 28616.47308618\n",
            "Iteration 19339, loss = 28616.16968696\n",
            "Iteration 19340, loss = 28615.56314900\n",
            "Iteration 19341, loss = 28614.37667819\n",
            "Iteration 19342, loss = 28614.67748358\n",
            "Iteration 19343, loss = 28614.61967259\n",
            "Iteration 19344, loss = 28612.63712777\n",
            "Iteration 19345, loss = 28612.92991120\n",
            "Iteration 19346, loss = 28613.29793773\n",
            "Iteration 19347, loss = 28613.05496814\n",
            "Iteration 19348, loss = 28611.64237444\n",
            "Iteration 19349, loss = 28610.61707748\n",
            "Iteration 19350, loss = 28610.48093458\n",
            "Iteration 19351, loss = 28610.37984873\n",
            "Iteration 19352, loss = 28609.48074698\n",
            "Iteration 19353, loss = 28607.89237924\n",
            "Iteration 19354, loss = 28606.99028908\n",
            "Iteration 19355, loss = 28606.94482939\n",
            "Iteration 19356, loss = 28606.73969046\n",
            "Iteration 19357, loss = 28606.03219157\n",
            "Iteration 19358, loss = 28604.85062271\n",
            "Iteration 19359, loss = 28605.08367575\n",
            "Iteration 19360, loss = 28604.36522347\n",
            "Iteration 19361, loss = 28602.67217900\n",
            "Iteration 19362, loss = 28602.73487219\n",
            "Iteration 19363, loss = 28603.00539060\n",
            "Iteration 19364, loss = 28602.50264680\n",
            "Iteration 19365, loss = 28601.84247275\n",
            "Iteration 19366, loss = 28600.91585953\n",
            "Iteration 19367, loss = 28599.34486760\n",
            "Iteration 19368, loss = 28600.12476977\n",
            "Iteration 19369, loss = 28601.03991237\n",
            "Iteration 19370, loss = 28599.64830447\n",
            "Iteration 19371, loss = 28597.66319509\n",
            "Iteration 19372, loss = 28597.20903962\n",
            "Iteration 19373, loss = 28597.59225713\n",
            "Iteration 19374, loss = 28597.02530791\n",
            "Iteration 19375, loss = 28596.47706926\n",
            "Iteration 19376, loss = 28596.25029402\n",
            "Iteration 19377, loss = 28595.25942960\n",
            "Iteration 19378, loss = 28595.04257198\n",
            "Iteration 19379, loss = 28594.88726249\n",
            "Iteration 19380, loss = 28594.27957864\n",
            "Iteration 19381, loss = 28592.74623632\n",
            "Iteration 19382, loss = 28592.98834533\n",
            "Iteration 19383, loss = 28592.57197305\n",
            "Iteration 19384, loss = 28591.66778157\n",
            "Iteration 19385, loss = 28590.24774733\n",
            "Iteration 19386, loss = 28589.97078444\n",
            "Iteration 19387, loss = 28589.69461320\n",
            "Iteration 19388, loss = 28589.82360050\n",
            "Iteration 19389, loss = 28589.35297427\n",
            "Iteration 19390, loss = 28587.79226150\n",
            "Iteration 19391, loss = 28586.66691048\n",
            "Iteration 19392, loss = 28586.82977575\n",
            "Iteration 19393, loss = 28586.19053562\n",
            "Iteration 19394, loss = 28584.94267529\n",
            "Iteration 19395, loss = 28585.26431102\n",
            "Iteration 19396, loss = 28584.27374546\n",
            "Iteration 19397, loss = 28583.20503260\n",
            "Iteration 19398, loss = 28582.93235794\n",
            "Iteration 19399, loss = 28582.42954335\n",
            "Iteration 19400, loss = 28581.84580953\n",
            "Iteration 19401, loss = 28581.84255588\n",
            "Iteration 19402, loss = 28581.18646356\n",
            "Iteration 19403, loss = 28580.04355724\n",
            "Iteration 19404, loss = 28580.68435300\n",
            "Iteration 19405, loss = 28580.53027638\n",
            "Iteration 19406, loss = 28580.13361266\n",
            "Iteration 19407, loss = 28579.36183471\n",
            "Iteration 19408, loss = 28578.86332444\n",
            "Iteration 19409, loss = 28577.43975994\n",
            "Iteration 19410, loss = 28577.21803322\n",
            "Iteration 19411, loss = 28577.07765183\n",
            "Iteration 19412, loss = 28575.36944340\n",
            "Iteration 19413, loss = 28575.22791564\n",
            "Iteration 19414, loss = 28576.02220048\n",
            "Iteration 19415, loss = 28575.63715063\n",
            "Iteration 19416, loss = 28574.58295864\n",
            "Iteration 19417, loss = 28572.67017630\n",
            "Iteration 19418, loss = 28572.18175206\n",
            "Iteration 19419, loss = 28572.33075691\n",
            "Iteration 19420, loss = 28572.04386759\n",
            "Iteration 19421, loss = 28571.46253248\n",
            "Iteration 19422, loss = 28570.19844547\n",
            "Iteration 19423, loss = 28569.45944534\n",
            "Iteration 19424, loss = 28570.14797434\n",
            "Iteration 19425, loss = 28569.92488596\n",
            "Iteration 19426, loss = 28569.73974119\n",
            "Iteration 19427, loss = 28568.58204660\n",
            "Iteration 19428, loss = 28566.34533483\n",
            "Iteration 19429, loss = 28567.68056072\n",
            "Iteration 19430, loss = 28567.60097958\n",
            "Iteration 19431, loss = 28566.77241648\n",
            "Iteration 19432, loss = 28566.75015283\n",
            "Iteration 19433, loss = 28566.17026197\n",
            "Iteration 19434, loss = 28564.04012881\n",
            "Iteration 19435, loss = 28562.41301116\n",
            "Iteration 19436, loss = 28563.88756115\n",
            "Iteration 19437, loss = 28564.51466699\n",
            "Iteration 19438, loss = 28563.51896004\n",
            "Iteration 19439, loss = 28561.96767796\n",
            "Iteration 19440, loss = 28562.26720972\n",
            "Iteration 19441, loss = 28561.20371912\n",
            "Iteration 19442, loss = 28560.18570037\n",
            "Iteration 19443, loss = 28560.51988592\n",
            "Iteration 19444, loss = 28560.28175159\n",
            "Iteration 19445, loss = 28558.46921519\n",
            "Iteration 19446, loss = 28557.40385859\n",
            "Iteration 19447, loss = 28557.80567524\n",
            "Iteration 19448, loss = 28557.08978628\n",
            "Iteration 19449, loss = 28557.07412212\n",
            "Iteration 19450, loss = 28556.24514102\n",
            "Iteration 19451, loss = 28553.93602626\n",
            "Iteration 19452, loss = 28554.71966094\n",
            "Iteration 19453, loss = 28554.72710667\n",
            "Iteration 19454, loss = 28555.37256141\n",
            "Iteration 19455, loss = 28555.40707742\n",
            "Iteration 19456, loss = 28553.77238499\n",
            "Iteration 19457, loss = 28552.14782067\n",
            "Iteration 19458, loss = 28551.71965893\n",
            "Iteration 19459, loss = 28552.33008409\n",
            "Iteration 19460, loss = 28552.08707831\n",
            "Iteration 19461, loss = 28550.96409604\n",
            "Iteration 19462, loss = 28550.16184981\n",
            "Iteration 19463, loss = 28549.38725153\n",
            "Iteration 19464, loss = 28548.57338244\n",
            "Iteration 19465, loss = 28547.84236378\n",
            "Iteration 19466, loss = 28548.18103570\n",
            "Iteration 19467, loss = 28547.58709940\n",
            "Iteration 19468, loss = 28545.81986342\n",
            "Iteration 19469, loss = 28544.54877926\n",
            "Iteration 19470, loss = 28545.54203815\n",
            "Iteration 19471, loss = 28545.54111510\n",
            "Iteration 19472, loss = 28544.25092120\n",
            "Iteration 19473, loss = 28542.62123127\n",
            "Iteration 19474, loss = 28543.36556559\n",
            "Iteration 19475, loss = 28543.31059106\n",
            "Iteration 19476, loss = 28542.60661355\n",
            "Iteration 19477, loss = 28541.41194475\n",
            "Iteration 19478, loss = 28540.57936011\n",
            "Iteration 19479, loss = 28539.78135183\n",
            "Iteration 19480, loss = 28539.77546796\n",
            "Iteration 19481, loss = 28538.98939892\n",
            "Iteration 19482, loss = 28537.77789366\n",
            "Iteration 19483, loss = 28537.78006456\n",
            "Iteration 19484, loss = 28537.50164961\n",
            "Iteration 19485, loss = 28536.69009473\n",
            "Iteration 19486, loss = 28535.61145959\n",
            "Iteration 19487, loss = 28535.29644537\n",
            "Iteration 19488, loss = 28536.05083687\n",
            "Iteration 19489, loss = 28535.72895743\n",
            "Iteration 19490, loss = 28535.29078369\n",
            "Iteration 19491, loss = 28533.03464161\n",
            "Iteration 19492, loss = 28533.51951889\n",
            "Iteration 19493, loss = 28534.09462686\n",
            "Iteration 19494, loss = 28532.97439846\n",
            "Iteration 19495, loss = 28532.00121605\n",
            "Iteration 19496, loss = 28531.83473311\n",
            "Iteration 19497, loss = 28530.66857377\n",
            "Iteration 19498, loss = 28530.96820280\n",
            "Iteration 19499, loss = 28531.04826828\n",
            "Iteration 19500, loss = 28530.65983425\n",
            "Iteration 19501, loss = 28529.62121005\n",
            "Iteration 19502, loss = 28527.38101506\n",
            "Iteration 19503, loss = 28527.58744557\n",
            "Iteration 19504, loss = 28527.49868216\n",
            "Iteration 19505, loss = 28526.96347975\n",
            "Iteration 19506, loss = 28525.96813165\n",
            "Iteration 19507, loss = 28525.65833580\n",
            "Iteration 19508, loss = 28524.66724893\n",
            "Iteration 19509, loss = 28523.57540725\n",
            "Iteration 19510, loss = 28523.68896408\n",
            "Iteration 19511, loss = 28522.42010162\n",
            "Iteration 19512, loss = 28521.22373293\n",
            "Iteration 19513, loss = 28521.67820206\n",
            "Iteration 19514, loss = 28520.96584736\n",
            "Iteration 19515, loss = 28520.37140884\n",
            "Iteration 19516, loss = 28519.57140555\n",
            "Iteration 19517, loss = 28519.90316922\n",
            "Iteration 19518, loss = 28519.40304962\n",
            "Iteration 19519, loss = 28518.31872073\n",
            "Iteration 19520, loss = 28517.63920763\n",
            "Iteration 19521, loss = 28516.15286374\n",
            "Iteration 19522, loss = 28516.93371252\n",
            "Iteration 19523, loss = 28515.96194989\n",
            "Iteration 19524, loss = 28515.54490617\n",
            "Iteration 19525, loss = 28515.78546555\n",
            "Iteration 19526, loss = 28515.31877993\n",
            "Iteration 19527, loss = 28514.89043999\n",
            "Iteration 19528, loss = 28513.20755738\n",
            "Iteration 19529, loss = 28513.74797325\n",
            "Iteration 19530, loss = 28514.50377487\n",
            "Iteration 19531, loss = 28512.92197639\n",
            "Iteration 19532, loss = 28511.15168644\n",
            "Iteration 19533, loss = 28511.63218964\n",
            "Iteration 19534, loss = 28510.72346916\n",
            "Iteration 19535, loss = 28509.87111737\n",
            "Iteration 19536, loss = 28508.81016358\n",
            "Iteration 19537, loss = 28508.88941482\n",
            "Iteration 19538, loss = 28508.20718389\n",
            "Iteration 19539, loss = 28507.09267150\n",
            "Iteration 19540, loss = 28506.75641849\n",
            "Iteration 19541, loss = 28506.02896593\n",
            "Iteration 19542, loss = 28506.38268568\n",
            "Iteration 19543, loss = 28505.02535028\n",
            "Iteration 19544, loss = 28504.41416392\n",
            "Iteration 19545, loss = 28504.63247764\n",
            "Iteration 19546, loss = 28504.25407404\n",
            "Iteration 19547, loss = 28503.46669395\n",
            "Iteration 19548, loss = 28502.28469339\n",
            "Iteration 19549, loss = 28501.46209120\n",
            "Iteration 19550, loss = 28501.94597992\n",
            "Iteration 19551, loss = 28502.05590492\n",
            "Iteration 19552, loss = 28501.25379444\n",
            "Iteration 19553, loss = 28500.16494207\n",
            "Iteration 19554, loss = 28500.59346264\n",
            "Iteration 19555, loss = 28500.81710479\n",
            "Iteration 19556, loss = 28499.85164027\n",
            "Iteration 19557, loss = 28498.67062542\n",
            "Iteration 19558, loss = 28498.64402297\n",
            "Iteration 19559, loss = 28498.63161966\n",
            "Iteration 19560, loss = 28498.21722973\n",
            "Iteration 19561, loss = 28497.03498192\n",
            "Iteration 19562, loss = 28496.71156366\n",
            "Iteration 19563, loss = 28496.39820726\n",
            "Iteration 19564, loss = 28495.25776267\n",
            "Iteration 19565, loss = 28494.76924709\n",
            "Iteration 19566, loss = 28495.93707587\n",
            "Iteration 19567, loss = 28495.63799049\n",
            "Iteration 19568, loss = 28494.44529297\n",
            "Iteration 19569, loss = 28493.34025088\n",
            "Iteration 19570, loss = 28494.28998290\n",
            "Iteration 19571, loss = 28494.62281489\n",
            "Iteration 19572, loss = 28493.20736857\n",
            "Iteration 19573, loss = 28492.18347362\n",
            "Iteration 19574, loss = 28492.60421669\n",
            "Iteration 19575, loss = 28492.64166184\n",
            "Iteration 19576, loss = 28491.31128834\n",
            "Iteration 19577, loss = 28490.72604939\n",
            "Iteration 19578, loss = 28491.00752617\n",
            "Iteration 19579, loss = 28491.71272314\n",
            "Iteration 19580, loss = 28490.61372419\n",
            "Iteration 19581, loss = 28490.19146920\n",
            "Iteration 19582, loss = 28490.58318697\n",
            "Iteration 19583, loss = 28490.02196163\n",
            "Iteration 19584, loss = 28489.87898524\n",
            "Iteration 19585, loss = 28489.16873509\n",
            "Iteration 19586, loss = 28488.63845871\n",
            "Iteration 19587, loss = 28489.43616111\n",
            "Iteration 19588, loss = 28489.07619419\n",
            "Iteration 19589, loss = 28487.39679564\n",
            "Iteration 19590, loss = 28487.37817414\n",
            "Iteration 19591, loss = 28487.89437098\n",
            "Iteration 19592, loss = 28488.58822997\n",
            "Iteration 19593, loss = 28487.00463237\n",
            "Iteration 19594, loss = 28486.59982421\n",
            "Iteration 19595, loss = 28485.93119822\n",
            "Iteration 19596, loss = 28485.71244541\n",
            "Iteration 19597, loss = 28484.91280790\n",
            "Iteration 19598, loss = 28485.01389561\n",
            "Iteration 19599, loss = 28485.63699775\n",
            "Iteration 19600, loss = 28485.46060870\n",
            "Iteration 19601, loss = 28484.55502908\n",
            "Iteration 19602, loss = 28483.64052621\n",
            "Iteration 19603, loss = 28483.54291893\n",
            "Iteration 19604, loss = 28483.72435376\n",
            "Iteration 19605, loss = 28483.45438347\n",
            "Iteration 19606, loss = 28483.19901383\n",
            "Iteration 19607, loss = 28482.56186832\n",
            "Iteration 19608, loss = 28482.95332211\n",
            "Iteration 19609, loss = 28482.50461339\n",
            "Iteration 19610, loss = 28481.48335431\n",
            "Iteration 19611, loss = 28482.65198643\n",
            "Iteration 19612, loss = 28483.16360286\n",
            "Iteration 19613, loss = 28482.70849047\n",
            "Iteration 19614, loss = 28482.02962941\n",
            "Iteration 19615, loss = 28480.61877886\n",
            "Iteration 19616, loss = 28480.28605478\n",
            "Iteration 19617, loss = 28481.12061130\n",
            "Iteration 19618, loss = 28481.23604063\n",
            "Iteration 19619, loss = 28480.00285361\n",
            "Iteration 19620, loss = 28478.96192459\n",
            "Iteration 19621, loss = 28479.07146220\n",
            "Iteration 19622, loss = 28478.68350080\n",
            "Iteration 19623, loss = 28478.37630721\n",
            "Iteration 19624, loss = 28477.63298758\n",
            "Iteration 19625, loss = 28478.64049761\n",
            "Iteration 19626, loss = 28477.58383586\n",
            "Iteration 19627, loss = 28477.25949530\n",
            "Iteration 19628, loss = 28477.42586199\n",
            "Iteration 19629, loss = 28477.46898139\n",
            "Iteration 19630, loss = 28476.95129899\n",
            "Iteration 19631, loss = 28476.55951153\n",
            "Iteration 19632, loss = 28476.18578244\n",
            "Iteration 19633, loss = 28475.28624886\n",
            "Iteration 19634, loss = 28474.43566975\n",
            "Iteration 19635, loss = 28474.14852832\n",
            "Iteration 19636, loss = 28474.42051366\n",
            "Iteration 19637, loss = 28474.00551352\n",
            "Iteration 19638, loss = 28473.84399053\n",
            "Iteration 19639, loss = 28473.26487175\n",
            "Iteration 19640, loss = 28473.65158301\n",
            "Iteration 19641, loss = 28473.28754171\n",
            "Iteration 19642, loss = 28473.18580669\n",
            "Iteration 19643, loss = 28472.99267167\n",
            "Iteration 19644, loss = 28472.74334065\n",
            "Iteration 19645, loss = 28472.23080647\n",
            "Iteration 19646, loss = 28471.73590407\n",
            "Iteration 19647, loss = 28471.37553356\n",
            "Iteration 19648, loss = 28470.91001992\n",
            "Iteration 19649, loss = 28471.68136079\n",
            "Iteration 19650, loss = 28470.71197867\n",
            "Iteration 19651, loss = 28470.17684581\n",
            "Iteration 19652, loss = 28471.89794327\n",
            "Iteration 19653, loss = 28471.85754541\n",
            "Iteration 19654, loss = 28470.10622460\n",
            "Iteration 19655, loss = 28469.02918030\n",
            "Iteration 19656, loss = 28469.45216179\n",
            "Iteration 19657, loss = 28469.21122824\n",
            "Iteration 19658, loss = 28468.93262062\n",
            "Iteration 19659, loss = 28468.62050776\n",
            "Iteration 19660, loss = 28467.46356573\n",
            "Iteration 19661, loss = 28467.94797365\n",
            "Iteration 19662, loss = 28468.27238680\n",
            "Iteration 19663, loss = 28467.31697560\n",
            "Iteration 19664, loss = 28466.57318678\n",
            "Iteration 19665, loss = 28466.87867250\n",
            "Iteration 19666, loss = 28467.40770554\n",
            "Iteration 19667, loss = 28466.58251771\n",
            "Iteration 19668, loss = 28465.74984924\n",
            "Iteration 19669, loss = 28466.44866437\n",
            "Iteration 19670, loss = 28466.19432394\n",
            "Iteration 19671, loss = 28465.30994573\n",
            "Iteration 19672, loss = 28464.84462793\n",
            "Iteration 19673, loss = 28465.33205092\n",
            "Iteration 19674, loss = 28465.68074492\n",
            "Iteration 19675, loss = 28465.41034568\n",
            "Iteration 19676, loss = 28463.80689263\n",
            "Iteration 19677, loss = 28464.13286333\n",
            "Iteration 19678, loss = 28464.05752952\n",
            "Iteration 19679, loss = 28462.64679725\n",
            "Iteration 19680, loss = 28463.16851879\n",
            "Iteration 19681, loss = 28462.67074416\n",
            "Iteration 19682, loss = 28461.88860322\n",
            "Iteration 19683, loss = 28463.07706501\n",
            "Iteration 19684, loss = 28462.74446638\n",
            "Iteration 19685, loss = 28461.58062269\n",
            "Iteration 19686, loss = 28461.75008979\n",
            "Iteration 19687, loss = 28461.06003662\n",
            "Iteration 19688, loss = 28461.44116879\n",
            "Iteration 19689, loss = 28461.23686050\n",
            "Iteration 19690, loss = 28461.05057499\n",
            "Iteration 19691, loss = 28461.35024232\n",
            "Iteration 19692, loss = 28460.74045181\n",
            "Iteration 19693, loss = 28459.96843603\n",
            "Iteration 19694, loss = 28460.20751566\n",
            "Iteration 19695, loss = 28459.03658103\n",
            "Iteration 19696, loss = 28458.48812989\n",
            "Iteration 19697, loss = 28459.37565918\n",
            "Iteration 19698, loss = 28458.82357502\n",
            "Iteration 19699, loss = 28458.44658445\n",
            "Iteration 19700, loss = 28457.54210698\n",
            "Iteration 19701, loss = 28458.27951607\n",
            "Iteration 19702, loss = 28459.17045102\n",
            "Iteration 19703, loss = 28459.11625379\n",
            "Iteration 19704, loss = 28458.15053681\n",
            "Iteration 19705, loss = 28456.76437508\n",
            "Iteration 19706, loss = 28455.87228958\n",
            "Iteration 19707, loss = 28455.68566724\n",
            "Iteration 19708, loss = 28455.06769192\n",
            "Iteration 19709, loss = 28455.43376894\n",
            "Iteration 19710, loss = 28454.81474018\n",
            "Iteration 19711, loss = 28454.71256910\n",
            "Iteration 19712, loss = 28454.64331813\n",
            "Iteration 19713, loss = 28454.54904406\n",
            "Iteration 19714, loss = 28454.11133805\n",
            "Iteration 19715, loss = 28453.31031396\n",
            "Iteration 19716, loss = 28454.10499316\n",
            "Iteration 19717, loss = 28453.65312037\n",
            "Iteration 19718, loss = 28453.36850998\n",
            "Iteration 19719, loss = 28453.04080274\n",
            "Iteration 19720, loss = 28451.88825284\n",
            "Iteration 19721, loss = 28452.20637617\n",
            "Iteration 19722, loss = 28452.83792697\n",
            "Iteration 19723, loss = 28452.00640513\n",
            "Iteration 19724, loss = 28450.74438693\n",
            "Iteration 19725, loss = 28451.81804049\n",
            "Iteration 19726, loss = 28452.18705893\n",
            "Iteration 19727, loss = 28451.80452954\n",
            "Iteration 19728, loss = 28451.42867422\n",
            "Iteration 19729, loss = 28450.33404875\n",
            "Iteration 19730, loss = 28449.75793614\n",
            "Iteration 19731, loss = 28450.14186359\n",
            "Iteration 19732, loss = 28450.03685651\n",
            "Iteration 19733, loss = 28450.37396588\n",
            "Iteration 19734, loss = 28449.40866050\n",
            "Iteration 19735, loss = 28448.42836568\n",
            "Iteration 19736, loss = 28448.32524011\n",
            "Iteration 19737, loss = 28448.10643024\n",
            "Iteration 19738, loss = 28447.56241901\n",
            "Iteration 19739, loss = 28446.66403559\n",
            "Iteration 19740, loss = 28446.64305216\n",
            "Iteration 19741, loss = 28446.52561656\n",
            "Iteration 19742, loss = 28446.83617917\n",
            "Iteration 19743, loss = 28445.85679989\n",
            "Iteration 19744, loss = 28445.65733558\n",
            "Iteration 19745, loss = 28446.06991130\n",
            "Iteration 19746, loss = 28446.06150598\n",
            "Iteration 19747, loss = 28444.58302232\n",
            "Iteration 19748, loss = 28444.98550881\n",
            "Iteration 19749, loss = 28445.33542639\n",
            "Iteration 19750, loss = 28444.27938869\n",
            "Iteration 19751, loss = 28444.37055285\n",
            "Iteration 19752, loss = 28444.80191350\n",
            "Iteration 19753, loss = 28444.06965821\n",
            "Iteration 19754, loss = 28443.30601061\n",
            "Iteration 19755, loss = 28443.24863461\n",
            "Iteration 19756, loss = 28443.15022880\n",
            "Iteration 19757, loss = 28442.55843348\n",
            "Iteration 19758, loss = 28442.51313985\n",
            "Iteration 19759, loss = 28442.64909370\n",
            "Iteration 19760, loss = 28441.70891257\n",
            "Iteration 19761, loss = 28441.16627318\n",
            "Iteration 19762, loss = 28440.86292057\n",
            "Iteration 19763, loss = 28440.90160941\n",
            "Iteration 19764, loss = 28441.21535651\n",
            "Iteration 19765, loss = 28440.81640638\n",
            "Iteration 19766, loss = 28440.80912654\n",
            "Iteration 19767, loss = 28440.68661130\n",
            "Iteration 19768, loss = 28439.41063373\n",
            "Iteration 19769, loss = 28439.80705581\n",
            "Iteration 19770, loss = 28439.54276668\n",
            "Iteration 19771, loss = 28438.84067945\n",
            "Iteration 19772, loss = 28438.52616112\n",
            "Iteration 19773, loss = 28438.67229484\n",
            "Iteration 19774, loss = 28438.86553768\n",
            "Iteration 19775, loss = 28437.86384750\n",
            "Iteration 19776, loss = 28438.51857009\n",
            "Iteration 19777, loss = 28439.47215484\n",
            "Iteration 19778, loss = 28438.36443366\n",
            "Iteration 19779, loss = 28437.09448853\n",
            "Iteration 19780, loss = 28437.47278543\n",
            "Iteration 19781, loss = 28437.27944823\n",
            "Iteration 19782, loss = 28436.52094581\n",
            "Iteration 19783, loss = 28438.06435102\n",
            "Iteration 19784, loss = 28438.49012963\n",
            "Iteration 19785, loss = 28436.91061850\n",
            "Iteration 19786, loss = 28436.57586484\n",
            "Iteration 19787, loss = 28436.80853171\n",
            "Iteration 19788, loss = 28436.48539308\n",
            "Iteration 19789, loss = 28437.02701829\n",
            "Iteration 19790, loss = 28436.44587527\n",
            "Iteration 19791, loss = 28435.48326363\n",
            "Iteration 19792, loss = 28435.27189454\n",
            "Iteration 19793, loss = 28435.12265164\n",
            "Iteration 19794, loss = 28434.84425498\n",
            "Iteration 19795, loss = 28433.90678535\n",
            "Iteration 19796, loss = 28434.01694013\n",
            "Iteration 19797, loss = 28434.19676377\n",
            "Iteration 19798, loss = 28433.64549220\n",
            "Iteration 19799, loss = 28432.16092623\n",
            "Iteration 19800, loss = 28433.05216010\n",
            "Iteration 19801, loss = 28433.32785498\n",
            "Iteration 19802, loss = 28433.54529394\n",
            "Iteration 19803, loss = 28432.85359768\n",
            "Iteration 19804, loss = 28432.22185060\n",
            "Iteration 19805, loss = 28431.96474197\n",
            "Iteration 19806, loss = 28432.08879656\n",
            "Iteration 19807, loss = 28431.08863810\n",
            "Iteration 19808, loss = 28431.67147861\n",
            "Iteration 19809, loss = 28431.79585880\n",
            "Iteration 19810, loss = 28431.67142362\n",
            "Iteration 19811, loss = 28431.63037720\n",
            "Iteration 19812, loss = 28430.79453490\n",
            "Iteration 19813, loss = 28429.74127378\n",
            "Iteration 19814, loss = 28429.92519392\n",
            "Iteration 19815, loss = 28430.06112226\n",
            "Iteration 19816, loss = 28429.62943840\n",
            "Iteration 19817, loss = 28428.70108077\n",
            "Iteration 19818, loss = 28429.15386072\n",
            "Iteration 19819, loss = 28429.76195709\n",
            "Iteration 19820, loss = 28428.43991907\n",
            "Iteration 19821, loss = 28427.04174423\n",
            "Iteration 19822, loss = 28428.58694408\n",
            "Iteration 19823, loss = 28428.05268748\n",
            "Iteration 19824, loss = 28427.82372342\n",
            "Iteration 19825, loss = 28427.88824084\n",
            "Iteration 19826, loss = 28428.13164580\n",
            "Iteration 19827, loss = 28427.16543891\n",
            "Iteration 19828, loss = 28426.77340445\n",
            "Iteration 19829, loss = 28427.21864191\n",
            "Iteration 19830, loss = 28427.20969965\n",
            "Iteration 19831, loss = 28426.94116396\n",
            "Iteration 19832, loss = 28424.74309716\n",
            "Iteration 19833, loss = 28425.92451326\n",
            "Iteration 19834, loss = 28427.31091982\n",
            "Iteration 19835, loss = 28426.57824529\n",
            "Iteration 19836, loss = 28425.75393146\n",
            "Iteration 19837, loss = 28425.03144067\n",
            "Iteration 19838, loss = 28424.49384424\n",
            "Iteration 19839, loss = 28424.86733468\n",
            "Iteration 19840, loss = 28425.10313542\n",
            "Iteration 19841, loss = 28424.96746515\n",
            "Iteration 19842, loss = 28423.13603749\n",
            "Iteration 19843, loss = 28423.42414696\n",
            "Iteration 19844, loss = 28424.45770888\n",
            "Iteration 19845, loss = 28424.81867609\n",
            "Iteration 19846, loss = 28424.29168515\n",
            "Iteration 19847, loss = 28423.82434970\n",
            "Iteration 19848, loss = 28424.00579037\n",
            "Iteration 19849, loss = 28422.88389198\n",
            "Iteration 19850, loss = 28421.60787578\n",
            "Iteration 19851, loss = 28421.92873295\n",
            "Iteration 19852, loss = 28421.47712789\n",
            "Iteration 19853, loss = 28420.58933808\n",
            "Iteration 19854, loss = 28420.11097372\n",
            "Iteration 19855, loss = 28420.15604331\n",
            "Iteration 19856, loss = 28419.56198991\n",
            "Iteration 19857, loss = 28418.97578434\n",
            "Iteration 19858, loss = 28418.48089587\n",
            "Iteration 19859, loss = 28419.41622628\n",
            "Iteration 19860, loss = 28419.40523435\n",
            "Iteration 19861, loss = 28418.22065940\n",
            "Iteration 19862, loss = 28417.91371767\n",
            "Iteration 19863, loss = 28419.67583780\n",
            "Iteration 19864, loss = 28419.40062440\n",
            "Iteration 19865, loss = 28417.35959368\n",
            "Iteration 19866, loss = 28417.56171091\n",
            "Iteration 19867, loss = 28418.12183465\n",
            "Iteration 19868, loss = 28417.90563329\n",
            "Iteration 19869, loss = 28417.45042660\n",
            "Iteration 19870, loss = 28417.13375795\n",
            "Iteration 19871, loss = 28416.45940767\n",
            "Iteration 19872, loss = 28417.75901378\n",
            "Iteration 19873, loss = 28417.53604258\n",
            "Iteration 19874, loss = 28416.63723212\n",
            "Iteration 19875, loss = 28415.59397307\n",
            "Iteration 19876, loss = 28416.75613851\n",
            "Iteration 19877, loss = 28417.07279039\n",
            "Iteration 19878, loss = 28416.75758999\n",
            "Iteration 19879, loss = 28417.60425130\n",
            "Iteration 19880, loss = 28417.24257288\n",
            "Iteration 19881, loss = 28416.14221529\n",
            "Iteration 19882, loss = 28414.37935127\n",
            "Iteration 19883, loss = 28414.72776983\n",
            "Iteration 19884, loss = 28415.18742891\n",
            "Iteration 19885, loss = 28414.22985368\n",
            "Iteration 19886, loss = 28412.57598407\n",
            "Iteration 19887, loss = 28412.61852047\n",
            "Iteration 19888, loss = 28412.55220927\n",
            "Iteration 19889, loss = 28412.74327381\n",
            "Iteration 19890, loss = 28412.60294066\n",
            "Iteration 19891, loss = 28411.43988026\n",
            "Iteration 19892, loss = 28412.44614232\n",
            "Iteration 19893, loss = 28413.03553089\n",
            "Iteration 19894, loss = 28411.92001309\n",
            "Iteration 19895, loss = 28410.45309953\n",
            "Iteration 19896, loss = 28411.33433661\n",
            "Iteration 19897, loss = 28411.43122937\n",
            "Iteration 19898, loss = 28410.78072981\n",
            "Iteration 19899, loss = 28411.02367989\n",
            "Iteration 19900, loss = 28410.84471624\n",
            "Iteration 19901, loss = 28411.55564151\n",
            "Iteration 19902, loss = 28411.21105576\n",
            "Iteration 19903, loss = 28409.52682441\n",
            "Iteration 19904, loss = 28408.73362857\n",
            "Iteration 19905, loss = 28411.55305674\n",
            "Iteration 19906, loss = 28412.03956810\n",
            "Iteration 19907, loss = 28410.28979526\n",
            "Iteration 19908, loss = 28407.22929124\n",
            "Iteration 19909, loss = 28408.74188705\n",
            "Iteration 19910, loss = 28409.44304070\n",
            "Iteration 19911, loss = 28408.65170208\n",
            "Iteration 19912, loss = 28407.35537514\n",
            "Iteration 19913, loss = 28406.41826046\n",
            "Iteration 19914, loss = 28407.38802565\n",
            "Iteration 19915, loss = 28407.21930608\n",
            "Iteration 19916, loss = 28406.31997574\n",
            "Iteration 19917, loss = 28406.29711359\n",
            "Iteration 19918, loss = 28407.59152395\n",
            "Iteration 19919, loss = 28407.65274788\n",
            "Iteration 19920, loss = 28405.97399443\n",
            "Iteration 19921, loss = 28405.66995955\n",
            "Iteration 19922, loss = 28406.50515460\n",
            "Iteration 19923, loss = 28406.63924194\n",
            "Iteration 19924, loss = 28405.33791171\n",
            "Iteration 19925, loss = 28404.75730089\n",
            "Iteration 19926, loss = 28403.98156647\n",
            "Iteration 19927, loss = 28404.46831666\n",
            "Iteration 19928, loss = 28404.81401120\n",
            "Iteration 19929, loss = 28404.25181760\n",
            "Iteration 19930, loss = 28402.99546170\n",
            "Iteration 19931, loss = 28402.83642820\n",
            "Iteration 19932, loss = 28402.95934598\n",
            "Iteration 19933, loss = 28402.66430952\n",
            "Iteration 19934, loss = 28401.78664768\n",
            "Iteration 19935, loss = 28402.09118695\n",
            "Iteration 19936, loss = 28401.88272161\n",
            "Iteration 19937, loss = 28402.21206341\n",
            "Iteration 19938, loss = 28401.91967685\n",
            "Iteration 19939, loss = 28401.01513848\n",
            "Iteration 19940, loss = 28401.89364269\n",
            "Iteration 19941, loss = 28402.06046752\n",
            "Iteration 19942, loss = 28400.48894627\n",
            "Iteration 19943, loss = 28400.20326083\n",
            "Iteration 19944, loss = 28401.79808101\n",
            "Iteration 19945, loss = 28401.90272846\n",
            "Iteration 19946, loss = 28400.43371259\n",
            "Iteration 19947, loss = 28400.18764995\n",
            "Iteration 19948, loss = 28399.95425680\n",
            "Iteration 19949, loss = 28400.41190529\n",
            "Iteration 19950, loss = 28399.74844881\n",
            "Iteration 19951, loss = 28399.18927435\n",
            "Iteration 19952, loss = 28398.34083881\n",
            "Iteration 19953, loss = 28398.13047146\n",
            "Iteration 19954, loss = 28397.21012153\n",
            "Iteration 19955, loss = 28397.76457751\n",
            "Iteration 19956, loss = 28397.01010882\n",
            "Iteration 19957, loss = 28396.38081343\n",
            "Iteration 19958, loss = 28398.06590242\n",
            "Iteration 19959, loss = 28398.30358964\n",
            "Iteration 19960, loss = 28397.06730255\n",
            "Iteration 19961, loss = 28395.94408471\n",
            "Iteration 19962, loss = 28397.82981575\n",
            "Iteration 19963, loss = 28397.76852418\n",
            "Iteration 19964, loss = 28397.53216234\n",
            "Iteration 19965, loss = 28398.28832945\n",
            "Iteration 19966, loss = 28397.18862491\n",
            "Iteration 19967, loss = 28396.97250739\n",
            "Iteration 19968, loss = 28397.16400727\n",
            "Iteration 19969, loss = 28397.15183209\n",
            "Iteration 19970, loss = 28395.20728449\n",
            "Iteration 19971, loss = 28394.83377247\n",
            "Iteration 19972, loss = 28396.36569558\n",
            "Iteration 19973, loss = 28396.71776235\n",
            "Iteration 19974, loss = 28395.27298352\n",
            "Iteration 19975, loss = 28394.14417987\n",
            "Iteration 19976, loss = 28393.24055750\n",
            "Iteration 19977, loss = 28394.02053335\n",
            "Iteration 19978, loss = 28394.04652168\n",
            "Iteration 19979, loss = 28393.78260146\n",
            "Iteration 19980, loss = 28393.35713031\n",
            "Iteration 19981, loss = 28392.56076141\n",
            "Iteration 19982, loss = 28392.57167486\n",
            "Iteration 19983, loss = 28392.70252313\n",
            "Iteration 19984, loss = 28393.16337863\n",
            "Iteration 19985, loss = 28391.70971415\n",
            "Iteration 19986, loss = 28390.92069778\n",
            "Iteration 19987, loss = 28392.21633970\n",
            "Iteration 19988, loss = 28392.00712872\n",
            "Iteration 19989, loss = 28391.89711848\n",
            "Iteration 19990, loss = 28391.51239704\n",
            "Iteration 19991, loss = 28390.90069181\n",
            "Iteration 19992, loss = 28389.79995298\n",
            "Iteration 19993, loss = 28389.95950845\n",
            "Iteration 19994, loss = 28389.93392057\n",
            "Iteration 19995, loss = 28389.58911494\n",
            "Iteration 19996, loss = 28388.06452455\n",
            "Iteration 19997, loss = 28388.50178439\n",
            "Iteration 19998, loss = 28388.32165218\n",
            "Iteration 19999, loss = 28387.64404666\n",
            "Iteration 20000, loss = 28387.71280914\n",
            "Iteration 20001, loss = 28387.84766008\n",
            "Iteration 20002, loss = 28387.25042878\n",
            "Iteration 20003, loss = 28387.06945738\n",
            "Iteration 20004, loss = 28386.65890202\n",
            "Iteration 20005, loss = 28385.62565990\n",
            "Iteration 20006, loss = 28387.05538616\n",
            "Iteration 20007, loss = 28386.98247592\n",
            "Iteration 20008, loss = 28385.78918222\n",
            "Iteration 20009, loss = 28386.22031855\n",
            "Iteration 20010, loss = 28386.94463357\n",
            "Iteration 20011, loss = 28386.87263634\n",
            "Iteration 20012, loss = 28385.94558137\n",
            "Iteration 20013, loss = 28385.27853587\n",
            "Iteration 20014, loss = 28385.26602938\n",
            "Iteration 20015, loss = 28385.62455901\n",
            "Iteration 20016, loss = 28385.41834174\n",
            "Iteration 20017, loss = 28385.46889647\n",
            "Iteration 20018, loss = 28384.36769269\n",
            "Iteration 20019, loss = 28384.17300180\n",
            "Iteration 20020, loss = 28384.39649337\n",
            "Iteration 20021, loss = 28383.57877790\n",
            "Iteration 20022, loss = 28383.38118460\n",
            "Iteration 20023, loss = 28382.69369197\n",
            "Iteration 20024, loss = 28382.45323938\n",
            "Iteration 20025, loss = 28382.55407286\n",
            "Iteration 20026, loss = 28382.24812194\n",
            "Iteration 20027, loss = 28381.75105912\n",
            "Iteration 20028, loss = 28382.08326891\n",
            "Iteration 20029, loss = 28381.87930958\n",
            "Iteration 20030, loss = 28381.22629838\n",
            "Iteration 20031, loss = 28381.22323018\n",
            "Iteration 20032, loss = 28381.30254951\n",
            "Iteration 20033, loss = 28381.68460334\n",
            "Iteration 20034, loss = 28381.08309012\n",
            "Iteration 20035, loss = 28380.06618814\n",
            "Iteration 20036, loss = 28379.53892388\n",
            "Iteration 20037, loss = 28380.09108006\n",
            "Iteration 20038, loss = 28380.13422563\n",
            "Iteration 20039, loss = 28379.65227621\n",
            "Iteration 20040, loss = 28378.08640504\n",
            "Iteration 20041, loss = 28378.35240725\n",
            "Iteration 20042, loss = 28377.63243938\n",
            "Iteration 20043, loss = 28377.68585602\n",
            "Iteration 20044, loss = 28377.58489409\n",
            "Iteration 20045, loss = 28377.13394088\n",
            "Iteration 20046, loss = 28378.47953579\n",
            "Iteration 20047, loss = 28378.58136587\n",
            "Iteration 20048, loss = 28377.50627099\n",
            "Iteration 20049, loss = 28375.74088981\n",
            "Iteration 20050, loss = 28378.36621591\n",
            "Iteration 20051, loss = 28378.83349228\n",
            "Iteration 20052, loss = 28376.78343914\n",
            "Iteration 20053, loss = 28376.42383985\n",
            "Iteration 20054, loss = 28377.44935500\n",
            "Iteration 20055, loss = 28377.70462093\n",
            "Iteration 20056, loss = 28376.67263043\n",
            "Iteration 20057, loss = 28375.52819314\n",
            "Iteration 20058, loss = 28375.09235186\n",
            "Iteration 20059, loss = 28376.21943973\n",
            "Iteration 20060, loss = 28376.12709166\n",
            "Iteration 20061, loss = 28375.15026023\n",
            "Iteration 20062, loss = 28373.97650425\n",
            "Iteration 20063, loss = 28374.19466974\n",
            "Iteration 20064, loss = 28374.96280265\n",
            "Iteration 20065, loss = 28375.78008640\n",
            "Iteration 20066, loss = 28375.60092159\n",
            "Iteration 20067, loss = 28374.32336729\n",
            "Iteration 20068, loss = 28373.23450242\n",
            "Iteration 20069, loss = 28373.56355883\n",
            "Iteration 20070, loss = 28373.52881386\n",
            "Iteration 20071, loss = 28373.52102345\n",
            "Iteration 20072, loss = 28371.74211345\n",
            "Iteration 20073, loss = 28371.69036432\n",
            "Iteration 20074, loss = 28372.32018570\n",
            "Iteration 20075, loss = 28371.93201671\n",
            "Iteration 20076, loss = 28371.60745523\n",
            "Iteration 20077, loss = 28371.31449468\n",
            "Iteration 20078, loss = 28370.92516550\n",
            "Iteration 20079, loss = 28370.21204228\n",
            "Iteration 20080, loss = 28370.10239598\n",
            "Iteration 20081, loss = 28369.37312666\n",
            "Iteration 20082, loss = 28368.39487838\n",
            "Iteration 20083, loss = 28369.15515352\n",
            "Iteration 20084, loss = 28369.39163470\n",
            "Iteration 20085, loss = 28368.01498139\n",
            "Iteration 20086, loss = 28368.57329988\n",
            "Iteration 20087, loss = 28369.20753574\n",
            "Iteration 20088, loss = 28368.79332754\n",
            "Iteration 20089, loss = 28368.50933304\n",
            "Iteration 20090, loss = 28367.32704867\n",
            "Iteration 20091, loss = 28366.42492175\n",
            "Iteration 20092, loss = 28367.73989607\n",
            "Iteration 20093, loss = 28368.65497422\n",
            "Iteration 20094, loss = 28367.25526511\n",
            "Iteration 20095, loss = 28366.28593578\n",
            "Iteration 20096, loss = 28366.92872916\n",
            "Iteration 20097, loss = 28367.49341228\n",
            "Iteration 20098, loss = 28367.61897527\n",
            "Iteration 20099, loss = 28367.44362564\n",
            "Iteration 20100, loss = 28366.66333487\n",
            "Iteration 20101, loss = 28366.63408120\n",
            "Iteration 20102, loss = 28365.65341689\n",
            "Iteration 20103, loss = 28365.09362903\n",
            "Iteration 20104, loss = 28366.66012401\n",
            "Iteration 20105, loss = 28366.59229750\n",
            "Iteration 20106, loss = 28365.15378343\n",
            "Iteration 20107, loss = 28364.32506163\n",
            "Iteration 20108, loss = 28363.89768074\n",
            "Iteration 20109, loss = 28363.92415327\n",
            "Iteration 20110, loss = 28363.82457244\n",
            "Iteration 20111, loss = 28362.89147553\n",
            "Iteration 20112, loss = 28362.79365303\n",
            "Iteration 20113, loss = 28363.10741473\n",
            "Iteration 20114, loss = 28362.38204918\n",
            "Iteration 20115, loss = 28361.28494783\n",
            "Iteration 20116, loss = 28361.78626693\n",
            "Iteration 20117, loss = 28361.50343317\n",
            "Iteration 20118, loss = 28360.90450512\n",
            "Iteration 20119, loss = 28360.79837585\n",
            "Iteration 20120, loss = 28360.28704543\n",
            "Iteration 20121, loss = 28361.23021959\n",
            "Iteration 20122, loss = 28360.76746006\n",
            "Iteration 20123, loss = 28359.94442195\n",
            "Iteration 20124, loss = 28359.30445970\n",
            "Iteration 20125, loss = 28359.50774193\n",
            "Iteration 20126, loss = 28360.04351896\n",
            "Iteration 20127, loss = 28358.89327321\n",
            "Iteration 20128, loss = 28359.70817041\n",
            "Iteration 20129, loss = 28360.28920596\n",
            "Iteration 20130, loss = 28359.14684842\n",
            "Iteration 20131, loss = 28358.36748586\n",
            "Iteration 20132, loss = 28359.56203845\n",
            "Iteration 20133, loss = 28358.84230805\n",
            "Iteration 20134, loss = 28357.95487696\n",
            "Iteration 20135, loss = 28358.71229186\n",
            "Iteration 20136, loss = 28359.05127163\n",
            "Iteration 20137, loss = 28358.25728569\n",
            "Iteration 20138, loss = 28357.45755691\n",
            "Iteration 20139, loss = 28358.12777750\n",
            "Iteration 20140, loss = 28358.21639640\n",
            "Iteration 20141, loss = 28358.01656573\n",
            "Iteration 20142, loss = 28357.46652655\n",
            "Iteration 20143, loss = 28356.45554235\n",
            "Iteration 20144, loss = 28355.89464300\n",
            "Iteration 20145, loss = 28357.11867840\n",
            "Iteration 20146, loss = 28357.43814454\n",
            "Iteration 20147, loss = 28356.99528458\n",
            "Iteration 20148, loss = 28355.21672633\n",
            "Iteration 20149, loss = 28354.49042491\n",
            "Iteration 20150, loss = 28355.64294758\n",
            "Iteration 20151, loss = 28355.15674683\n",
            "Iteration 20152, loss = 28354.25885774\n",
            "Iteration 20153, loss = 28354.14000391\n",
            "Iteration 20154, loss = 28354.84859880\n",
            "Iteration 20155, loss = 28354.35289679\n",
            "Iteration 20156, loss = 28353.68969110\n",
            "Iteration 20157, loss = 28353.13496775\n",
            "Iteration 20158, loss = 28353.12825100\n",
            "Iteration 20159, loss = 28352.64245277\n",
            "Iteration 20160, loss = 28353.33313145\n",
            "Iteration 20161, loss = 28352.42273869\n",
            "Iteration 20162, loss = 28351.12750297\n",
            "Iteration 20163, loss = 28352.78965388\n",
            "Iteration 20164, loss = 28353.09860242\n",
            "Iteration 20165, loss = 28351.42118611\n",
            "Iteration 20166, loss = 28351.09399982\n",
            "Iteration 20167, loss = 28352.52140764\n",
            "Iteration 20168, loss = 28351.89174003\n",
            "Iteration 20169, loss = 28350.38475818\n",
            "Iteration 20170, loss = 28350.77516157\n",
            "Iteration 20171, loss = 28351.82224099\n",
            "Iteration 20172, loss = 28351.03254112\n",
            "Iteration 20173, loss = 28349.63764756\n",
            "Iteration 20174, loss = 28348.98894183\n",
            "Iteration 20175, loss = 28349.51115382\n",
            "Iteration 20176, loss = 28350.36563346\n",
            "Iteration 20177, loss = 28349.96501364\n",
            "Iteration 20178, loss = 28348.88249574\n",
            "Iteration 20179, loss = 28348.34635545\n",
            "Iteration 20180, loss = 28348.14527504\n",
            "Iteration 20181, loss = 28347.04322135\n",
            "Iteration 20182, loss = 28346.97085535\n",
            "Iteration 20183, loss = 28346.27345679\n",
            "Iteration 20184, loss = 28347.20112563\n",
            "Iteration 20185, loss = 28346.88335810\n",
            "Iteration 20186, loss = 28346.19557162\n",
            "Iteration 20187, loss = 28346.11298751\n",
            "Iteration 20188, loss = 28346.07142845\n",
            "Iteration 20189, loss = 28346.21875141\n",
            "Iteration 20190, loss = 28345.55327739\n",
            "Iteration 20191, loss = 28345.46077032\n",
            "Iteration 20192, loss = 28345.73077425\n",
            "Iteration 20193, loss = 28345.63036892\n",
            "Iteration 20194, loss = 28345.18762385\n",
            "Iteration 20195, loss = 28345.56675643\n",
            "Iteration 20196, loss = 28345.06098087\n",
            "Iteration 20197, loss = 28343.51361916\n",
            "Iteration 20198, loss = 28343.87580454\n",
            "Iteration 20199, loss = 28343.96203138\n",
            "Iteration 20200, loss = 28343.16834993\n",
            "Iteration 20201, loss = 28343.07610976\n",
            "Iteration 20202, loss = 28343.39594298\n",
            "Iteration 20203, loss = 28343.50836556\n",
            "Iteration 20204, loss = 28343.72074679\n",
            "Iteration 20205, loss = 28343.55346239\n",
            "Iteration 20206, loss = 28343.50116806\n",
            "Iteration 20207, loss = 28342.13534991\n",
            "Iteration 20208, loss = 28342.17577956\n",
            "Iteration 20209, loss = 28342.13855342\n",
            "Iteration 20210, loss = 28342.30643866\n",
            "Iteration 20211, loss = 28341.15988978\n",
            "Iteration 20212, loss = 28340.33456844\n",
            "Iteration 20213, loss = 28340.55125719\n",
            "Iteration 20214, loss = 28341.74926410\n",
            "Iteration 20215, loss = 28339.99423874\n",
            "Iteration 20216, loss = 28340.33733826\n",
            "Iteration 20217, loss = 28341.17654953\n",
            "Iteration 20218, loss = 28340.35667173\n",
            "Iteration 20219, loss = 28338.81859335\n",
            "Iteration 20220, loss = 28340.47454339\n",
            "Iteration 20221, loss = 28340.94643493\n",
            "Iteration 20222, loss = 28339.19360506\n",
            "Iteration 20223, loss = 28339.45328308\n",
            "Iteration 20224, loss = 28339.69681003\n",
            "Iteration 20225, loss = 28340.12951597\n",
            "Iteration 20226, loss = 28339.89249090\n",
            "Iteration 20227, loss = 28338.61453358\n",
            "Iteration 20228, loss = 28336.89538060\n",
            "Iteration 20229, loss = 28338.61658607\n",
            "Iteration 20230, loss = 28339.36214199\n",
            "Iteration 20231, loss = 28338.47573577\n",
            "Iteration 20232, loss = 28336.92150810\n",
            "Iteration 20233, loss = 28336.65679978\n",
            "Iteration 20234, loss = 28337.36525168\n",
            "Iteration 20235, loss = 28337.18392138\n",
            "Iteration 20236, loss = 28336.15317685\n",
            "Iteration 20237, loss = 28335.34111349\n",
            "Iteration 20238, loss = 28336.44864481\n",
            "Iteration 20239, loss = 28336.49995657\n",
            "Iteration 20240, loss = 28335.57687715\n",
            "Iteration 20241, loss = 28335.17187615\n",
            "Iteration 20242, loss = 28335.29764684\n",
            "Iteration 20243, loss = 28336.11921355\n",
            "Iteration 20244, loss = 28335.23269705\n",
            "Iteration 20245, loss = 28334.82355749\n",
            "Iteration 20246, loss = 28335.18924936\n",
            "Iteration 20247, loss = 28334.81836132\n",
            "Iteration 20248, loss = 28335.10949607\n",
            "Iteration 20249, loss = 28334.20090664\n",
            "Iteration 20250, loss = 28332.99130139\n",
            "Iteration 20251, loss = 28333.04975439\n",
            "Iteration 20252, loss = 28332.86995864\n",
            "Iteration 20253, loss = 28333.20816650\n",
            "Iteration 20254, loss = 28332.89125752\n",
            "Iteration 20255, loss = 28331.91921476\n",
            "Iteration 20256, loss = 28333.04417614\n",
            "Iteration 20257, loss = 28333.43290621\n",
            "Iteration 20258, loss = 28331.79764187\n",
            "Iteration 20259, loss = 28330.86386521\n",
            "Iteration 20260, loss = 28331.66816161\n",
            "Iteration 20261, loss = 28331.48949346\n",
            "Iteration 20262, loss = 28331.21447740\n",
            "Iteration 20263, loss = 28330.27577765\n",
            "Iteration 20264, loss = 28329.63184181\n",
            "Iteration 20265, loss = 28329.97511699\n",
            "Iteration 20266, loss = 28329.58222838\n",
            "Iteration 20267, loss = 28329.00409021\n",
            "Iteration 20268, loss = 28329.32024483\n",
            "Iteration 20269, loss = 28329.64105577\n",
            "Iteration 20270, loss = 28328.53275670\n",
            "Iteration 20271, loss = 28327.83990071\n",
            "Iteration 20272, loss = 28329.55555881\n",
            "Iteration 20273, loss = 28329.18866437\n",
            "Iteration 20274, loss = 28328.01059243\n",
            "Iteration 20275, loss = 28328.29314703\n",
            "Iteration 20276, loss = 28329.27071549\n",
            "Iteration 20277, loss = 28329.76795131\n",
            "Iteration 20278, loss = 28329.72436699\n",
            "Iteration 20279, loss = 28328.32244822\n",
            "Iteration 20280, loss = 28326.47599847\n",
            "Iteration 20281, loss = 28327.57418609\n",
            "Iteration 20282, loss = 28328.76383026\n",
            "Iteration 20283, loss = 28328.03488472\n",
            "Iteration 20284, loss = 28326.43137212\n",
            "Iteration 20285, loss = 28325.72236278\n",
            "Iteration 20286, loss = 28325.82634448\n",
            "Iteration 20287, loss = 28326.30852983\n",
            "Iteration 20288, loss = 28325.52547428\n",
            "Iteration 20289, loss = 28325.74082928\n",
            "Iteration 20290, loss = 28325.99391408\n",
            "Iteration 20291, loss = 28325.22910924\n",
            "Iteration 20292, loss = 28324.25894745\n",
            "Iteration 20293, loss = 28324.72133166\n",
            "Iteration 20294, loss = 28324.83500555\n",
            "Iteration 20295, loss = 28324.31063515\n",
            "Iteration 20296, loss = 28323.60481589\n",
            "Iteration 20297, loss = 28324.27592920\n",
            "Iteration 20298, loss = 28324.53175199\n",
            "Iteration 20299, loss = 28322.79105568\n",
            "Iteration 20300, loss = 28324.21447793\n",
            "Iteration 20301, loss = 28324.61560771\n",
            "Iteration 20302, loss = 28323.85187643\n",
            "Iteration 20303, loss = 28322.93535179\n",
            "Iteration 20304, loss = 28321.35823435\n",
            "Iteration 20305, loss = 28321.31484880\n",
            "Iteration 20306, loss = 28322.81119091\n",
            "Iteration 20307, loss = 28322.19141197\n",
            "Iteration 20308, loss = 28321.93877425\n",
            "Iteration 20309, loss = 28321.21705468\n",
            "Iteration 20310, loss = 28322.02126212\n",
            "Iteration 20311, loss = 28321.74781059\n",
            "Iteration 20312, loss = 28321.30120631\n",
            "Iteration 20313, loss = 28322.41723731\n",
            "Iteration 20314, loss = 28322.12219989\n",
            "Iteration 20315, loss = 28321.08125202\n",
            "Iteration 20316, loss = 28318.92547573\n",
            "Iteration 20317, loss = 28319.45186786\n",
            "Iteration 20318, loss = 28320.83098409\n",
            "Iteration 20319, loss = 28320.15865284\n",
            "Iteration 20320, loss = 28317.66116494\n",
            "Iteration 20321, loss = 28318.18554811\n",
            "Iteration 20322, loss = 28320.34870901\n",
            "Iteration 20323, loss = 28320.91061603\n",
            "Iteration 20324, loss = 28320.44325259\n",
            "Iteration 20325, loss = 28319.31509785\n",
            "Iteration 20326, loss = 28317.60729550\n",
            "Iteration 20327, loss = 28316.69775055\n",
            "Iteration 20328, loss = 28317.91084664\n",
            "Iteration 20329, loss = 28318.20423055\n",
            "Iteration 20330, loss = 28316.46669827\n",
            "Iteration 20331, loss = 28315.95058607\n",
            "Iteration 20332, loss = 28316.77185258\n",
            "Iteration 20333, loss = 28317.28040169\n",
            "Iteration 20334, loss = 28316.47660607\n",
            "Iteration 20335, loss = 28316.23568454\n",
            "Iteration 20336, loss = 28316.89012746\n",
            "Iteration 20337, loss = 28315.87615454\n",
            "Iteration 20338, loss = 28314.31657604\n",
            "Iteration 20339, loss = 28314.11678081\n",
            "Iteration 20340, loss = 28315.27476661\n",
            "Iteration 20341, loss = 28314.26592025\n",
            "Iteration 20342, loss = 28312.90066843\n",
            "Iteration 20343, loss = 28314.05551442\n",
            "Iteration 20344, loss = 28314.25541780\n",
            "Iteration 20345, loss = 28313.71025100\n",
            "Iteration 20346, loss = 28314.85874854\n",
            "Iteration 20347, loss = 28314.31352389\n",
            "Iteration 20348, loss = 28312.80992045\n",
            "Iteration 20349, loss = 28310.84477139\n",
            "Iteration 20350, loss = 28312.29926207\n",
            "Iteration 20351, loss = 28312.62423846\n",
            "Iteration 20352, loss = 28312.58251526\n",
            "Iteration 20353, loss = 28311.28448358\n",
            "Iteration 20354, loss = 28310.80784807\n",
            "Iteration 20355, loss = 28311.20335437\n",
            "Iteration 20356, loss = 28311.49918179\n",
            "Iteration 20357, loss = 28311.11672565\n",
            "Iteration 20358, loss = 28311.33218982\n",
            "Iteration 20359, loss = 28310.09707984\n",
            "Iteration 20360, loss = 28309.56113621\n",
            "Iteration 20361, loss = 28311.79168749\n",
            "Iteration 20362, loss = 28312.35575872\n",
            "Iteration 20363, loss = 28311.39474946\n",
            "Iteration 20364, loss = 28309.59945974\n",
            "Iteration 20365, loss = 28309.43079828\n",
            "Iteration 20366, loss = 28310.09049100\n",
            "Iteration 20367, loss = 28309.55207529\n",
            "Iteration 20368, loss = 28308.63399890\n",
            "Iteration 20369, loss = 28308.72468235\n",
            "Iteration 20370, loss = 28308.11528126\n",
            "Iteration 20371, loss = 28306.48824988\n",
            "Iteration 20372, loss = 28306.30907815\n",
            "Iteration 20373, loss = 28306.38892974\n",
            "Iteration 20374, loss = 28306.04376149\n",
            "Iteration 20375, loss = 28305.88462153\n",
            "Iteration 20376, loss = 28305.27841391\n",
            "Iteration 20377, loss = 28305.99605205\n",
            "Iteration 20378, loss = 28306.44368577\n",
            "Iteration 20379, loss = 28305.66762084\n",
            "Iteration 20380, loss = 28306.11561232\n",
            "Iteration 20381, loss = 28305.53302567\n",
            "Iteration 20382, loss = 28304.34553450\n",
            "Iteration 20383, loss = 28306.15973303\n",
            "Iteration 20384, loss = 28306.42387361\n",
            "Iteration 20385, loss = 28305.12883042\n",
            "Iteration 20386, loss = 28304.32511844\n",
            "Iteration 20387, loss = 28304.51852705\n",
            "Iteration 20388, loss = 28304.33121477\n",
            "Iteration 20389, loss = 28304.13490670\n",
            "Iteration 20390, loss = 28303.40523873\n",
            "Iteration 20391, loss = 28303.15584283\n",
            "Iteration 20392, loss = 28302.16881955\n",
            "Iteration 20393, loss = 28302.38585447\n",
            "Iteration 20394, loss = 28301.67781504\n",
            "Iteration 20395, loss = 28301.46666267\n",
            "Iteration 20396, loss = 28301.06253322\n",
            "Iteration 20397, loss = 28301.20810533\n",
            "Iteration 20398, loss = 28300.71543141\n",
            "Iteration 20399, loss = 28301.62626881\n",
            "Iteration 20400, loss = 28301.39768431\n",
            "Iteration 20401, loss = 28301.21182583\n",
            "Iteration 20402, loss = 28300.90767397\n",
            "Iteration 20403, loss = 28299.64349708\n",
            "Iteration 20404, loss = 28300.94808277\n",
            "Iteration 20405, loss = 28301.26918494\n",
            "Iteration 20406, loss = 28299.40077736\n",
            "Iteration 20407, loss = 28300.02998492\n",
            "Iteration 20408, loss = 28300.59048275\n",
            "Iteration 20409, loss = 28299.97537589\n",
            "Iteration 20410, loss = 28299.73715018\n",
            "Iteration 20411, loss = 28299.11992224\n",
            "Iteration 20412, loss = 28298.84828151\n",
            "Iteration 20413, loss = 28299.17788999\n",
            "Iteration 20414, loss = 28298.80983323\n",
            "Iteration 20415, loss = 28298.51505872\n",
            "Iteration 20416, loss = 28298.21678904\n",
            "Iteration 20417, loss = 28299.52802116\n",
            "Iteration 20418, loss = 28299.48936930\n",
            "Iteration 20419, loss = 28297.99447109\n",
            "Iteration 20420, loss = 28296.05709251\n",
            "Iteration 20421, loss = 28297.36134985\n",
            "Iteration 20422, loss = 28297.77075960\n",
            "Iteration 20423, loss = 28297.17381550\n",
            "Iteration 20424, loss = 28295.42327003\n",
            "Iteration 20425, loss = 28296.55053860\n",
            "Iteration 20426, loss = 28296.98222071\n",
            "Iteration 20427, loss = 28296.18868708\n",
            "Iteration 20428, loss = 28294.99013084\n",
            "Iteration 20429, loss = 28294.67293054\n",
            "Iteration 20430, loss = 28294.35520754\n",
            "Iteration 20431, loss = 28293.72377524\n",
            "Iteration 20432, loss = 28293.93098052\n",
            "Iteration 20433, loss = 28294.01435640\n",
            "Iteration 20434, loss = 28293.34235243\n",
            "Iteration 20435, loss = 28293.78501238\n",
            "Iteration 20436, loss = 28294.83265480\n",
            "Iteration 20437, loss = 28293.89121521\n",
            "Iteration 20438, loss = 28292.43154548\n",
            "Iteration 20439, loss = 28293.29044908\n",
            "Iteration 20440, loss = 28292.38556069\n",
            "Iteration 20441, loss = 28292.11732125\n",
            "Iteration 20442, loss = 28292.31636027\n",
            "Iteration 20443, loss = 28291.58371032\n",
            "Iteration 20444, loss = 28290.97157544\n",
            "Iteration 20445, loss = 28291.44984427\n",
            "Iteration 20446, loss = 28291.03006055\n",
            "Iteration 20447, loss = 28291.45487825\n",
            "Iteration 20448, loss = 28291.08843923\n",
            "Iteration 20449, loss = 28289.98606881\n",
            "Iteration 20450, loss = 28290.28507190\n",
            "Iteration 20451, loss = 28290.05013259\n",
            "Iteration 20452, loss = 28289.73451324\n",
            "Iteration 20453, loss = 28289.17067996\n",
            "Iteration 20454, loss = 28289.28186487\n",
            "Iteration 20455, loss = 28288.79661864\n",
            "Iteration 20456, loss = 28288.63424739\n",
            "Iteration 20457, loss = 28287.98877375\n",
            "Iteration 20458, loss = 28288.41294706\n",
            "Iteration 20459, loss = 28288.04829913\n",
            "Iteration 20460, loss = 28287.21972309\n",
            "Iteration 20461, loss = 28287.78438700\n",
            "Iteration 20462, loss = 28287.77109579\n",
            "Iteration 20463, loss = 28287.60297507\n",
            "Iteration 20464, loss = 28287.32374496\n",
            "Iteration 20465, loss = 28287.43082781\n",
            "Iteration 20466, loss = 28287.20389328\n",
            "Iteration 20467, loss = 28287.05497757\n",
            "Iteration 20468, loss = 28287.27242663\n",
            "Iteration 20469, loss = 28286.29586098\n",
            "Iteration 20470, loss = 28285.44080479\n",
            "Iteration 20471, loss = 28286.04560948\n",
            "Iteration 20472, loss = 28284.97530687\n",
            "Iteration 20473, loss = 28285.15945590\n",
            "Iteration 20474, loss = 28285.22553842\n",
            "Iteration 20475, loss = 28284.98763319\n",
            "Iteration 20476, loss = 28284.99714043\n",
            "Iteration 20477, loss = 28285.17814068\n",
            "Iteration 20478, loss = 28285.47481374\n",
            "Iteration 20479, loss = 28284.52962294\n",
            "Iteration 20480, loss = 28283.71207407\n",
            "Iteration 20481, loss = 28284.45474059\n",
            "Iteration 20482, loss = 28284.65345058\n",
            "Iteration 20483, loss = 28283.16850180\n",
            "Iteration 20484, loss = 28283.65446981\n",
            "Iteration 20485, loss = 28284.64750924\n",
            "Iteration 20486, loss = 28284.05339348\n",
            "Iteration 20487, loss = 28283.27492356\n",
            "Iteration 20488, loss = 28282.86884633\n",
            "Iteration 20489, loss = 28283.43450331\n",
            "Iteration 20490, loss = 28282.81028929\n",
            "Iteration 20491, loss = 28282.53332651\n",
            "Iteration 20492, loss = 28282.19352764\n",
            "Iteration 20493, loss = 28281.72241746\n",
            "Iteration 20494, loss = 28281.10901299\n",
            "Iteration 20495, loss = 28280.77383973\n",
            "Iteration 20496, loss = 28281.30209444\n",
            "Iteration 20497, loss = 28280.84219582\n",
            "Iteration 20498, loss = 28280.03909028\n",
            "Iteration 20499, loss = 28280.50001687\n",
            "Iteration 20500, loss = 28280.37795280\n",
            "Iteration 20501, loss = 28279.15593372\n",
            "Iteration 20502, loss = 28279.28847694\n",
            "Iteration 20503, loss = 28279.18158614\n",
            "Iteration 20504, loss = 28279.02614197\n",
            "Iteration 20505, loss = 28278.93751970\n",
            "Iteration 20506, loss = 28277.96360014\n",
            "Iteration 20507, loss = 28278.61983620\n",
            "Iteration 20508, loss = 28279.15369801\n",
            "Iteration 20509, loss = 28278.68632173\n",
            "Iteration 20510, loss = 28278.08656653\n",
            "Iteration 20511, loss = 28278.03894300\n",
            "Iteration 20512, loss = 28277.42324988\n",
            "Iteration 20513, loss = 28277.18737281\n",
            "Iteration 20514, loss = 28276.62967185\n",
            "Iteration 20515, loss = 28276.73034569\n",
            "Iteration 20516, loss = 28277.16564728\n",
            "Iteration 20517, loss = 28276.75366287\n",
            "Iteration 20518, loss = 28277.63497335\n",
            "Iteration 20519, loss = 28277.59139161\n",
            "Iteration 20520, loss = 28276.68297558\n",
            "Iteration 20521, loss = 28275.31432889\n",
            "Iteration 20522, loss = 28275.21983506\n",
            "Iteration 20523, loss = 28276.01123251\n",
            "Iteration 20524, loss = 28275.17979961\n",
            "Iteration 20525, loss = 28273.50660459\n",
            "Iteration 20526, loss = 28273.83146284\n",
            "Iteration 20527, loss = 28274.32810817\n",
            "Iteration 20528, loss = 28273.40784680\n",
            "Iteration 20529, loss = 28273.22654565\n",
            "Iteration 20530, loss = 28272.84609277\n",
            "Iteration 20531, loss = 28272.57002988\n",
            "Iteration 20532, loss = 28272.88205617\n",
            "Iteration 20533, loss = 28272.55282153\n",
            "Iteration 20534, loss = 28271.87477206\n",
            "Iteration 20535, loss = 28272.85830990\n",
            "Iteration 20536, loss = 28273.49155303\n",
            "Iteration 20537, loss = 28271.58556761\n",
            "Iteration 20538, loss = 28273.03181764\n",
            "Iteration 20539, loss = 28274.19297368\n",
            "Iteration 20540, loss = 28273.59849877\n",
            "Iteration 20541, loss = 28272.14082767\n",
            "Iteration 20542, loss = 28272.73154576\n",
            "Iteration 20543, loss = 28272.26164049\n",
            "Iteration 20544, loss = 28272.78047175\n",
            "Iteration 20545, loss = 28272.33593202\n",
            "Iteration 20546, loss = 28271.54491808\n",
            "Iteration 20547, loss = 28270.07796748\n",
            "Iteration 20548, loss = 28270.96754363\n",
            "Iteration 20549, loss = 28270.86983512\n",
            "Iteration 20550, loss = 28271.39786305\n",
            "Iteration 20551, loss = 28271.10329779\n",
            "Iteration 20552, loss = 28270.43174265\n",
            "Iteration 20553, loss = 28269.40251923\n",
            "Iteration 20554, loss = 28268.10787148\n",
            "Iteration 20555, loss = 28269.12743317\n",
            "Iteration 20556, loss = 28269.63590570\n",
            "Iteration 20557, loss = 28268.26038773\n",
            "Iteration 20558, loss = 28266.98835496\n",
            "Iteration 20559, loss = 28267.54445826\n",
            "Iteration 20560, loss = 28267.59525207\n",
            "Iteration 20561, loss = 28266.81515402\n",
            "Iteration 20562, loss = 28267.21267384\n",
            "Iteration 20563, loss = 28268.02038997\n",
            "Iteration 20564, loss = 28267.46725560\n",
            "Iteration 20565, loss = 28266.40824925\n",
            "Iteration 20566, loss = 28266.84230842\n",
            "Iteration 20567, loss = 28267.13770378\n",
            "Iteration 20568, loss = 28265.81823028\n",
            "Iteration 20569, loss = 28265.12922373\n",
            "Iteration 20570, loss = 28265.75597570\n",
            "Iteration 20571, loss = 28265.37441287\n",
            "Iteration 20572, loss = 28264.69149633\n",
            "Iteration 20573, loss = 28264.22642098\n",
            "Iteration 20574, loss = 28264.02327918\n",
            "Iteration 20575, loss = 28263.80104280\n",
            "Iteration 20576, loss = 28263.58225715\n",
            "Iteration 20577, loss = 28263.14386918\n",
            "Iteration 20578, loss = 28264.02444612\n",
            "Iteration 20579, loss = 28263.31896150\n",
            "Iteration 20580, loss = 28262.87368382\n",
            "Iteration 20581, loss = 28263.24587463\n",
            "Iteration 20582, loss = 28263.25972785\n",
            "Iteration 20583, loss = 28262.06484257\n",
            "Iteration 20584, loss = 28262.10721469\n",
            "Iteration 20585, loss = 28262.58859895\n",
            "Iteration 20586, loss = 28261.83971557\n",
            "Iteration 20587, loss = 28260.90451095\n",
            "Iteration 20588, loss = 28261.51160649\n",
            "Iteration 20589, loss = 28262.51279771\n",
            "Iteration 20590, loss = 28261.47630496\n",
            "Iteration 20591, loss = 28260.22122655\n",
            "Iteration 20592, loss = 28260.49565210\n",
            "Iteration 20593, loss = 28260.07956116\n",
            "Iteration 20594, loss = 28259.66279411\n",
            "Iteration 20595, loss = 28260.60554285\n",
            "Iteration 20596, loss = 28260.51617068\n",
            "Iteration 20597, loss = 28259.23389354\n",
            "Iteration 20598, loss = 28259.71953202\n",
            "Iteration 20599, loss = 28260.03774815\n",
            "Iteration 20600, loss = 28260.04270580\n",
            "Iteration 20601, loss = 28259.74190377\n",
            "Iteration 20602, loss = 28258.95469168\n",
            "Iteration 20603, loss = 28258.52059111\n",
            "Iteration 20604, loss = 28258.59257625\n",
            "Iteration 20605, loss = 28258.93322715\n",
            "Iteration 20606, loss = 28258.11401771\n",
            "Iteration 20607, loss = 28256.80632655\n",
            "Iteration 20608, loss = 28257.16047533\n",
            "Iteration 20609, loss = 28256.74655687\n",
            "Iteration 20610, loss = 28256.62594566\n",
            "Iteration 20611, loss = 28255.85433804\n",
            "Iteration 20612, loss = 28255.34336583\n",
            "Iteration 20613, loss = 28256.42399941\n",
            "Iteration 20614, loss = 28256.56636851\n",
            "Iteration 20615, loss = 28255.48555770\n",
            "Iteration 20616, loss = 28255.11940161\n",
            "Iteration 20617, loss = 28255.79502524\n",
            "Iteration 20618, loss = 28256.02620464\n",
            "Iteration 20619, loss = 28254.85305640\n",
            "Iteration 20620, loss = 28254.85701053\n",
            "Iteration 20621, loss = 28255.08183181\n",
            "Iteration 20622, loss = 28255.41303980\n",
            "Iteration 20623, loss = 28255.14882889\n",
            "Iteration 20624, loss = 28254.15449322\n",
            "Iteration 20625, loss = 28253.76722252\n",
            "Iteration 20626, loss = 28255.14785422\n",
            "Iteration 20627, loss = 28254.88059979\n",
            "Iteration 20628, loss = 28254.02974637\n",
            "Iteration 20629, loss = 28253.12651314\n",
            "Iteration 20630, loss = 28253.48553798\n",
            "Iteration 20631, loss = 28254.16438023\n",
            "Iteration 20632, loss = 28254.92810864\n",
            "Iteration 20633, loss = 28252.98241364\n",
            "Iteration 20634, loss = 28249.34065434\n",
            "Iteration 20635, loss = 28246.62689013\n",
            "Iteration 20636, loss = 28243.96883817\n",
            "Iteration 20637, loss = 28240.71635964\n",
            "Iteration 20638, loss = 28236.75682707\n",
            "Iteration 20639, loss = 28232.19812854\n",
            "Iteration 20640, loss = 28229.97712466\n",
            "Iteration 20641, loss = 28226.22501502\n",
            "Iteration 20642, loss = 28222.48723861\n",
            "Iteration 20643, loss = 28219.17917557\n",
            "Iteration 20644, loss = 28215.29326257\n",
            "Iteration 20645, loss = 28210.76316770\n",
            "Iteration 20646, loss = 28207.09369034\n",
            "Iteration 20647, loss = 28203.05745518\n",
            "Iteration 20648, loss = 28199.89962334\n",
            "Iteration 20649, loss = 28199.18710932\n",
            "Iteration 20650, loss = 28197.77050186\n",
            "Iteration 20651, loss = 28196.13536897\n",
            "Iteration 20652, loss = 28195.36661854\n",
            "Iteration 20653, loss = 28194.78841577\n",
            "Iteration 20654, loss = 28193.27126706\n",
            "Iteration 20655, loss = 28192.58029723\n",
            "Iteration 20656, loss = 28193.44282925\n",
            "Iteration 20657, loss = 28192.70581970\n",
            "Iteration 20658, loss = 28191.95030945\n",
            "Iteration 20659, loss = 28192.09966144\n",
            "Iteration 20660, loss = 28191.62912118\n",
            "Iteration 20661, loss = 28191.04176367\n",
            "Iteration 20662, loss = 28192.19524627\n",
            "Iteration 20663, loss = 28191.42046535\n",
            "Iteration 20664, loss = 28190.66873752\n",
            "Iteration 20665, loss = 28190.38382783\n",
            "Iteration 20666, loss = 28189.39063583\n",
            "Iteration 20667, loss = 28189.24979641\n",
            "Iteration 20668, loss = 28188.64561768\n",
            "Iteration 20669, loss = 28188.79909108\n",
            "Iteration 20670, loss = 28188.64602160\n",
            "Iteration 20671, loss = 28188.08862295\n",
            "Iteration 20672, loss = 28187.39681761\n",
            "Iteration 20673, loss = 28187.04987225\n",
            "Iteration 20674, loss = 28186.59640120\n",
            "Iteration 20675, loss = 28186.31682394\n",
            "Iteration 20676, loss = 28186.62691546\n",
            "Iteration 20677, loss = 28186.36022890\n",
            "Iteration 20678, loss = 28186.74475669\n",
            "Iteration 20679, loss = 28186.26632228\n",
            "Iteration 20680, loss = 28185.35696712\n",
            "Iteration 20681, loss = 28185.62237768\n",
            "Iteration 20682, loss = 28185.20556663\n",
            "Iteration 20683, loss = 28185.73194173\n",
            "Iteration 20684, loss = 28186.00063907\n",
            "Iteration 20685, loss = 28185.11160081\n",
            "Iteration 20686, loss = 28184.01813461\n",
            "Iteration 20687, loss = 28183.34041284\n",
            "Iteration 20688, loss = 28184.46635259\n",
            "Iteration 20689, loss = 28183.27725023\n",
            "Iteration 20690, loss = 28183.07574724\n",
            "Iteration 20691, loss = 28183.57697920\n",
            "Iteration 20692, loss = 28183.59522297\n",
            "Iteration 20693, loss = 28182.70377903\n",
            "Iteration 20694, loss = 28183.32430879\n",
            "Iteration 20695, loss = 28183.84155463\n",
            "Iteration 20696, loss = 28182.92253967\n",
            "Iteration 20697, loss = 28181.46056681\n",
            "Iteration 20698, loss = 28182.06214793\n",
            "Iteration 20699, loss = 28183.33079790\n",
            "Iteration 20700, loss = 28183.20455924\n",
            "Iteration 20701, loss = 28181.43724428\n",
            "Iteration 20702, loss = 28180.83177443\n",
            "Iteration 20703, loss = 28180.35859159\n",
            "Iteration 20704, loss = 28180.26294118\n",
            "Iteration 20705, loss = 28180.42115310\n",
            "Iteration 20706, loss = 28180.79381029\n",
            "Iteration 20707, loss = 28180.01347368\n",
            "Iteration 20708, loss = 28178.41438202\n",
            "Iteration 20709, loss = 28178.40752042\n",
            "Iteration 20710, loss = 28179.80447407\n",
            "Iteration 20711, loss = 28179.72777134\n",
            "Iteration 20712, loss = 28178.79579218\n",
            "Iteration 20713, loss = 28178.12704270\n",
            "Iteration 20714, loss = 28177.26705483\n",
            "Iteration 20715, loss = 28177.48248279\n",
            "Iteration 20716, loss = 28177.39555582\n",
            "Iteration 20717, loss = 28176.39918680\n",
            "Iteration 20718, loss = 28175.25801209\n",
            "Iteration 20719, loss = 28175.82524957\n",
            "Iteration 20720, loss = 28176.08575937\n",
            "Iteration 20721, loss = 28175.35036563\n",
            "Iteration 20722, loss = 28174.97307473\n",
            "Iteration 20723, loss = 28174.40285204\n",
            "Iteration 20724, loss = 28174.13377823\n",
            "Iteration 20725, loss = 28175.22613535\n",
            "Iteration 20726, loss = 28174.72690861\n",
            "Iteration 20727, loss = 28174.33414448\n",
            "Iteration 20728, loss = 28174.02941555\n",
            "Iteration 20729, loss = 28174.05027297\n",
            "Iteration 20730, loss = 28173.71182134\n",
            "Iteration 20731, loss = 28173.95194760\n",
            "Iteration 20732, loss = 28172.93573197\n",
            "Iteration 20733, loss = 28172.34089099\n",
            "Iteration 20734, loss = 28172.09499252\n",
            "Iteration 20735, loss = 28171.87183541\n",
            "Iteration 20736, loss = 28172.04022096\n",
            "Iteration 20737, loss = 28172.07309342\n",
            "Iteration 20738, loss = 28171.32627289\n",
            "Iteration 20739, loss = 28170.83971074\n",
            "Iteration 20740, loss = 28170.82909176\n",
            "Iteration 20741, loss = 28171.18561148\n",
            "Iteration 20742, loss = 28170.81734544\n",
            "Iteration 20743, loss = 28170.83061956\n",
            "Iteration 20744, loss = 28170.39861659\n",
            "Iteration 20745, loss = 28169.45878993\n",
            "Iteration 20746, loss = 28169.32155212\n",
            "Iteration 20747, loss = 28169.64836562\n",
            "Iteration 20748, loss = 28168.58333726\n",
            "Iteration 20749, loss = 28168.00607381\n",
            "Iteration 20750, loss = 28168.43523182\n",
            "Iteration 20751, loss = 28168.85566663\n",
            "Iteration 20752, loss = 28168.03866027\n",
            "Iteration 20753, loss = 28168.88891199\n",
            "Iteration 20754, loss = 28168.55677452\n",
            "Iteration 20755, loss = 28168.07473543\n",
            "Iteration 20756, loss = 28168.81076962\n",
            "Iteration 20757, loss = 28168.53797585\n",
            "Iteration 20758, loss = 28168.17605656\n",
            "Iteration 20759, loss = 28166.94523669\n",
            "Iteration 20760, loss = 28167.48285380\n",
            "Iteration 20761, loss = 28168.41759468\n",
            "Iteration 20762, loss = 28168.01507273\n",
            "Iteration 20763, loss = 28166.81307892\n",
            "Iteration 20764, loss = 28164.72972353\n",
            "Iteration 20765, loss = 28165.42708864\n",
            "Iteration 20766, loss = 28165.54597758\n",
            "Iteration 20767, loss = 28165.44358695\n",
            "Iteration 20768, loss = 28164.47851700\n",
            "Iteration 20769, loss = 28163.85178431\n",
            "Iteration 20770, loss = 28163.69844508\n",
            "Iteration 20771, loss = 28163.79608466\n",
            "Iteration 20772, loss = 28163.10131786\n",
            "Iteration 20773, loss = 28162.84245902\n",
            "Iteration 20774, loss = 28162.78602625\n",
            "Iteration 20775, loss = 28162.84099377\n",
            "Iteration 20776, loss = 28162.63580449\n",
            "Iteration 20777, loss = 28163.31010878\n",
            "Iteration 20778, loss = 28163.21825488\n",
            "Iteration 20779, loss = 28162.55433756\n",
            "Iteration 20780, loss = 28162.35377633\n",
            "Iteration 20781, loss = 28162.26941735\n",
            "Iteration 20782, loss = 28162.01481849\n",
            "Iteration 20783, loss = 28161.61803301\n",
            "Iteration 20784, loss = 28160.21040580\n",
            "Iteration 20785, loss = 28160.24554025\n",
            "Iteration 20786, loss = 28160.26287277\n",
            "Iteration 20787, loss = 28160.13945855\n",
            "Iteration 20788, loss = 28159.19354691\n",
            "Iteration 20789, loss = 28160.11201623\n",
            "Iteration 20790, loss = 28160.26896079\n",
            "Iteration 20791, loss = 28159.70091637\n",
            "Iteration 20792, loss = 28159.67610680\n",
            "Iteration 20793, loss = 28158.69302192\n",
            "Iteration 20794, loss = 28159.12955954\n",
            "Iteration 20795, loss = 28159.43211580\n",
            "Iteration 20796, loss = 28157.26175925\n",
            "Iteration 20797, loss = 28158.05304276\n",
            "Iteration 20798, loss = 28159.22658479\n",
            "Iteration 20799, loss = 28158.84860991\n",
            "Iteration 20800, loss = 28158.92764972\n",
            "Iteration 20801, loss = 28158.30533236\n",
            "Iteration 20802, loss = 28156.61948165\n",
            "Iteration 20803, loss = 28157.31505445\n",
            "Iteration 20804, loss = 28157.83879776\n",
            "Iteration 20805, loss = 28156.02318883\n",
            "Iteration 20806, loss = 28155.91401033\n",
            "Iteration 20807, loss = 28156.85617505\n",
            "Iteration 20808, loss = 28156.77939267\n",
            "Iteration 20809, loss = 28156.38264489\n",
            "Iteration 20810, loss = 28155.45099517\n",
            "Iteration 20811, loss = 28154.92709006\n",
            "Iteration 20812, loss = 28154.64863574\n",
            "Iteration 20813, loss = 28154.63132102\n",
            "Iteration 20814, loss = 28153.58862767\n",
            "Iteration 20815, loss = 28153.35304831\n",
            "Iteration 20816, loss = 28153.66373294\n",
            "Iteration 20817, loss = 28154.06216269\n",
            "Iteration 20818, loss = 28153.48188790\n",
            "Iteration 20819, loss = 28153.14699012\n",
            "Iteration 20820, loss = 28152.70110172\n",
            "Iteration 20821, loss = 28153.34963300\n",
            "Iteration 20822, loss = 28153.31861980\n",
            "Iteration 20823, loss = 28153.67092970\n",
            "Iteration 20824, loss = 28152.99509522\n",
            "Iteration 20825, loss = 28152.69381237\n",
            "Iteration 20826, loss = 28151.69884119\n",
            "Iteration 20827, loss = 28151.64678279\n",
            "Iteration 20828, loss = 28152.29225117\n",
            "Iteration 20829, loss = 28151.68439569\n",
            "Iteration 20830, loss = 28150.62916729\n",
            "Iteration 20831, loss = 28150.13816084\n",
            "Iteration 20832, loss = 28150.36713322\n",
            "Iteration 20833, loss = 28149.58959782\n",
            "Iteration 20834, loss = 28149.34153017\n",
            "Iteration 20835, loss = 28150.25552344\n",
            "Iteration 20836, loss = 28149.78507002\n",
            "Iteration 20837, loss = 28148.31975110\n",
            "Iteration 20838, loss = 28149.08865997\n",
            "Iteration 20839, loss = 28149.61413272\n",
            "Iteration 20840, loss = 28148.69486611\n",
            "Iteration 20841, loss = 28147.62729939\n",
            "Iteration 20842, loss = 28148.40699249\n",
            "Iteration 20843, loss = 28148.74413280\n",
            "Iteration 20844, loss = 28148.20946693\n",
            "Iteration 20845, loss = 28148.23801221\n",
            "Iteration 20846, loss = 28147.64994915\n",
            "Iteration 20847, loss = 28146.65114480\n",
            "Iteration 20848, loss = 28146.25688271\n",
            "Iteration 20849, loss = 28146.90397071\n",
            "Iteration 20850, loss = 28146.36528013\n",
            "Iteration 20851, loss = 28145.91464552\n",
            "Iteration 20852, loss = 28146.13461757\n",
            "Iteration 20853, loss = 28145.60225021\n",
            "Iteration 20854, loss = 28145.69860372\n",
            "Iteration 20855, loss = 28146.20527622\n",
            "Iteration 20856, loss = 28145.63236023\n",
            "Iteration 20857, loss = 28144.93123642\n",
            "Iteration 20858, loss = 28145.03440171\n",
            "Iteration 20859, loss = 28145.64858150\n",
            "Iteration 20860, loss = 28145.40646316\n",
            "Iteration 20861, loss = 28143.99089584\n",
            "Iteration 20862, loss = 28144.98964385\n",
            "Iteration 20863, loss = 28145.67285717\n",
            "Iteration 20864, loss = 28144.83777567\n",
            "Iteration 20865, loss = 28143.70573684\n",
            "Iteration 20866, loss = 28143.44801878\n",
            "Iteration 20867, loss = 28143.30917187\n",
            "Iteration 20868, loss = 28143.47294721\n",
            "Iteration 20869, loss = 28144.04092251\n",
            "Iteration 20870, loss = 28142.05036269\n",
            "Iteration 20871, loss = 28142.09618070\n",
            "Iteration 20872, loss = 28143.27963692\n",
            "Iteration 20873, loss = 28143.32668550\n",
            "Iteration 20874, loss = 28143.06786793\n",
            "Iteration 20875, loss = 28142.23229877\n",
            "Iteration 20876, loss = 28140.45678426\n",
            "Iteration 20877, loss = 28140.69563539\n",
            "Iteration 20878, loss = 28140.64428524\n",
            "Iteration 20879, loss = 28141.54438956\n",
            "Iteration 20880, loss = 28141.38676542\n",
            "Iteration 20881, loss = 28140.08224275\n",
            "Iteration 20882, loss = 28140.86413865\n",
            "Iteration 20883, loss = 28141.13747528\n",
            "Iteration 20884, loss = 28140.32788231\n",
            "Iteration 20885, loss = 28140.44842706\n",
            "Iteration 20886, loss = 28140.57846378\n",
            "Iteration 20887, loss = 28141.18847308\n",
            "Iteration 20888, loss = 28140.65496123\n",
            "Iteration 20889, loss = 28138.97694245\n",
            "Iteration 20890, loss = 28138.07819881\n",
            "Iteration 20891, loss = 28138.41284501\n",
            "Iteration 20892, loss = 28139.83308281\n",
            "Iteration 20893, loss = 28139.14025785\n",
            "Iteration 20894, loss = 28138.26114235\n",
            "Iteration 20895, loss = 28137.91725672\n",
            "Iteration 20896, loss = 28138.52245979\n",
            "Iteration 20897, loss = 28138.76828259\n",
            "Iteration 20898, loss = 28138.66849729\n",
            "Iteration 20899, loss = 28138.90010633\n",
            "Iteration 20900, loss = 28138.03334896\n",
            "Iteration 20901, loss = 28137.07240132\n",
            "Iteration 20902, loss = 28135.98592943\n",
            "Iteration 20903, loss = 28134.48899431\n",
            "Iteration 20904, loss = 28136.19731130\n",
            "Iteration 20905, loss = 28136.59327299\n",
            "Iteration 20906, loss = 28136.51162096\n",
            "Iteration 20907, loss = 28134.76868369\n",
            "Iteration 20908, loss = 28134.28761554\n",
            "Iteration 20909, loss = 28134.90225403\n",
            "Iteration 20910, loss = 28134.37573360\n",
            "Iteration 20911, loss = 28134.49440825\n",
            "Iteration 20912, loss = 28134.94882264\n",
            "Iteration 20913, loss = 28133.78951286\n",
            "Iteration 20914, loss = 28132.48081847\n",
            "Iteration 20915, loss = 28133.42279890\n",
            "Iteration 20916, loss = 28134.94836005\n",
            "Iteration 20917, loss = 28133.92616006\n",
            "Iteration 20918, loss = 28131.76597867\n",
            "Iteration 20919, loss = 28131.64607497\n",
            "Iteration 20920, loss = 28130.98223846\n",
            "Iteration 20921, loss = 28131.52779395\n",
            "Iteration 20922, loss = 28131.45858382\n",
            "Iteration 20923, loss = 28131.18456533\n",
            "Iteration 20924, loss = 28131.21295018\n",
            "Iteration 20925, loss = 28130.87312376\n",
            "Iteration 20926, loss = 28130.52769879\n",
            "Iteration 20927, loss = 28130.52187388\n",
            "Iteration 20928, loss = 28130.61746506\n",
            "Iteration 20929, loss = 28130.06071165\n",
            "Iteration 20930, loss = 28129.70853449\n",
            "Iteration 20931, loss = 28129.60239810\n",
            "Iteration 20932, loss = 28129.10516010\n",
            "Iteration 20933, loss = 28128.21524966\n",
            "Iteration 20934, loss = 28128.32698565\n",
            "Iteration 20935, loss = 28129.26375721\n",
            "Iteration 20936, loss = 28129.06111196\n",
            "Iteration 20937, loss = 28128.27470447\n",
            "Iteration 20938, loss = 28127.87567125\n",
            "Iteration 20939, loss = 28126.94580108\n",
            "Iteration 20940, loss = 28126.32538502\n",
            "Iteration 20941, loss = 28127.39592823\n",
            "Iteration 20942, loss = 28127.13971488\n",
            "Iteration 20943, loss = 28127.45158082\n",
            "Iteration 20944, loss = 28126.02834036\n",
            "Iteration 20945, loss = 28125.50755760\n",
            "Iteration 20946, loss = 28125.72948280\n",
            "Iteration 20947, loss = 28125.43118981\n",
            "Iteration 20948, loss = 28124.22885609\n",
            "Iteration 20949, loss = 28125.45400580\n",
            "Iteration 20950, loss = 28125.71778354\n",
            "Iteration 20951, loss = 28124.17889449\n",
            "Iteration 20952, loss = 28124.40713637\n",
            "Iteration 20953, loss = 28124.66662654\n",
            "Iteration 20954, loss = 28125.02093873\n",
            "Iteration 20955, loss = 28124.17706182\n",
            "Iteration 20956, loss = 28124.31952770\n",
            "Iteration 20957, loss = 28124.02499607\n",
            "Iteration 20958, loss = 28122.97260391\n",
            "Iteration 20959, loss = 28122.97727151\n",
            "Iteration 20960, loss = 28123.36267885\n",
            "Iteration 20961, loss = 28123.46450226\n",
            "Iteration 20962, loss = 28123.08001144\n",
            "Iteration 20963, loss = 28122.10025473\n",
            "Iteration 20964, loss = 28121.22284213\n",
            "Iteration 20965, loss = 28121.76861793\n",
            "Iteration 20966, loss = 28121.47785627\n",
            "Iteration 20967, loss = 28121.12809198\n",
            "Iteration 20968, loss = 28120.87865138\n",
            "Iteration 20969, loss = 28120.37476818\n",
            "Iteration 20970, loss = 28119.69530828\n",
            "Iteration 20971, loss = 28120.09892155\n",
            "Iteration 20972, loss = 28119.91463968\n",
            "Iteration 20973, loss = 28119.77757102\n",
            "Iteration 20974, loss = 28119.24626127\n",
            "Iteration 20975, loss = 28119.60506644\n",
            "Iteration 20976, loss = 28119.28014542\n",
            "Iteration 20977, loss = 28118.54856711\n",
            "Iteration 20978, loss = 28119.33913103\n",
            "Iteration 20979, loss = 28119.76268431\n",
            "Iteration 20980, loss = 28118.67141481\n",
            "Iteration 20981, loss = 28118.52988979\n",
            "Iteration 20982, loss = 28118.59527827\n",
            "Iteration 20983, loss = 28118.59686590\n",
            "Iteration 20984, loss = 28119.29217157\n",
            "Iteration 20985, loss = 28118.37540627\n",
            "Iteration 20986, loss = 28116.99467214\n",
            "Iteration 20987, loss = 28116.90443198\n",
            "Iteration 20988, loss = 28118.07623865\n",
            "Iteration 20989, loss = 28117.19626105\n",
            "Iteration 20990, loss = 28116.57729766\n",
            "Iteration 20991, loss = 28117.28907719\n",
            "Iteration 20992, loss = 28116.92774292\n",
            "Iteration 20993, loss = 28116.09944505\n",
            "Iteration 20994, loss = 28115.26375479\n",
            "Iteration 20995, loss = 28114.42985303\n",
            "Iteration 20996, loss = 28116.24605182\n",
            "Iteration 20997, loss = 28116.17338347\n",
            "Iteration 20998, loss = 28114.66154055\n",
            "Iteration 20999, loss = 28114.20677587\n",
            "Iteration 21000, loss = 28114.50497345\n",
            "Iteration 21001, loss = 28113.89673423\n",
            "Iteration 21002, loss = 28113.30187408\n",
            "Iteration 21003, loss = 28113.42889530\n",
            "Iteration 21004, loss = 28114.42052730\n",
            "Iteration 21005, loss = 28113.18856612\n",
            "Iteration 21006, loss = 28113.46834978\n",
            "Iteration 21007, loss = 28114.04093324\n",
            "Iteration 21008, loss = 28114.03518422\n",
            "Iteration 21009, loss = 28113.22622096\n",
            "Iteration 21010, loss = 28113.81443196\n",
            "Iteration 21011, loss = 28113.75816811\n",
            "Iteration 21012, loss = 28112.53469290\n",
            "Iteration 21013, loss = 28111.86413600\n",
            "Iteration 21014, loss = 28112.24202189\n",
            "Iteration 21015, loss = 28112.06360401\n",
            "Iteration 21016, loss = 28111.51652412\n",
            "Iteration 21017, loss = 28111.36411527\n",
            "Iteration 21018, loss = 28111.08759225\n",
            "Iteration 21019, loss = 28111.54692372\n",
            "Iteration 21020, loss = 28110.89805157\n",
            "Iteration 21021, loss = 28109.51378177\n",
            "Iteration 21022, loss = 28109.38242834\n",
            "Iteration 21023, loss = 28109.59473897\n",
            "Iteration 21024, loss = 28109.34389228\n",
            "Iteration 21025, loss = 28108.39437528\n",
            "Iteration 21026, loss = 28108.73010884\n",
            "Iteration 21027, loss = 28108.89358555\n",
            "Iteration 21028, loss = 28108.83666313\n",
            "Iteration 21029, loss = 28108.89110923\n",
            "Iteration 21030, loss = 28108.32795972\n",
            "Iteration 21031, loss = 28107.70806873\n",
            "Iteration 21032, loss = 28107.21773490\n",
            "Iteration 21033, loss = 28107.64748279\n",
            "Iteration 21034, loss = 28107.61602543\n",
            "Iteration 21035, loss = 28106.76535421\n",
            "Iteration 21036, loss = 28106.28373962\n",
            "Iteration 21037, loss = 28106.66552500\n",
            "Iteration 21038, loss = 28106.95659800\n",
            "Iteration 21039, loss = 28106.69726099\n",
            "Iteration 21040, loss = 28106.33111522\n",
            "Iteration 21041, loss = 28104.88328651\n",
            "Iteration 21042, loss = 28106.81005871\n",
            "Iteration 21043, loss = 28107.16913735\n",
            "Iteration 21044, loss = 28105.84146022\n",
            "Iteration 21045, loss = 28104.32176834\n",
            "Iteration 21046, loss = 28105.02445461\n",
            "Iteration 21047, loss = 28104.88716799\n",
            "Iteration 21048, loss = 28104.75314808\n",
            "Iteration 21049, loss = 28104.14328415\n",
            "Iteration 21050, loss = 28104.13560438\n",
            "Iteration 21051, loss = 28104.67834634\n",
            "Iteration 21052, loss = 28103.90929618\n",
            "Iteration 21053, loss = 28102.89746920\n",
            "Iteration 21054, loss = 28104.40621802\n",
            "Iteration 21055, loss = 28105.04057535\n",
            "Iteration 21056, loss = 28104.27313724\n",
            "Iteration 21057, loss = 28103.38929580\n",
            "Iteration 21058, loss = 28102.51652508\n",
            "Iteration 21059, loss = 28102.17893669\n",
            "Iteration 21060, loss = 28102.27851816\n",
            "Iteration 21061, loss = 28102.52793691\n",
            "Iteration 21062, loss = 28102.08775150\n",
            "Iteration 21063, loss = 28102.21590551\n",
            "Iteration 21064, loss = 28101.26609994\n",
            "Iteration 21065, loss = 28101.10494730\n",
            "Iteration 21066, loss = 28100.67979123\n",
            "Iteration 21067, loss = 28100.26897042\n",
            "Iteration 21068, loss = 28100.53032285\n",
            "Iteration 21069, loss = 28100.50017470\n",
            "Iteration 21070, loss = 28099.69110912\n",
            "Iteration 21071, loss = 28099.30871764\n",
            "Iteration 21072, loss = 28100.67636930\n",
            "Iteration 21073, loss = 28100.20566143\n",
            "Iteration 21074, loss = 28099.21336249\n",
            "Iteration 21075, loss = 28099.88888244\n",
            "Iteration 21076, loss = 28099.13979100\n",
            "Iteration 21077, loss = 28098.25957335\n",
            "Iteration 21078, loss = 28097.30249700\n",
            "Iteration 21079, loss = 28098.00834060\n",
            "Iteration 21080, loss = 28098.42793103\n",
            "Iteration 21081, loss = 28097.62800164\n",
            "Iteration 21082, loss = 28097.13751536\n",
            "Iteration 21083, loss = 28096.92008005\n",
            "Iteration 21084, loss = 28097.20599039\n",
            "Iteration 21085, loss = 28096.75392287\n",
            "Iteration 21086, loss = 28096.39378169\n",
            "Iteration 21087, loss = 28096.32935375\n",
            "Iteration 21088, loss = 28095.53041204\n",
            "Iteration 21089, loss = 28095.95477923\n",
            "Iteration 21090, loss = 28095.75965677\n",
            "Iteration 21091, loss = 28095.45430586\n",
            "Iteration 21092, loss = 28095.52863856\n",
            "Iteration 21093, loss = 28095.92605990\n",
            "Iteration 21094, loss = 28094.57654006\n",
            "Iteration 21095, loss = 28094.45706122\n",
            "Iteration 21096, loss = 28096.49808668\n",
            "Iteration 21097, loss = 28096.28837220\n",
            "Iteration 21098, loss = 28094.28046968\n",
            "Iteration 21099, loss = 28094.29824304\n",
            "Iteration 21100, loss = 28095.06677796\n",
            "Iteration 21101, loss = 28094.36407801\n",
            "Iteration 21102, loss = 28093.88018681\n",
            "Iteration 21103, loss = 28093.35347953\n",
            "Iteration 21104, loss = 28093.22184471\n",
            "Iteration 21105, loss = 28092.58928009\n",
            "Iteration 21106, loss = 28093.21465291\n",
            "Iteration 21107, loss = 28093.29380921\n",
            "Iteration 21108, loss = 28093.40507131\n",
            "Iteration 21109, loss = 28092.52849958\n",
            "Iteration 21110, loss = 28092.29269800\n",
            "Iteration 21111, loss = 28092.48048188\n",
            "Iteration 21112, loss = 28092.38090987\n",
            "Iteration 21113, loss = 28091.45693185\n",
            "Iteration 21114, loss = 28090.63216107\n",
            "Iteration 21115, loss = 28092.37488906\n",
            "Iteration 21116, loss = 28092.53578865\n",
            "Iteration 21117, loss = 28091.11909496\n",
            "Iteration 21118, loss = 28091.61643955\n",
            "Iteration 21119, loss = 28091.37326275\n",
            "Iteration 21120, loss = 28090.71589032\n",
            "Iteration 21121, loss = 28090.78945428\n",
            "Iteration 21122, loss = 28090.03327435\n",
            "Iteration 21123, loss = 28089.29488729\n",
            "Iteration 21124, loss = 28089.80293384\n",
            "Iteration 21125, loss = 28089.58743950\n",
            "Iteration 21126, loss = 28088.16132787\n",
            "Iteration 21127, loss = 28088.48902738\n",
            "Iteration 21128, loss = 28088.06572606\n",
            "Iteration 21129, loss = 28088.34288974\n",
            "Iteration 21130, loss = 28087.30348841\n",
            "Iteration 21131, loss = 28087.18645275\n",
            "Iteration 21132, loss = 28087.58229702\n",
            "Iteration 21133, loss = 28087.43465864\n",
            "Iteration 21134, loss = 28086.75582341\n",
            "Iteration 21135, loss = 28085.83648161\n",
            "Iteration 21136, loss = 28085.74852173\n",
            "Iteration 21137, loss = 28085.68768764\n",
            "Iteration 21138, loss = 28086.25785278\n",
            "Iteration 21139, loss = 28086.34545591\n",
            "Iteration 21140, loss = 28085.38628410\n",
            "Iteration 21141, loss = 28085.87705530\n",
            "Iteration 21142, loss = 28085.47749151\n",
            "Iteration 21143, loss = 28084.65912240\n",
            "Iteration 21144, loss = 28085.76068316\n",
            "Iteration 21145, loss = 28085.62379223\n",
            "Iteration 21146, loss = 28085.03860181\n",
            "Iteration 21147, loss = 28083.53719656\n",
            "Iteration 21148, loss = 28084.35209592\n",
            "Iteration 21149, loss = 28084.11856942\n",
            "Iteration 21150, loss = 28083.83069590\n",
            "Iteration 21151, loss = 28083.45115358\n",
            "Iteration 21152, loss = 28082.78300633\n",
            "Iteration 21153, loss = 28083.44468583\n",
            "Iteration 21154, loss = 28083.25341638\n",
            "Iteration 21155, loss = 28082.97850846\n",
            "Iteration 21156, loss = 28082.51645953\n",
            "Iteration 21157, loss = 28082.57285482\n",
            "Iteration 21158, loss = 28082.23192729\n",
            "Iteration 21159, loss = 28081.99324734\n",
            "Iteration 21160, loss = 28081.16470152\n",
            "Iteration 21161, loss = 28080.57204534\n",
            "Iteration 21162, loss = 28080.92815686\n",
            "Iteration 21163, loss = 28080.73522912\n",
            "Iteration 21164, loss = 28080.12955989\n",
            "Iteration 21165, loss = 28079.62626641\n",
            "Iteration 21166, loss = 28080.86171193\n",
            "Iteration 21167, loss = 28080.21736947\n",
            "Iteration 21168, loss = 28079.68106206\n",
            "Iteration 21169, loss = 28079.57549972\n",
            "Iteration 21170, loss = 28079.88300941\n",
            "Iteration 21171, loss = 28079.55028609\n",
            "Iteration 21172, loss = 28078.94295359\n",
            "Iteration 21173, loss = 28078.27266263\n",
            "Iteration 21174, loss = 28078.57327393\n",
            "Iteration 21175, loss = 28078.80621560\n",
            "Iteration 21176, loss = 28078.39157591\n",
            "Iteration 21177, loss = 28077.13490270\n",
            "Iteration 21178, loss = 28078.10525789\n",
            "Iteration 21179, loss = 28078.13142519\n",
            "Iteration 21180, loss = 28076.73178402\n",
            "Iteration 21181, loss = 28077.27088244\n",
            "Iteration 21182, loss = 28077.37616696\n",
            "Iteration 21183, loss = 28076.92532436\n",
            "Iteration 21184, loss = 28076.77261323\n",
            "Iteration 21185, loss = 28077.23987360\n",
            "Iteration 21186, loss = 28076.92417275\n",
            "Iteration 21187, loss = 28076.16313413\n",
            "Iteration 21188, loss = 28075.98654677\n",
            "Iteration 21189, loss = 28075.49210125\n",
            "Iteration 21190, loss = 28074.73842248\n",
            "Iteration 21191, loss = 28075.05447977\n",
            "Iteration 21192, loss = 28075.41092505\n",
            "Iteration 21193, loss = 28074.18272588\n",
            "Iteration 21194, loss = 28074.17684717\n",
            "Iteration 21195, loss = 28075.49710511\n",
            "Iteration 21196, loss = 28075.34678289\n",
            "Iteration 21197, loss = 28074.18004743\n",
            "Iteration 21198, loss = 28074.33862433\n",
            "Iteration 21199, loss = 28075.05157379\n",
            "Iteration 21200, loss = 28074.63661215\n",
            "Iteration 21201, loss = 28075.10463623\n",
            "Iteration 21202, loss = 28074.87289774\n",
            "Iteration 21203, loss = 28073.36205483\n",
            "Iteration 21204, loss = 28072.25873917\n",
            "Iteration 21205, loss = 28072.38462060\n",
            "Iteration 21206, loss = 28072.12771015\n",
            "Iteration 21207, loss = 28072.51471957\n",
            "Iteration 21208, loss = 28071.99728773\n",
            "Iteration 21209, loss = 28073.06241581\n",
            "Iteration 21210, loss = 28073.03513202\n",
            "Iteration 21211, loss = 28071.43442107\n",
            "Iteration 21212, loss = 28070.78695527\n",
            "Iteration 21213, loss = 28071.26866162\n",
            "Iteration 21214, loss = 28070.37471629\n",
            "Iteration 21215, loss = 28070.13463404\n",
            "Iteration 21216, loss = 28069.95457404\n",
            "Iteration 21217, loss = 28069.94671795\n",
            "Iteration 21218, loss = 28069.00909294\n",
            "Iteration 21219, loss = 28069.71821661\n",
            "Iteration 21220, loss = 28070.45980207\n",
            "Iteration 21221, loss = 28069.44469445\n",
            "Iteration 21222, loss = 28068.54332358\n",
            "Iteration 21223, loss = 28069.15676067\n",
            "Iteration 21224, loss = 28068.57606123\n",
            "Iteration 21225, loss = 28067.85431638\n",
            "Iteration 21226, loss = 28067.67794958\n",
            "Iteration 21227, loss = 28068.03116541\n",
            "Iteration 21228, loss = 28067.76962598\n",
            "Iteration 21229, loss = 28066.69988606\n",
            "Iteration 21230, loss = 28067.62798659\n",
            "Iteration 21231, loss = 28067.55333642\n",
            "Iteration 21232, loss = 28066.81837978\n",
            "Iteration 21233, loss = 28066.89043658\n",
            "Iteration 21234, loss = 28067.21306594\n",
            "Iteration 21235, loss = 28065.95200242\n",
            "Iteration 21236, loss = 28066.21860403\n",
            "Iteration 21237, loss = 28066.75357911\n",
            "Iteration 21238, loss = 28065.82271846\n",
            "Iteration 21239, loss = 28065.46617007\n",
            "Iteration 21240, loss = 28066.04304123\n",
            "Iteration 21241, loss = 28065.83075251\n",
            "Iteration 21242, loss = 28065.21002013\n",
            "Iteration 21243, loss = 28065.01449483\n",
            "Iteration 21244, loss = 28064.66430547\n",
            "Iteration 21245, loss = 28063.61522620\n",
            "Iteration 21246, loss = 28064.09246477\n",
            "Iteration 21247, loss = 28064.51720112\n",
            "Iteration 21248, loss = 28063.33180719\n",
            "Iteration 21249, loss = 28063.95444179\n",
            "Iteration 21250, loss = 28064.01898842\n",
            "Iteration 21251, loss = 28064.18069445\n",
            "Iteration 21252, loss = 28063.60977622\n",
            "Iteration 21253, loss = 28062.79781607\n",
            "Iteration 21254, loss = 28063.37112241\n",
            "Iteration 21255, loss = 28062.88906660\n",
            "Iteration 21256, loss = 28062.91035609\n",
            "Iteration 21257, loss = 28062.38028415\n",
            "Iteration 21258, loss = 28062.05406095\n",
            "Iteration 21259, loss = 28062.64744556\n",
            "Iteration 21260, loss = 28062.96467045\n",
            "Iteration 21261, loss = 28062.36543516\n",
            "Iteration 21262, loss = 28061.78373023\n",
            "Iteration 21263, loss = 28061.13251223\n",
            "Iteration 21264, loss = 28060.84487794\n",
            "Iteration 21265, loss = 28061.23810019\n",
            "Iteration 21266, loss = 28061.24932609\n",
            "Iteration 21267, loss = 28060.59619531\n",
            "Iteration 21268, loss = 28059.21861033\n",
            "Iteration 21269, loss = 28059.74256961\n",
            "Iteration 21270, loss = 28060.55104807\n",
            "Iteration 21271, loss = 28059.63525722\n",
            "Iteration 21272, loss = 28059.12659976\n",
            "Iteration 21273, loss = 28058.77411562\n",
            "Iteration 21274, loss = 28059.27758201\n",
            "Iteration 21275, loss = 28058.96831601\n",
            "Iteration 21276, loss = 28057.99838320\n",
            "Iteration 21277, loss = 28058.79742167\n",
            "Iteration 21278, loss = 28058.72425002\n",
            "Iteration 21279, loss = 28058.98339969\n",
            "Iteration 21280, loss = 28059.32842916\n",
            "Iteration 21281, loss = 28057.95837582\n",
            "Iteration 21282, loss = 28057.38895137\n",
            "Iteration 21283, loss = 28057.80659375\n",
            "Iteration 21284, loss = 28056.96882908\n",
            "Iteration 21285, loss = 28056.16497059\n",
            "Iteration 21286, loss = 28056.06585475\n",
            "Iteration 21287, loss = 28056.42236416\n",
            "Iteration 21288, loss = 28056.17698540\n",
            "Iteration 21289, loss = 28056.33658974\n",
            "Iteration 21290, loss = 28055.88458029\n",
            "Iteration 21291, loss = 28054.99850176\n",
            "Iteration 21292, loss = 28055.73243116\n",
            "Iteration 21293, loss = 28055.11293103\n",
            "Iteration 21294, loss = 28054.33817155\n",
            "Iteration 21295, loss = 28054.25918437\n",
            "Iteration 21296, loss = 28054.76254749\n",
            "Iteration 21297, loss = 28054.94432374\n",
            "Iteration 21298, loss = 28053.33931237\n",
            "Iteration 21299, loss = 28053.19118775\n",
            "Iteration 21300, loss = 28053.03442093\n",
            "Iteration 21301, loss = 28053.04541782\n",
            "Iteration 21302, loss = 28052.35318899\n",
            "Iteration 21303, loss = 28052.61057211\n",
            "Iteration 21304, loss = 28052.81828048\n",
            "Iteration 21305, loss = 28052.59609978\n",
            "Iteration 21306, loss = 28052.76198066\n",
            "Iteration 21307, loss = 28052.31874335\n",
            "Iteration 21308, loss = 28051.35754092\n",
            "Iteration 21309, loss = 28051.26480023\n",
            "Iteration 21310, loss = 28050.86628752\n",
            "Iteration 21311, loss = 28050.56169468\n",
            "Iteration 21312, loss = 28050.61526115\n",
            "Iteration 21313, loss = 28050.99106904\n",
            "Iteration 21314, loss = 28050.56782547\n",
            "Iteration 21315, loss = 28050.65569680\n",
            "Iteration 21316, loss = 28049.72053820\n",
            "Iteration 21317, loss = 28049.80131073\n",
            "Iteration 21318, loss = 28050.22879768\n",
            "Iteration 21319, loss = 28049.73043159\n",
            "Iteration 21320, loss = 28049.42873780\n",
            "Iteration 21321, loss = 28050.25014617\n",
            "Iteration 21322, loss = 28050.13690322\n",
            "Iteration 21323, loss = 28048.83945845\n",
            "Iteration 21324, loss = 28048.22755835\n",
            "Iteration 21325, loss = 28049.31820190\n",
            "Iteration 21326, loss = 28048.71039711\n",
            "Iteration 21327, loss = 28048.63854114\n",
            "Iteration 21328, loss = 28048.49064454\n",
            "Iteration 21329, loss = 28047.81316219\n",
            "Iteration 21330, loss = 28048.69388164\n",
            "Iteration 21331, loss = 28048.47702298\n",
            "Iteration 21332, loss = 28047.51449349\n",
            "Iteration 21333, loss = 28047.21458090\n",
            "Iteration 21334, loss = 28047.49997772\n",
            "Iteration 21335, loss = 28046.41435216\n",
            "Iteration 21336, loss = 28045.87165545\n",
            "Iteration 21337, loss = 28046.81008742\n",
            "Iteration 21338, loss = 28047.74480585\n",
            "Iteration 21339, loss = 28046.25163307\n",
            "Iteration 21340, loss = 28045.78778654\n",
            "Iteration 21341, loss = 28046.64191383\n",
            "Iteration 21342, loss = 28046.72315747\n",
            "Iteration 21343, loss = 28046.08448666\n",
            "Iteration 21344, loss = 28046.40263283\n",
            "Iteration 21345, loss = 28045.32922467\n",
            "Iteration 21346, loss = 28044.43766123\n",
            "Iteration 21347, loss = 28045.20698303\n",
            "Iteration 21348, loss = 28044.69973261\n",
            "Iteration 21349, loss = 28044.01142239\n",
            "Iteration 21350, loss = 28043.43574582\n",
            "Iteration 21351, loss = 28043.75485278\n",
            "Iteration 21352, loss = 28043.98080293\n",
            "Iteration 21353, loss = 28043.24471123\n",
            "Iteration 21354, loss = 28043.24351934\n",
            "Iteration 21355, loss = 28042.94927555\n",
            "Iteration 21356, loss = 28042.31236423\n",
            "Iteration 21357, loss = 28042.53401860\n",
            "Iteration 21358, loss = 28043.23016931\n",
            "Iteration 21359, loss = 28042.44988190\n",
            "Iteration 21360, loss = 28041.24889991\n",
            "Iteration 21361, loss = 28042.79703534\n",
            "Iteration 21362, loss = 28043.58084814\n",
            "Iteration 21363, loss = 28042.79064406\n",
            "Iteration 21364, loss = 28041.55232488\n",
            "Iteration 21365, loss = 28041.61711242\n",
            "Iteration 21366, loss = 28042.74669307\n",
            "Iteration 21367, loss = 28042.11651329\n",
            "Iteration 21368, loss = 28040.77315486\n",
            "Iteration 21369, loss = 28039.91767505\n",
            "Iteration 21370, loss = 28040.65528344\n",
            "Iteration 21371, loss = 28040.59108242\n",
            "Iteration 21372, loss = 28039.52891023\n",
            "Iteration 21373, loss = 28039.25184975\n",
            "Iteration 21374, loss = 28039.42816742\n",
            "Iteration 21375, loss = 28038.82036612\n",
            "Iteration 21376, loss = 28039.39285750\n",
            "Iteration 21377, loss = 28038.93988618\n",
            "Iteration 21378, loss = 28039.02079447\n",
            "Iteration 21379, loss = 28039.10383371\n",
            "Iteration 21380, loss = 28038.57098670\n",
            "Iteration 21381, loss = 28037.54090616\n",
            "Iteration 21382, loss = 28038.42951599\n",
            "Iteration 21383, loss = 28039.25801766\n",
            "Iteration 21384, loss = 28038.89830958\n",
            "Iteration 21385, loss = 28037.79985644\n",
            "Iteration 21386, loss = 28036.83046346\n",
            "Iteration 21387, loss = 28037.13747320\n",
            "Iteration 21388, loss = 28036.22732014\n",
            "Iteration 21389, loss = 28035.38962750\n",
            "Iteration 21390, loss = 28036.39574357\n",
            "Iteration 21391, loss = 28037.51015049\n",
            "Iteration 21392, loss = 28036.65657656\n",
            "Iteration 21393, loss = 28034.99949838\n",
            "Iteration 21394, loss = 28036.62782463\n",
            "Iteration 21395, loss = 28037.74531699\n",
            "Iteration 21396, loss = 28036.90998467\n",
            "Iteration 21397, loss = 28035.66519898\n",
            "Iteration 21398, loss = 28035.32572779\n",
            "Iteration 21399, loss = 28035.38072441\n",
            "Iteration 21400, loss = 28036.27666283\n",
            "Iteration 21401, loss = 28035.95750921\n",
            "Iteration 21402, loss = 28035.51919235\n",
            "Iteration 21403, loss = 28035.20320826\n",
            "Iteration 21404, loss = 28035.11301065\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        }
      ],
      "source": [
        "# Set model and training\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(5,5),\n",
        "                    activation = 'relu',\n",
        "                    solver = 'adam',\n",
        "                    max_iter= 50000,\n",
        "                    verbose = True).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Semakin rendah nilai loss, semakin baik performa model dalam memprediksi data pelatihan. Tujuan pelatihan adalah mencapai loss yang rendah sehingga model dapat digunakan untuk melakukan prediksi yang akurat pada data baru yang belum pernah dilihat sebelumnya.*"
      ],
      "metadata": {
        "id": "6KoPwO6XP8st"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpMxPdFMmHhO",
        "outputId": "9b0283da-9878-45b3-9b19-c538d1075ab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Layer = 4\n",
            "Number of Iteration = 21404\n",
            "Current loss computed with the loss function = 28035.113010648427\n"
          ]
        }
      ],
      "source": [
        "# Print model\n",
        "print('Number of Layer =', mlp.n_layers_)\n",
        "print('Number of Iteration =', mlp.n_iter_)\n",
        "print('Current loss computed with the loss function =', mlp.loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGyWhU0ZxEIK"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "Melakukan prediksi pada data test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CarA0JFckoxq",
        "outputId": "53cc4a82-7291-4285-cc2d-7a71bee9fccb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4349.55528691, 4782.10200909, 2012.39666307, 1906.58468814,\n",
              "       5297.29592031, 2759.84278508, 2142.48428071, 2838.38107917,\n",
              "       4070.91945014, 4972.85395852, 5380.62011675, 3101.36912768,\n",
              "       4599.38969586, 4749.39868792, 2283.67560447, 2233.00288512,\n",
              "       1372.50134735, 4934.25858184, 4489.7425912 , 2537.33791006,\n",
              "       1902.20437393, 5025.55206398, 4686.52099118, 3811.62449411,\n",
              "       3263.05598862, 2508.21002697, 2175.01221276, 4395.0995954 ,\n",
              "       4201.64878017, 3870.46352611, 2349.0764028 , 2450.73493449,\n",
              "       3792.12171191, 5023.44878879, 4789.88259446, 3913.341774  ,\n",
              "       2514.13484361, 1636.45781212, 4706.02326368, 1698.11121289,\n",
              "       1058.78763809, 5218.40288489, 5467.67178621, 2986.93196841,\n",
              "       2977.29951149, 4187.95303301, 4318.49474799, 5551.47496696,\n",
              "       1903.85780773, 3081.02376879, 5774.68586044, 1941.19484259,\n",
              "       1616.65180681, 3251.71932608, 4931.75538324, 4522.96993805,\n",
              "       1548.81596359, 4539.82613951, 3134.28111915, 4724.31113341,\n",
              "       5590.11219662, 4744.9278869 , 4770.23204404, 4158.00394454,\n",
              "       3061.23650849, 5018.18759474, 4088.19870028, 2901.43474099,\n",
              "       3258.15788184, 4764.82484525, 5219.8453779 ])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Make a prediction to test data\n",
        "y_pred = mlp.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Melakukan pendefinisian pada fungsi MAPE dan melakukan pengecekan hasil dari dataset\n",
        "\n",
        "Mean Absolute Percentage Error (Kesalahan Persentase Mutlak Rata-rata) = salah satu metrik evaluasi yang umum digunakan untuk mengukur akurasi model dalam tugas regresi. MAPE mengukur sejauh mana perbedaan antara nilai aktual (y_test) dan nilai yang diprediksi (y_pred) sebagai persentase dari nilai aktual itu sendiri."
      ],
      "metadata": {
        "id": "AsEfRH_CR04X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OXmlMdlJxE_e"
      },
      "outputs": [],
      "source": [
        "# Define MAPE function\n",
        "def mape(y_test, y_pred):\n",
        "    return np.mean(np.abs((y_pred - y_test) / y_test)) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxhoneR-vzDi",
        "outputId": "84546cc9-f4fc-4326-f839-dc3991b4de5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE = 296.1146332766306\n",
            "RMSE 141440.14682391981\n",
            "R2 = 0.9228589574124206\n",
            "MAPE 9.625783753058537\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "print('MAE =', mean_absolute_error(y_test, y_pred))\n",
        "print('RMSE', mean_squared_error(y_test, y_pred))\n",
        "print('R2 =', r2_score(y_test, y_pred))\n",
        "print('MAPE', mape(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.   MAE (Mean Absolute Error): nilai rata-rata dari kesalahan absolut antara nilai aktual (y_test) dan nilai yang diprediksi (y_pred). Artinya bahwa rata-rata kesalahan absolut dari prediksi sekitar 283.16 unit\n",
        "2.   RMSE (Root Mean Square Error): akar kuadrat dari rata-rata dari kuadrat kesalahan antara nilai aktual dan nilai yang diprediksi. RMSE sekitar 130,556.04.\n",
        "3. R-squared (R^2) :  ukuran sejauh mana variasi dalam data dapat dijelaskan oleh model regresi. Nilai R-squared berkisar dari 0 hingga 1, di mana 0 berarti model tidak menjelaskan variasi sama sekali, dan 1 berarti model menjelaskan seluruh variasi. R2 = 0.93, yang berarti model Anda mampu menjelaskan sekitar 93% variasi dalam data uji.\n",
        "4. MAPE (Mean Absolute Percentage Error) = mengukur rata-rata kesalahan dalam persentase dari nilai aktual. MAPE = 9,05% -> secara rata-rata, prediksi model memiliki kesalahan sekitar 9.05% terhadap nilai aktual.\n",
        "\n",
        "\n",
        "**Semakin rendah MAE, RMSE, dan MAPE, serta semakin tinggi R-squared, semakin baik performa suatu model**\n",
        "\n",
        "\n",
        "Kesimpulan : model memiliki performa yang sangat baik dalam memprediksi data.\n",
        "\n"
      ],
      "metadata": {
        "id": "tHfPmiUMSn1y"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}